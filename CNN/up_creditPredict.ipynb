{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline    \n",
    "\n",
    "#加载原始数据\n",
    "raw_data_train = pd.read_csv(r\"./dataSets/train.csv\", encoding='gbk')\n",
    "raw_data_test = pd.read_csv(r\"./dataSets/test.csv\", encoding='gbk')\n",
    "\n",
    "#缺失值处理\n",
    "train_data = raw_data_train.fillna(0)\n",
    "train_feature_data = (train_data.drop(['id','label1','label2'],axis=1))\n",
    "train_target = train_data.label2\n",
    "X_train = train_feature_data.values.astype(np.float32)\n",
    "\n",
    "test_data = raw_data_test.fillna(0)\n",
    "test_feature_data = (test_data.drop(['id','label1','label2'],axis=1))\n",
    "test_target = test_data.label2\n",
    "X_test = test_feature_data.values.astype(np.float32)\n",
    "\n",
    "X_train, _, y_train, _ = train_test_split(X_train, train_target, test_size=0.0, random_state=123)\n",
    "_, X_test, _, y_test = train_test_split(X_test, test_target, test_size=0.9999, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载原始数据\n",
    "#raw_data = pd.read_csv(r\"./creditGrade_train_data.csv\", encoding='gbk')\n",
    "#data = raw_data.fillna(0)\n",
    "#features_data = (data.drop(['id','label1','label2'],axis=1))\n",
    "#5-class\n",
    "#target = data.label2\n",
    "#X = features_data.values.astype(np.float32) # 转换数据类型\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.3, random_state=123) # 参数test_size设置训练集占比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.01437473e-01   0.00000000e+00   2.17514172e-01 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  4.90476266e-02   0.00000000e+00   1.65245622e-01 ...,   7.08895456e-03\n",
      "    1.36673189e-04   2.60942634e-02]\n",
      " [  1.11642247e-03   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  6.29723221e-02   0.00000000e+00   1.66234493e-01 ...,   8.97091231e-05\n",
      "    0.00000000e+00   1.16708950e-04]\n",
      " [  1.07931413e-01   0.00000000e+00   1.36101902e-01 ...,   2.62339599e-03\n",
      "    3.63099825e-05   2.48723361e-03]\n",
      " [  9.69535932e-02   0.00000000e+00   1.26169785e-03 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Normalization\n",
    "from sklearn import preprocessing\n",
    "# l2正则化\n",
    "X_train = preprocessing.normalize(X_train, norm='l2')\n",
    "X_test = preprocessing.normalize(X_test, norm='l2')\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2600, 106)\n",
      "(100, 106)\n",
      "train num: 2600\n",
      "val num: 100\n"
     ]
    }
   ],
   "source": [
    "#对分类进行one-hot编码\n",
    "y_tr = one_hot(y_train.astype(np.int64),5)\n",
    "y_vld = one_hot(y_test.astype(np.int64),5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(\"train num:\", len(y_tr))\n",
    "print(\"val num:\", len(y_vld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow运行版本：1.3.0\n",
      "Tensor(\"cnn:0\", shape=(?,), dtype=int64)\n",
      "Epoch: 4/5000 Iteration: 5 Train loss: 86.496323 Train acc: 0.471154\n",
      "Epoch: 9/5000 Iteration: 10 Train loss: 84.506325 Train acc: 0.471154\n",
      "Epoch: 9/5000 Iteration: 10 Validation loss: 84.227013 Validation acc: 0.440000\n",
      "Epoch: 14/5000 Iteration: 15 Train loss: 82.540886 Train acc: 0.471154\n",
      "Epoch: 19/5000 Iteration: 20 Train loss: 80.650345 Train acc: 0.471154\n",
      "Epoch: 19/5000 Iteration: 20 Validation loss: 80.375511 Validation acc: 0.440000\n",
      "Epoch: 24/5000 Iteration: 25 Train loss: 78.787941 Train acc: 0.471154\n",
      "Epoch: 29/5000 Iteration: 30 Train loss: 76.974236 Train acc: 0.471154\n",
      "Epoch: 29/5000 Iteration: 30 Validation loss: 76.715675 Validation acc: 0.440000\n",
      "Epoch: 34/5000 Iteration: 35 Train loss: 75.199036 Train acc: 0.471154\n",
      "Epoch: 39/5000 Iteration: 40 Train loss: 73.471191 Train acc: 0.471154\n",
      "Epoch: 39/5000 Iteration: 40 Validation loss: 73.230507 Validation acc: 0.440000\n",
      "Epoch: 44/5000 Iteration: 45 Train loss: 71.784805 Train acc: 0.471154\n",
      "Epoch: 49/5000 Iteration: 50 Train loss: 70.134415 Train acc: 0.471154\n",
      "Epoch: 49/5000 Iteration: 50 Validation loss: 69.905190 Validation acc: 0.440000\n",
      "Epoch: 54/5000 Iteration: 55 Train loss: 68.524803 Train acc: 0.471154\n",
      "Epoch: 59/5000 Iteration: 60 Train loss: 66.955139 Train acc: 0.471154\n",
      "Epoch: 59/5000 Iteration: 60 Validation loss: 66.739754 Validation acc: 0.440000\n",
      "Epoch: 64/5000 Iteration: 65 Train loss: 65.422287 Train acc: 0.471154\n",
      "Epoch: 69/5000 Iteration: 70 Train loss: 63.922085 Train acc: 0.471154\n",
      "Epoch: 69/5000 Iteration: 70 Validation loss: 63.723537 Validation acc: 0.440000\n",
      "Epoch: 74/5000 Iteration: 75 Train loss: 62.464912 Train acc: 0.471154\n",
      "Epoch: 79/5000 Iteration: 80 Train loss: 61.034813 Train acc: 0.471154\n",
      "Epoch: 79/5000 Iteration: 80 Validation loss: 60.848999 Validation acc: 0.440000\n",
      "Epoch: 84/5000 Iteration: 85 Train loss: 59.643776 Train acc: 0.471154\n",
      "Epoch: 89/5000 Iteration: 90 Train loss: 58.282284 Train acc: 0.471154\n",
      "Epoch: 89/5000 Iteration: 90 Validation loss: 58.107624 Validation acc: 0.440000\n",
      "Epoch: 94/5000 Iteration: 95 Train loss: 56.951141 Train acc: 0.471154\n",
      "Epoch: 99/5000 Iteration: 100 Train loss: 55.656441 Train acc: 0.471154\n",
      "Epoch: 99/5000 Iteration: 100 Validation loss: 55.492943 Validation acc: 0.440000\n",
      "Epoch: 104/5000 Iteration: 105 Train loss: 54.387966 Train acc: 0.471154\n",
      "Epoch: 109/5000 Iteration: 110 Train loss: 53.151276 Train acc: 0.471154\n",
      "Epoch: 109/5000 Iteration: 110 Validation loss: 52.998528 Validation acc: 0.440000\n",
      "Epoch: 114/5000 Iteration: 115 Train loss: 51.939407 Train acc: 0.471154\n",
      "Epoch: 119/5000 Iteration: 120 Train loss: 50.759506 Train acc: 0.471154\n",
      "Epoch: 119/5000 Iteration: 120 Validation loss: 50.617580 Validation acc: 0.440000\n",
      "Epoch: 124/5000 Iteration: 125 Train loss: 49.604214 Train acc: 0.471154\n",
      "Epoch: 129/5000 Iteration: 130 Train loss: 48.476898 Train acc: 0.471154\n",
      "Epoch: 129/5000 Iteration: 130 Validation loss: 48.345921 Validation acc: 0.440000\n",
      "Epoch: 134/5000 Iteration: 135 Train loss: 47.375362 Train acc: 0.471154\n",
      "Epoch: 139/5000 Iteration: 140 Train loss: 46.298843 Train acc: 0.471154\n",
      "Epoch: 139/5000 Iteration: 140 Validation loss: 46.177002 Validation acc: 0.440000\n",
      "Epoch: 144/5000 Iteration: 145 Train loss: 45.244461 Train acc: 0.471154\n",
      "Epoch: 149/5000 Iteration: 150 Train loss: 44.218189 Train acc: 0.471154\n",
      "Epoch: 149/5000 Iteration: 150 Validation loss: 44.105980 Validation acc: 0.440000\n",
      "Epoch: 154/5000 Iteration: 155 Train loss: 43.215977 Train acc: 0.471154\n",
      "Epoch: 159/5000 Iteration: 160 Train loss: 42.232903 Train acc: 0.471154\n",
      "Epoch: 159/5000 Iteration: 160 Validation loss: 42.127766 Validation acc: 0.440000\n",
      "Epoch: 164/5000 Iteration: 165 Train loss: 41.275547 Train acc: 0.471154\n",
      "Epoch: 169/5000 Iteration: 170 Train loss: 40.338894 Train acc: 0.471154\n",
      "Epoch: 169/5000 Iteration: 170 Validation loss: 40.240257 Validation acc: 0.440000\n",
      "Epoch: 174/5000 Iteration: 175 Train loss: 39.421803 Train acc: 0.471154\n",
      "Epoch: 179/5000 Iteration: 180 Train loss: 38.525742 Train acc: 0.471154\n",
      "Epoch: 179/5000 Iteration: 180 Validation loss: 38.438011 Validation acc: 0.440000\n",
      "Epoch: 184/5000 Iteration: 185 Train loss: 37.654469 Train acc: 0.471154\n",
      "Epoch: 189/5000 Iteration: 190 Train loss: 36.800865 Train acc: 0.471154\n",
      "Epoch: 189/5000 Iteration: 190 Validation loss: 36.717037 Validation acc: 0.440000\n",
      "Epoch: 194/5000 Iteration: 195 Train loss: 35.967640 Train acc: 0.471154\n",
      "Epoch: 199/5000 Iteration: 200 Train loss: 35.149986 Train acc: 0.471154\n",
      "Epoch: 199/5000 Iteration: 200 Validation loss: 35.071899 Validation acc: 0.440000\n",
      "Epoch: 204/5000 Iteration: 205 Train loss: 34.356071 Train acc: 0.471154\n",
      "Epoch: 209/5000 Iteration: 210 Train loss: 33.570198 Train acc: 0.471154\n",
      "Epoch: 209/5000 Iteration: 210 Validation loss: 33.500114 Validation acc: 0.440000\n",
      "Epoch: 214/5000 Iteration: 215 Train loss: 32.806255 Train acc: 0.471154\n",
      "Epoch: 219/5000 Iteration: 220 Train loss: 32.062580 Train acc: 0.471154\n",
      "Epoch: 219/5000 Iteration: 220 Validation loss: 31.999981 Validation acc: 0.440000\n",
      "Epoch: 224/5000 Iteration: 225 Train loss: 31.335987 Train acc: 0.471154\n",
      "Epoch: 229/5000 Iteration: 230 Train loss: 30.621790 Train acc: 0.471154\n",
      "Epoch: 229/5000 Iteration: 230 Validation loss: 30.565802 Validation acc: 0.440000\n",
      "Epoch: 234/5000 Iteration: 235 Train loss: 29.928106 Train acc: 0.471154\n",
      "Epoch: 239/5000 Iteration: 240 Train loss: 29.244427 Train acc: 0.471154\n",
      "Epoch: 239/5000 Iteration: 240 Validation loss: 29.194515 Validation acc: 0.440000\n",
      "Epoch: 244/5000 Iteration: 245 Train loss: 28.583481 Train acc: 0.471154\n",
      "Epoch: 249/5000 Iteration: 250 Train loss: 27.937408 Train acc: 0.471154\n",
      "Epoch: 249/5000 Iteration: 250 Validation loss: 27.882189 Validation acc: 0.440000\n",
      "Epoch: 254/5000 Iteration: 255 Train loss: 27.295448 Train acc: 0.471154\n",
      "Epoch: 259/5000 Iteration: 260 Train loss: 26.677946 Train acc: 0.471154\n",
      "Epoch: 259/5000 Iteration: 260 Validation loss: 26.626471 Validation acc: 0.440000\n",
      "Epoch: 264/5000 Iteration: 265 Train loss: 26.063959 Train acc: 0.471538\n",
      "Epoch: 269/5000 Iteration: 270 Train loss: 25.464134 Train acc: 0.470769\n",
      "Epoch: 269/5000 Iteration: 270 Validation loss: 25.420927 Validation acc: 0.440000\n",
      "Epoch: 274/5000 Iteration: 275 Train loss: 24.881702 Train acc: 0.471538\n",
      "Epoch: 279/5000 Iteration: 280 Train loss: 24.308910 Train acc: 0.474231\n",
      "Epoch: 279/5000 Iteration: 280 Validation loss: 24.257818 Validation acc: 0.430000\n",
      "Epoch: 284/5000 Iteration: 285 Train loss: 23.741524 Train acc: 0.472308\n",
      "Epoch: 289/5000 Iteration: 290 Train loss: 23.191713 Train acc: 0.481538\n",
      "Epoch: 289/5000 Iteration: 290 Validation loss: 23.138348 Validation acc: 0.400000\n",
      "Epoch: 294/5000 Iteration: 295 Train loss: 22.648907 Train acc: 0.489231\n",
      "Epoch: 299/5000 Iteration: 300 Train loss: 22.120378 Train acc: 0.496154\n",
      "Epoch: 299/5000 Iteration: 300 Validation loss: 22.073071 Validation acc: 0.380000\n",
      "Epoch: 304/5000 Iteration: 305 Train loss: 21.602730 Train acc: 0.506154\n",
      "Epoch: 309/5000 Iteration: 310 Train loss: 21.090094 Train acc: 0.514615\n",
      "Epoch: 309/5000 Iteration: 310 Validation loss: 21.049959 Validation acc: 0.400000\n",
      "Epoch: 314/5000 Iteration: 315 Train loss: 20.597048 Train acc: 0.525385\n",
      "Epoch: 319/5000 Iteration: 320 Train loss: 20.120296 Train acc: 0.520000\n",
      "Epoch: 319/5000 Iteration: 320 Validation loss: 20.067135 Validation acc: 0.400000\n",
      "Epoch: 324/5000 Iteration: 325 Train loss: 19.638260 Train acc: 0.530000\n",
      "Epoch: 329/5000 Iteration: 330 Train loss: 19.190231 Train acc: 0.532692\n",
      "Epoch: 329/5000 Iteration: 330 Validation loss: 19.126808 Validation acc: 0.490000\n",
      "Epoch: 334/5000 Iteration: 335 Train loss: 18.730516 Train acc: 0.542692\n",
      "Epoch: 339/5000 Iteration: 340 Train loss: 18.299109 Train acc: 0.546154\n",
      "Epoch: 339/5000 Iteration: 340 Validation loss: 18.240860 Validation acc: 0.530000\n",
      "Epoch: 344/5000 Iteration: 345 Train loss: 17.874352 Train acc: 0.548461\n",
      "Epoch: 349/5000 Iteration: 350 Train loss: 17.450544 Train acc: 0.550769\n",
      "Epoch: 349/5000 Iteration: 350 Validation loss: 17.400311 Validation acc: 0.550000\n",
      "Epoch: 354/5000 Iteration: 355 Train loss: 17.045887 Train acc: 0.551538\n",
      "Epoch: 359/5000 Iteration: 360 Train loss: 16.652298 Train acc: 0.549615\n",
      "Epoch: 359/5000 Iteration: 360 Validation loss: 16.601688 Validation acc: 0.550000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 364/5000 Iteration: 365 Train loss: 16.264938 Train acc: 0.556538\n",
      "Epoch: 369/5000 Iteration: 370 Train loss: 15.887785 Train acc: 0.565385\n",
      "Epoch: 369/5000 Iteration: 370 Validation loss: 15.834915 Validation acc: 0.540000\n",
      "Epoch: 374/5000 Iteration: 375 Train loss: 15.511174 Train acc: 0.564615\n",
      "Epoch: 379/5000 Iteration: 380 Train loss: 15.152331 Train acc: 0.561154\n",
      "Epoch: 379/5000 Iteration: 380 Validation loss: 15.111995 Validation acc: 0.550000\n",
      "Epoch: 384/5000 Iteration: 385 Train loss: 14.791865 Train acc: 0.586154\n",
      "Epoch: 389/5000 Iteration: 390 Train loss: 14.461596 Train acc: 0.567692\n",
      "Epoch: 389/5000 Iteration: 390 Validation loss: 14.416246 Validation acc: 0.530000\n",
      "Epoch: 394/5000 Iteration: 395 Train loss: 14.116766 Train acc: 0.579231\n",
      "Epoch: 399/5000 Iteration: 400 Train loss: 13.784970 Train acc: 0.573077\n",
      "Epoch: 399/5000 Iteration: 400 Validation loss: 13.754872 Validation acc: 0.530000\n",
      "Epoch: 404/5000 Iteration: 405 Train loss: 13.460133 Train acc: 0.583077\n",
      "Epoch: 409/5000 Iteration: 410 Train loss: 13.146728 Train acc: 0.592692\n",
      "Epoch: 409/5000 Iteration: 410 Validation loss: 13.123366 Validation acc: 0.550000\n",
      "Epoch: 414/5000 Iteration: 415 Train loss: 12.841674 Train acc: 0.583462\n",
      "Epoch: 419/5000 Iteration: 420 Train loss: 12.537233 Train acc: 0.593077\n",
      "Epoch: 419/5000 Iteration: 420 Validation loss: 12.517897 Validation acc: 0.550000\n",
      "Epoch: 424/5000 Iteration: 425 Train loss: 12.243312 Train acc: 0.603846\n",
      "Epoch: 429/5000 Iteration: 430 Train loss: 11.958485 Train acc: 0.599231\n",
      "Epoch: 429/5000 Iteration: 430 Validation loss: 11.944124 Validation acc: 0.550000\n",
      "Epoch: 434/5000 Iteration: 435 Train loss: 11.672210 Train acc: 0.611923\n",
      "Epoch: 439/5000 Iteration: 440 Train loss: 11.404078 Train acc: 0.607692\n",
      "Epoch: 439/5000 Iteration: 440 Validation loss: 11.390545 Validation acc: 0.550000\n",
      "Epoch: 444/5000 Iteration: 445 Train loss: 11.134368 Train acc: 0.621538\n",
      "Epoch: 449/5000 Iteration: 450 Train loss: 10.877117 Train acc: 0.608846\n",
      "Epoch: 449/5000 Iteration: 450 Validation loss: 10.874275 Validation acc: 0.530000\n",
      "Epoch: 454/5000 Iteration: 455 Train loss: 10.616483 Train acc: 0.623846\n",
      "Epoch: 459/5000 Iteration: 460 Train loss: 10.368331 Train acc: 0.629615\n",
      "Epoch: 459/5000 Iteration: 460 Validation loss: 10.373846 Validation acc: 0.560000\n",
      "Epoch: 464/5000 Iteration: 465 Train loss: 10.116660 Train acc: 0.643462\n",
      "Epoch: 469/5000 Iteration: 470 Train loss: 9.885604 Train acc: 0.635769\n",
      "Epoch: 469/5000 Iteration: 470 Validation loss: 9.889536 Validation acc: 0.560000\n",
      "Epoch: 474/5000 Iteration: 475 Train loss: 9.644760 Train acc: 0.640385\n",
      "Epoch: 479/5000 Iteration: 480 Train loss: 9.424078 Train acc: 0.638846\n",
      "Epoch: 479/5000 Iteration: 480 Validation loss: 9.428077 Validation acc: 0.580000\n",
      "Epoch: 484/5000 Iteration: 485 Train loss: 9.196836 Train acc: 0.655769\n",
      "Epoch: 489/5000 Iteration: 490 Train loss: 8.970943 Train acc: 0.659615\n",
      "Epoch: 489/5000 Iteration: 490 Validation loss: 8.994976 Validation acc: 0.580000\n",
      "Epoch: 494/5000 Iteration: 495 Train loss: 8.747877 Train acc: 0.672308\n",
      "Epoch: 499/5000 Iteration: 500 Train loss: 8.552106 Train acc: 0.671923\n",
      "Epoch: 499/5000 Iteration: 500 Validation loss: 8.576629 Validation acc: 0.590000\n",
      "Epoch: 504/5000 Iteration: 505 Train loss: 8.340669 Train acc: 0.676154\n",
      "Epoch: 509/5000 Iteration: 510 Train loss: 8.138454 Train acc: 0.683846\n",
      "Epoch: 509/5000 Iteration: 510 Validation loss: 8.169696 Validation acc: 0.630000\n",
      "Epoch: 514/5000 Iteration: 515 Train loss: 7.949772 Train acc: 0.692692\n",
      "Epoch: 519/5000 Iteration: 520 Train loss: 7.750374 Train acc: 0.698846\n",
      "Epoch: 519/5000 Iteration: 520 Validation loss: 7.788389 Validation acc: 0.690000\n",
      "Epoch: 524/5000 Iteration: 525 Train loss: 7.551013 Train acc: 0.716923\n",
      "Epoch: 529/5000 Iteration: 530 Train loss: 7.386923 Train acc: 0.704615\n",
      "Epoch: 529/5000 Iteration: 530 Validation loss: 7.420604 Validation acc: 0.700000\n",
      "Epoch: 534/5000 Iteration: 535 Train loss: 7.197134 Train acc: 0.713077\n",
      "Epoch: 539/5000 Iteration: 540 Train loss: 7.020899 Train acc: 0.720385\n",
      "Epoch: 539/5000 Iteration: 540 Validation loss: 7.075977 Validation acc: 0.700000\n",
      "Epoch: 544/5000 Iteration: 545 Train loss: 6.850750 Train acc: 0.734231\n",
      "Epoch: 549/5000 Iteration: 550 Train loss: 6.687183 Train acc: 0.723846\n",
      "Epoch: 549/5000 Iteration: 550 Validation loss: 6.750892 Validation acc: 0.660000\n",
      "Epoch: 554/5000 Iteration: 555 Train loss: 6.509996 Train acc: 0.745769\n",
      "Epoch: 559/5000 Iteration: 560 Train loss: 6.360912 Train acc: 0.738846\n",
      "Epoch: 559/5000 Iteration: 560 Validation loss: 6.424115 Validation acc: 0.700000\n",
      "Epoch: 564/5000 Iteration: 565 Train loss: 6.188873 Train acc: 0.773462\n",
      "Epoch: 569/5000 Iteration: 570 Train loss: 6.054313 Train acc: 0.756154\n",
      "Epoch: 569/5000 Iteration: 570 Validation loss: 6.133533 Validation acc: 0.700000\n",
      "Epoch: 574/5000 Iteration: 575 Train loss: 5.902145 Train acc: 0.768077\n",
      "Epoch: 579/5000 Iteration: 580 Train loss: 5.759116 Train acc: 0.776538\n",
      "Epoch: 579/5000 Iteration: 580 Validation loss: 5.837483 Validation acc: 0.710000\n",
      "Epoch: 584/5000 Iteration: 585 Train loss: 5.613453 Train acc: 0.786154\n",
      "Epoch: 589/5000 Iteration: 590 Train loss: 5.460165 Train acc: 0.788846\n",
      "Epoch: 589/5000 Iteration: 590 Validation loss: 5.562013 Validation acc: 0.720000\n",
      "Epoch: 594/5000 Iteration: 595 Train loss: 5.345656 Train acc: 0.796154\n",
      "Epoch: 599/5000 Iteration: 600 Train loss: 5.195096 Train acc: 0.799615\n",
      "Epoch: 599/5000 Iteration: 600 Validation loss: 5.308411 Validation acc: 0.700000\n",
      "Epoch: 604/5000 Iteration: 605 Train loss: 5.064851 Train acc: 0.803846\n",
      "Epoch: 609/5000 Iteration: 610 Train loss: 4.925664 Train acc: 0.821538\n",
      "Epoch: 609/5000 Iteration: 610 Validation loss: 5.042920 Validation acc: 0.720000\n",
      "Epoch: 614/5000 Iteration: 615 Train loss: 4.814409 Train acc: 0.815385\n",
      "Epoch: 619/5000 Iteration: 620 Train loss: 4.693987 Train acc: 0.820385\n",
      "Epoch: 619/5000 Iteration: 620 Validation loss: 4.819360 Validation acc: 0.730000\n",
      "Epoch: 624/5000 Iteration: 625 Train loss: 4.575705 Train acc: 0.824231\n",
      "Epoch: 629/5000 Iteration: 630 Train loss: 4.454984 Train acc: 0.839231\n",
      "Epoch: 629/5000 Iteration: 630 Validation loss: 4.595363 Validation acc: 0.730000\n",
      "Epoch: 634/5000 Iteration: 635 Train loss: 4.349641 Train acc: 0.833846\n",
      "Epoch: 639/5000 Iteration: 640 Train loss: 4.212035 Train acc: 0.851154\n",
      "Epoch: 639/5000 Iteration: 640 Validation loss: 4.378622 Validation acc: 0.730000\n",
      "Epoch: 644/5000 Iteration: 645 Train loss: 4.117821 Train acc: 0.853462\n",
      "Epoch: 649/5000 Iteration: 650 Train loss: 4.014146 Train acc: 0.855385\n",
      "Epoch: 649/5000 Iteration: 650 Validation loss: 4.162629 Validation acc: 0.780000\n",
      "Epoch: 654/5000 Iteration: 655 Train loss: 3.917786 Train acc: 0.852308\n",
      "Epoch: 659/5000 Iteration: 660 Train loss: 3.820750 Train acc: 0.866923\n",
      "Epoch: 659/5000 Iteration: 660 Validation loss: 3.970074 Validation acc: 0.740000\n",
      "Epoch: 664/5000 Iteration: 665 Train loss: 3.718977 Train acc: 0.865000\n",
      "Epoch: 669/5000 Iteration: 670 Train loss: 3.631013 Train acc: 0.868077\n",
      "Epoch: 669/5000 Iteration: 670 Validation loss: 3.809834 Validation acc: 0.750000\n",
      "Epoch: 674/5000 Iteration: 675 Train loss: 3.537826 Train acc: 0.873077\n",
      "Epoch: 679/5000 Iteration: 680 Train loss: 3.440210 Train acc: 0.878077\n",
      "Epoch: 679/5000 Iteration: 680 Validation loss: 3.612092 Validation acc: 0.770000\n",
      "Epoch: 684/5000 Iteration: 685 Train loss: 3.345499 Train acc: 0.884231\n",
      "Epoch: 689/5000 Iteration: 690 Train loss: 3.266320 Train acc: 0.885769\n",
      "Epoch: 689/5000 Iteration: 690 Validation loss: 3.446391 Validation acc: 0.780000\n",
      "Epoch: 694/5000 Iteration: 695 Train loss: 3.181994 Train acc: 0.886539\n",
      "Epoch: 699/5000 Iteration: 700 Train loss: 3.121069 Train acc: 0.880385\n",
      "Epoch: 699/5000 Iteration: 700 Validation loss: 3.308395 Validation acc: 0.740000\n",
      "Epoch: 704/5000 Iteration: 705 Train loss: 3.022415 Train acc: 0.896538\n",
      "Epoch: 709/5000 Iteration: 710 Train loss: 2.936908 Train acc: 0.903462\n",
      "Epoch: 709/5000 Iteration: 710 Validation loss: 3.148178 Validation acc: 0.790000\n",
      "Epoch: 714/5000 Iteration: 715 Train loss: 2.865011 Train acc: 0.904231\n",
      "Epoch: 719/5000 Iteration: 720 Train loss: 2.793425 Train acc: 0.897692\n",
      "Epoch: 719/5000 Iteration: 720 Validation loss: 3.028687 Validation acc: 0.770000\n",
      "Epoch: 724/5000 Iteration: 725 Train loss: 2.722830 Train acc: 0.913077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 729/5000 Iteration: 730 Train loss: 2.655426 Train acc: 0.903846\n",
      "Epoch: 729/5000 Iteration: 730 Validation loss: 2.861913 Validation acc: 0.810000\n",
      "Epoch: 734/5000 Iteration: 735 Train loss: 2.579524 Train acc: 0.917692\n",
      "Epoch: 739/5000 Iteration: 740 Train loss: 2.526285 Train acc: 0.908846\n",
      "Epoch: 739/5000 Iteration: 740 Validation loss: 2.756802 Validation acc: 0.780000\n",
      "Epoch: 744/5000 Iteration: 745 Train loss: 2.457534 Train acc: 0.916538\n",
      "Epoch: 749/5000 Iteration: 750 Train loss: 2.397440 Train acc: 0.919615\n",
      "Epoch: 749/5000 Iteration: 750 Validation loss: 2.622327 Validation acc: 0.810000\n",
      "Epoch: 754/5000 Iteration: 755 Train loss: 2.326274 Train acc: 0.923461\n",
      "Epoch: 759/5000 Iteration: 760 Train loss: 2.278409 Train acc: 0.919231\n",
      "Epoch: 759/5000 Iteration: 760 Validation loss: 2.509172 Validation acc: 0.790000\n",
      "Epoch: 764/5000 Iteration: 765 Train loss: 2.215590 Train acc: 0.925385\n",
      "Epoch: 769/5000 Iteration: 770 Train loss: 2.162705 Train acc: 0.927308\n",
      "Epoch: 769/5000 Iteration: 770 Validation loss: 2.411074 Validation acc: 0.820000\n",
      "Epoch: 774/5000 Iteration: 775 Train loss: 2.101296 Train acc: 0.932692\n",
      "Epoch: 779/5000 Iteration: 780 Train loss: 2.058533 Train acc: 0.923461\n",
      "Epoch: 779/5000 Iteration: 780 Validation loss: 2.310447 Validation acc: 0.790000\n",
      "Epoch: 784/5000 Iteration: 785 Train loss: 2.006269 Train acc: 0.935385\n",
      "Epoch: 789/5000 Iteration: 790 Train loss: 1.957730 Train acc: 0.927692\n",
      "Epoch: 789/5000 Iteration: 790 Validation loss: 2.208723 Validation acc: 0.820000\n",
      "Epoch: 794/5000 Iteration: 795 Train loss: 1.900964 Train acc: 0.933462\n",
      "Epoch: 799/5000 Iteration: 800 Train loss: 1.858246 Train acc: 0.933461\n",
      "Epoch: 799/5000 Iteration: 800 Validation loss: 2.109951 Validation acc: 0.810000\n",
      "Epoch: 804/5000 Iteration: 805 Train loss: 1.805758 Train acc: 0.942308\n",
      "Epoch: 809/5000 Iteration: 810 Train loss: 1.771303 Train acc: 0.935000\n",
      "Epoch: 809/5000 Iteration: 810 Validation loss: 2.016385 Validation acc: 0.790000\n",
      "Epoch: 814/5000 Iteration: 815 Train loss: 1.711813 Train acc: 0.943846\n",
      "Epoch: 819/5000 Iteration: 820 Train loss: 1.674722 Train acc: 0.944231\n",
      "Epoch: 819/5000 Iteration: 820 Validation loss: 1.931266 Validation acc: 0.780000\n",
      "Epoch: 824/5000 Iteration: 825 Train loss: 1.654891 Train acc: 0.935385\n",
      "Epoch: 829/5000 Iteration: 830 Train loss: 1.593075 Train acc: 0.946154\n",
      "Epoch: 829/5000 Iteration: 830 Validation loss: 1.868231 Validation acc: 0.800000\n",
      "Epoch: 834/5000 Iteration: 835 Train loss: 1.558941 Train acc: 0.946923\n",
      "Epoch: 839/5000 Iteration: 840 Train loss: 1.523230 Train acc: 0.941154\n",
      "Epoch: 839/5000 Iteration: 840 Validation loss: 1.792077 Validation acc: 0.810000\n",
      "Epoch: 844/5000 Iteration: 845 Train loss: 1.484306 Train acc: 0.940769\n",
      "Epoch: 849/5000 Iteration: 850 Train loss: 1.443014 Train acc: 0.950385\n",
      "Epoch: 849/5000 Iteration: 850 Validation loss: 1.699989 Validation acc: 0.860000\n",
      "Epoch: 854/5000 Iteration: 855 Train loss: 1.404994 Train acc: 0.954231\n",
      "Epoch: 859/5000 Iteration: 860 Train loss: 1.373177 Train acc: 0.956154\n",
      "Epoch: 859/5000 Iteration: 860 Validation loss: 1.658091 Validation acc: 0.830000\n",
      "Epoch: 864/5000 Iteration: 865 Train loss: 1.345291 Train acc: 0.946538\n",
      "Epoch: 869/5000 Iteration: 870 Train loss: 1.308815 Train acc: 0.952308\n",
      "Epoch: 869/5000 Iteration: 870 Validation loss: 1.578025 Validation acc: 0.830000\n",
      "Epoch: 874/5000 Iteration: 875 Train loss: 1.278967 Train acc: 0.956538\n",
      "Epoch: 879/5000 Iteration: 880 Train loss: 1.259641 Train acc: 0.946154\n",
      "Epoch: 879/5000 Iteration: 880 Validation loss: 1.509405 Validation acc: 0.830000\n",
      "Epoch: 884/5000 Iteration: 885 Train loss: 1.213037 Train acc: 0.956923\n",
      "Epoch: 889/5000 Iteration: 890 Train loss: 1.181996 Train acc: 0.954615\n",
      "Epoch: 889/5000 Iteration: 890 Validation loss: 1.468330 Validation acc: 0.840000\n",
      "Epoch: 894/5000 Iteration: 895 Train loss: 1.156317 Train acc: 0.954615\n",
      "Epoch: 899/5000 Iteration: 900 Train loss: 1.131400 Train acc: 0.961923\n",
      "Epoch: 899/5000 Iteration: 900 Validation loss: 1.400348 Validation acc: 0.870000\n",
      "Epoch: 904/5000 Iteration: 905 Train loss: 1.104385 Train acc: 0.957308\n",
      "Epoch: 909/5000 Iteration: 910 Train loss: 1.071550 Train acc: 0.965769\n",
      "Epoch: 909/5000 Iteration: 910 Validation loss: 1.343772 Validation acc: 0.840000\n",
      "Epoch: 914/5000 Iteration: 915 Train loss: 1.059770 Train acc: 0.956154\n",
      "Epoch: 919/5000 Iteration: 920 Train loss: 1.028718 Train acc: 0.962308\n",
      "Epoch: 919/5000 Iteration: 920 Validation loss: 1.307751 Validation acc: 0.840000\n",
      "Epoch: 924/5000 Iteration: 925 Train loss: 1.014093 Train acc: 0.952308\n",
      "Epoch: 929/5000 Iteration: 930 Train loss: 0.987061 Train acc: 0.959231\n",
      "Epoch: 929/5000 Iteration: 930 Validation loss: 1.247046 Validation acc: 0.840000\n",
      "Epoch: 934/5000 Iteration: 935 Train loss: 0.960043 Train acc: 0.961923\n",
      "Epoch: 939/5000 Iteration: 940 Train loss: 0.931735 Train acc: 0.964231\n",
      "Epoch: 939/5000 Iteration: 940 Validation loss: 1.227250 Validation acc: 0.870000\n",
      "Epoch: 944/5000 Iteration: 945 Train loss: 0.909374 Train acc: 0.968077\n",
      "Epoch: 949/5000 Iteration: 950 Train loss: 0.894861 Train acc: 0.965385\n",
      "Epoch: 949/5000 Iteration: 950 Validation loss: 1.182261 Validation acc: 0.830000\n",
      "Epoch: 954/5000 Iteration: 955 Train loss: 0.876283 Train acc: 0.966154\n",
      "Epoch: 959/5000 Iteration: 960 Train loss: 0.856213 Train acc: 0.963077\n",
      "Epoch: 959/5000 Iteration: 960 Validation loss: 1.141425 Validation acc: 0.810000\n",
      "Epoch: 964/5000 Iteration: 965 Train loss: 0.837706 Train acc: 0.967308\n",
      "Epoch: 969/5000 Iteration: 970 Train loss: 0.816447 Train acc: 0.965385\n",
      "Epoch: 969/5000 Iteration: 970 Validation loss: 1.103935 Validation acc: 0.840000\n",
      "Epoch: 974/5000 Iteration: 975 Train loss: 0.799948 Train acc: 0.967692\n",
      "Epoch: 979/5000 Iteration: 980 Train loss: 0.785453 Train acc: 0.963462\n",
      "Epoch: 979/5000 Iteration: 980 Validation loss: 1.082057 Validation acc: 0.830000\n",
      "Epoch: 984/5000 Iteration: 985 Train loss: 0.762574 Train acc: 0.969615\n",
      "Epoch: 989/5000 Iteration: 990 Train loss: 0.748835 Train acc: 0.966538\n",
      "Epoch: 989/5000 Iteration: 990 Validation loss: 1.036450 Validation acc: 0.810000\n",
      "Epoch: 994/5000 Iteration: 995 Train loss: 0.731924 Train acc: 0.966538\n",
      "Epoch: 999/5000 Iteration: 1000 Train loss: 0.723194 Train acc: 0.965769\n",
      "Epoch: 999/5000 Iteration: 1000 Validation loss: 1.008264 Validation acc: 0.840000\n",
      "Epoch: 1004/5000 Iteration: 1005 Train loss: 0.705281 Train acc: 0.963461\n",
      "Epoch: 1009/5000 Iteration: 1010 Train loss: 0.681562 Train acc: 0.969231\n",
      "Epoch: 1009/5000 Iteration: 1010 Validation loss: 0.984151 Validation acc: 0.820000\n",
      "Epoch: 1014/5000 Iteration: 1015 Train loss: 0.677756 Train acc: 0.968461\n",
      "Epoch: 1019/5000 Iteration: 1020 Train loss: 0.657284 Train acc: 0.970385\n",
      "Epoch: 1019/5000 Iteration: 1020 Validation loss: 0.933064 Validation acc: 0.800000\n",
      "Epoch: 1024/5000 Iteration: 1025 Train loss: 0.643633 Train acc: 0.969231\n",
      "Epoch: 1029/5000 Iteration: 1030 Train loss: 0.631876 Train acc: 0.969231\n",
      "Epoch: 1029/5000 Iteration: 1030 Validation loss: 0.927233 Validation acc: 0.840000\n",
      "Epoch: 1034/5000 Iteration: 1035 Train loss: 0.625174 Train acc: 0.965769\n",
      "Epoch: 1039/5000 Iteration: 1040 Train loss: 0.610901 Train acc: 0.967692\n",
      "Epoch: 1039/5000 Iteration: 1040 Validation loss: 0.893449 Validation acc: 0.870000\n",
      "Epoch: 1044/5000 Iteration: 1045 Train loss: 0.590881 Train acc: 0.970000\n",
      "Epoch: 1049/5000 Iteration: 1050 Train loss: 0.585176 Train acc: 0.969231\n",
      "Epoch: 1049/5000 Iteration: 1050 Validation loss: 0.875703 Validation acc: 0.860000\n",
      "Epoch: 1054/5000 Iteration: 1055 Train loss: 0.563780 Train acc: 0.973077\n",
      "Epoch: 1059/5000 Iteration: 1060 Train loss: 0.563223 Train acc: 0.968846\n",
      "Epoch: 1059/5000 Iteration: 1060 Validation loss: 0.866124 Validation acc: 0.840000\n",
      "Epoch: 1064/5000 Iteration: 1065 Train loss: 0.540003 Train acc: 0.976538\n",
      "Epoch: 1069/5000 Iteration: 1070 Train loss: 0.540184 Train acc: 0.972308\n",
      "Epoch: 1069/5000 Iteration: 1070 Validation loss: 0.851514 Validation acc: 0.830000\n",
      "Epoch: 1074/5000 Iteration: 1075 Train loss: 0.525896 Train acc: 0.973077\n",
      "Epoch: 1079/5000 Iteration: 1080 Train loss: 0.519388 Train acc: 0.971923\n",
      "Epoch: 1079/5000 Iteration: 1080 Validation loss: 0.825951 Validation acc: 0.810000\n",
      "Epoch: 1084/5000 Iteration: 1085 Train loss: 0.507731 Train acc: 0.973077\n",
      "Epoch: 1089/5000 Iteration: 1090 Train loss: 0.497487 Train acc: 0.976923\n",
      "Epoch: 1089/5000 Iteration: 1090 Validation loss: 0.803590 Validation acc: 0.840000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1094/5000 Iteration: 1095 Train loss: 0.494061 Train acc: 0.969615\n",
      "Epoch: 1099/5000 Iteration: 1100 Train loss: 0.480158 Train acc: 0.972308\n",
      "Epoch: 1099/5000 Iteration: 1100 Validation loss: 0.799798 Validation acc: 0.810000\n",
      "Epoch: 1104/5000 Iteration: 1105 Train loss: 0.477723 Train acc: 0.969615\n",
      "Epoch: 1109/5000 Iteration: 1110 Train loss: 0.470764 Train acc: 0.971154\n",
      "Epoch: 1109/5000 Iteration: 1110 Validation loss: 0.772740 Validation acc: 0.830000\n",
      "Epoch: 1114/5000 Iteration: 1115 Train loss: 0.450417 Train acc: 0.973077\n",
      "Epoch: 1119/5000 Iteration: 1120 Train loss: 0.446624 Train acc: 0.973461\n",
      "Epoch: 1119/5000 Iteration: 1120 Validation loss: 0.769125 Validation acc: 0.800000\n",
      "Epoch: 1124/5000 Iteration: 1125 Train loss: 0.440188 Train acc: 0.976538\n",
      "Epoch: 1129/5000 Iteration: 1130 Train loss: 0.435944 Train acc: 0.973846\n",
      "Epoch: 1129/5000 Iteration: 1130 Validation loss: 0.742900 Validation acc: 0.840000\n",
      "Epoch: 1134/5000 Iteration: 1135 Train loss: 0.425213 Train acc: 0.975000\n",
      "Epoch: 1139/5000 Iteration: 1140 Train loss: 0.426459 Train acc: 0.968077\n",
      "Epoch: 1139/5000 Iteration: 1140 Validation loss: 0.740297 Validation acc: 0.830000\n",
      "Epoch: 1144/5000 Iteration: 1145 Train loss: 0.413129 Train acc: 0.971923\n",
      "Epoch: 1149/5000 Iteration: 1150 Train loss: 0.408683 Train acc: 0.971923\n",
      "Epoch: 1149/5000 Iteration: 1150 Validation loss: 0.735797 Validation acc: 0.810000\n",
      "Epoch: 1154/5000 Iteration: 1155 Train loss: 0.404210 Train acc: 0.970385\n",
      "Epoch: 1159/5000 Iteration: 1160 Train loss: 0.397264 Train acc: 0.971923\n",
      "Epoch: 1159/5000 Iteration: 1160 Validation loss: 0.706203 Validation acc: 0.840000\n",
      "Epoch: 1164/5000 Iteration: 1165 Train loss: 0.396239 Train acc: 0.970000\n",
      "Epoch: 1169/5000 Iteration: 1170 Train loss: 0.389082 Train acc: 0.971538\n",
      "Epoch: 1169/5000 Iteration: 1170 Validation loss: 0.713527 Validation acc: 0.850000\n",
      "Epoch: 1174/5000 Iteration: 1175 Train loss: 0.373453 Train acc: 0.975769\n",
      "Epoch: 1179/5000 Iteration: 1180 Train loss: 0.381225 Train acc: 0.969615\n",
      "Epoch: 1179/5000 Iteration: 1180 Validation loss: 0.704789 Validation acc: 0.820000\n",
      "Epoch: 1184/5000 Iteration: 1185 Train loss: 0.370709 Train acc: 0.974231\n",
      "Epoch: 1189/5000 Iteration: 1190 Train loss: 0.362306 Train acc: 0.975769\n",
      "Epoch: 1189/5000 Iteration: 1190 Validation loss: 0.686629 Validation acc: 0.800000\n",
      "Epoch: 1194/5000 Iteration: 1195 Train loss: 0.358920 Train acc: 0.971923\n",
      "Epoch: 1199/5000 Iteration: 1200 Train loss: 0.350939 Train acc: 0.976923\n",
      "Epoch: 1199/5000 Iteration: 1200 Validation loss: 0.684569 Validation acc: 0.830000\n",
      "Epoch: 1204/5000 Iteration: 1205 Train loss: 0.352690 Train acc: 0.974231\n",
      "Epoch: 1209/5000 Iteration: 1210 Train loss: 0.338807 Train acc: 0.977308\n",
      "Epoch: 1209/5000 Iteration: 1210 Validation loss: 0.674264 Validation acc: 0.820000\n",
      "Epoch: 1214/5000 Iteration: 1215 Train loss: 0.333272 Train acc: 0.979615\n",
      "Epoch: 1219/5000 Iteration: 1220 Train loss: 0.333493 Train acc: 0.978077\n",
      "Epoch: 1219/5000 Iteration: 1220 Validation loss: 0.661991 Validation acc: 0.820000\n",
      "Epoch: 1224/5000 Iteration: 1225 Train loss: 0.321818 Train acc: 0.980384\n",
      "Epoch: 1229/5000 Iteration: 1230 Train loss: 0.323155 Train acc: 0.978846\n",
      "Epoch: 1229/5000 Iteration: 1230 Validation loss: 0.648928 Validation acc: 0.840000\n",
      "Epoch: 1234/5000 Iteration: 1235 Train loss: 0.320578 Train acc: 0.975385\n",
      "Epoch: 1239/5000 Iteration: 1240 Train loss: 0.318626 Train acc: 0.972692\n",
      "Epoch: 1239/5000 Iteration: 1240 Validation loss: 0.652038 Validation acc: 0.810000\n",
      "Epoch: 1244/5000 Iteration: 1245 Train loss: 0.311698 Train acc: 0.976538\n",
      "Epoch: 1249/5000 Iteration: 1250 Train loss: 0.302061 Train acc: 0.984231\n",
      "Epoch: 1249/5000 Iteration: 1250 Validation loss: 0.642751 Validation acc: 0.840000\n",
      "Epoch: 1254/5000 Iteration: 1255 Train loss: 0.304674 Train acc: 0.978846\n",
      "Epoch: 1259/5000 Iteration: 1260 Train loss: 0.302848 Train acc: 0.976923\n",
      "Epoch: 1259/5000 Iteration: 1260 Validation loss: 0.643806 Validation acc: 0.810000\n",
      "Epoch: 1264/5000 Iteration: 1265 Train loss: 0.292438 Train acc: 0.981538\n",
      "Epoch: 1269/5000 Iteration: 1270 Train loss: 0.291710 Train acc: 0.981923\n",
      "Epoch: 1269/5000 Iteration: 1270 Validation loss: 0.628288 Validation acc: 0.840000\n",
      "Epoch: 1274/5000 Iteration: 1275 Train loss: 0.291626 Train acc: 0.976923\n",
      "Epoch: 1279/5000 Iteration: 1280 Train loss: 0.289258 Train acc: 0.977692\n",
      "Epoch: 1279/5000 Iteration: 1280 Validation loss: 0.631581 Validation acc: 0.820000\n",
      "Epoch: 1284/5000 Iteration: 1285 Train loss: 0.285673 Train acc: 0.979231\n",
      "Epoch: 1289/5000 Iteration: 1290 Train loss: 0.281872 Train acc: 0.979231\n",
      "Epoch: 1289/5000 Iteration: 1290 Validation loss: 0.619584 Validation acc: 0.800000\n",
      "Epoch: 1294/5000 Iteration: 1295 Train loss: 0.280357 Train acc: 0.978077\n",
      "Epoch: 1299/5000 Iteration: 1300 Train loss: 0.275573 Train acc: 0.980384\n",
      "Epoch: 1299/5000 Iteration: 1300 Validation loss: 0.622320 Validation acc: 0.840000\n",
      "Epoch: 1304/5000 Iteration: 1305 Train loss: 0.271967 Train acc: 0.981923\n",
      "Epoch: 1309/5000 Iteration: 1310 Train loss: 0.270142 Train acc: 0.978077\n",
      "Epoch: 1309/5000 Iteration: 1310 Validation loss: 0.618389 Validation acc: 0.810000\n",
      "Epoch: 1314/5000 Iteration: 1315 Train loss: 0.272026 Train acc: 0.978462\n",
      "Epoch: 1319/5000 Iteration: 1320 Train loss: 0.266556 Train acc: 0.978077\n",
      "Epoch: 1319/5000 Iteration: 1320 Validation loss: 0.607931 Validation acc: 0.810000\n",
      "Epoch: 1324/5000 Iteration: 1325 Train loss: 0.266508 Train acc: 0.978461\n",
      "Epoch: 1329/5000 Iteration: 1330 Train loss: 0.265513 Train acc: 0.973462\n",
      "Epoch: 1329/5000 Iteration: 1330 Validation loss: 0.605730 Validation acc: 0.800000\n",
      "Epoch: 1334/5000 Iteration: 1335 Train loss: 0.256860 Train acc: 0.980769\n",
      "Epoch: 1339/5000 Iteration: 1340 Train loss: 0.256479 Train acc: 0.983846\n",
      "Epoch: 1339/5000 Iteration: 1340 Validation loss: 0.592819 Validation acc: 0.810000\n",
      "Epoch: 1344/5000 Iteration: 1345 Train loss: 0.252464 Train acc: 0.981923\n",
      "Epoch: 1349/5000 Iteration: 1350 Train loss: 0.257744 Train acc: 0.976154\n",
      "Epoch: 1349/5000 Iteration: 1350 Validation loss: 0.603220 Validation acc: 0.810000\n",
      "Epoch: 1354/5000 Iteration: 1355 Train loss: 0.252656 Train acc: 0.977308\n",
      "Epoch: 1359/5000 Iteration: 1360 Train loss: 0.255878 Train acc: 0.978461\n",
      "Epoch: 1359/5000 Iteration: 1360 Validation loss: 0.593303 Validation acc: 0.860000\n",
      "Epoch: 1364/5000 Iteration: 1365 Train loss: 0.245931 Train acc: 0.982692\n",
      "Epoch: 1369/5000 Iteration: 1370 Train loss: 0.237539 Train acc: 0.983461\n",
      "Epoch: 1369/5000 Iteration: 1370 Validation loss: 0.585737 Validation acc: 0.810000\n",
      "Epoch: 1374/5000 Iteration: 1375 Train loss: 0.244551 Train acc: 0.979615\n",
      "Epoch: 1379/5000 Iteration: 1380 Train loss: 0.247243 Train acc: 0.977692\n",
      "Epoch: 1379/5000 Iteration: 1380 Validation loss: 0.590421 Validation acc: 0.810000\n",
      "Epoch: 1384/5000 Iteration: 1385 Train loss: 0.243752 Train acc: 0.980000\n",
      "Epoch: 1389/5000 Iteration: 1390 Train loss: 0.245728 Train acc: 0.977692\n",
      "Epoch: 1389/5000 Iteration: 1390 Validation loss: 0.592772 Validation acc: 0.860000\n",
      "Epoch: 1394/5000 Iteration: 1395 Train loss: 0.236655 Train acc: 0.980000\n",
      "Epoch: 1399/5000 Iteration: 1400 Train loss: 0.240429 Train acc: 0.978462\n",
      "Epoch: 1399/5000 Iteration: 1400 Validation loss: 0.583823 Validation acc: 0.840000\n",
      "Epoch: 1404/5000 Iteration: 1405 Train loss: 0.237644 Train acc: 0.978846\n",
      "Epoch: 1409/5000 Iteration: 1410 Train loss: 0.229862 Train acc: 0.983077\n",
      "Epoch: 1409/5000 Iteration: 1410 Validation loss: 0.575720 Validation acc: 0.800000\n",
      "Epoch: 1414/5000 Iteration: 1415 Train loss: 0.223932 Train acc: 0.985385\n",
      "Epoch: 1419/5000 Iteration: 1420 Train loss: 0.225209 Train acc: 0.983077\n",
      "Epoch: 1419/5000 Iteration: 1420 Validation loss: 0.555574 Validation acc: 0.850000\n",
      "Epoch: 1424/5000 Iteration: 1425 Train loss: 0.228076 Train acc: 0.980000\n",
      "Epoch: 1429/5000 Iteration: 1430 Train loss: 0.228146 Train acc: 0.981154\n",
      "Epoch: 1429/5000 Iteration: 1430 Validation loss: 0.582637 Validation acc: 0.840000\n",
      "Epoch: 1434/5000 Iteration: 1435 Train loss: 0.224473 Train acc: 0.982692\n",
      "Epoch: 1439/5000 Iteration: 1440 Train loss: 0.222620 Train acc: 0.979231\n",
      "Epoch: 1439/5000 Iteration: 1440 Validation loss: 0.586211 Validation acc: 0.800000\n",
      "Epoch: 1444/5000 Iteration: 1445 Train loss: 0.224337 Train acc: 0.980769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1449/5000 Iteration: 1450 Train loss: 0.214928 Train acc: 0.985769\n",
      "Epoch: 1449/5000 Iteration: 1450 Validation loss: 0.579913 Validation acc: 0.820000\n",
      "Epoch: 1454/5000 Iteration: 1455 Train loss: 0.221292 Train acc: 0.981923\n",
      "Epoch: 1459/5000 Iteration: 1460 Train loss: 0.219915 Train acc: 0.982692\n",
      "Epoch: 1459/5000 Iteration: 1460 Validation loss: 0.560472 Validation acc: 0.820000\n",
      "Epoch: 1464/5000 Iteration: 1465 Train loss: 0.224965 Train acc: 0.977692\n",
      "Epoch: 1469/5000 Iteration: 1470 Train loss: 0.215497 Train acc: 0.982308\n",
      "Epoch: 1469/5000 Iteration: 1470 Validation loss: 0.573641 Validation acc: 0.810000\n",
      "Epoch: 1474/5000 Iteration: 1475 Train loss: 0.215477 Train acc: 0.984231\n",
      "Epoch: 1479/5000 Iteration: 1480 Train loss: 0.215637 Train acc: 0.982308\n",
      "Epoch: 1479/5000 Iteration: 1480 Validation loss: 0.559154 Validation acc: 0.840000\n",
      "Epoch: 1484/5000 Iteration: 1485 Train loss: 0.216012 Train acc: 0.978846\n",
      "Epoch: 1489/5000 Iteration: 1490 Train loss: 0.213863 Train acc: 0.980385\n",
      "Epoch: 1489/5000 Iteration: 1490 Validation loss: 0.583910 Validation acc: 0.810000\n",
      "Epoch: 1494/5000 Iteration: 1495 Train loss: 0.212909 Train acc: 0.983461\n",
      "Epoch: 1499/5000 Iteration: 1500 Train loss: 0.214242 Train acc: 0.981154\n",
      "Epoch: 1499/5000 Iteration: 1500 Validation loss: 0.575454 Validation acc: 0.820000\n",
      "Epoch: 1504/5000 Iteration: 1505 Train loss: 0.217743 Train acc: 0.978846\n",
      "Epoch: 1509/5000 Iteration: 1510 Train loss: 0.215240 Train acc: 0.980385\n",
      "Epoch: 1509/5000 Iteration: 1510 Validation loss: 0.574555 Validation acc: 0.800000\n",
      "Epoch: 1514/5000 Iteration: 1515 Train loss: 0.207431 Train acc: 0.982692\n",
      "Epoch: 1519/5000 Iteration: 1520 Train loss: 0.207796 Train acc: 0.983461\n",
      "Epoch: 1519/5000 Iteration: 1520 Validation loss: 0.558782 Validation acc: 0.810000\n",
      "Epoch: 1524/5000 Iteration: 1525 Train loss: 0.211338 Train acc: 0.979615\n",
      "Epoch: 1529/5000 Iteration: 1530 Train loss: 0.204645 Train acc: 0.982692\n",
      "Epoch: 1529/5000 Iteration: 1530 Validation loss: 0.540281 Validation acc: 0.810000\n",
      "Epoch: 1534/5000 Iteration: 1535 Train loss: 0.202633 Train acc: 0.985769\n",
      "Epoch: 1539/5000 Iteration: 1540 Train loss: 0.206774 Train acc: 0.981154\n",
      "Epoch: 1539/5000 Iteration: 1540 Validation loss: 0.553083 Validation acc: 0.810000\n",
      "Epoch: 1544/5000 Iteration: 1545 Train loss: 0.201948 Train acc: 0.983846\n",
      "Epoch: 1549/5000 Iteration: 1550 Train loss: 0.203089 Train acc: 0.982692\n",
      "Epoch: 1549/5000 Iteration: 1550 Validation loss: 0.569723 Validation acc: 0.810000\n",
      "Epoch: 1554/5000 Iteration: 1555 Train loss: 0.204053 Train acc: 0.980769\n",
      "Epoch: 1559/5000 Iteration: 1560 Train loss: 0.206981 Train acc: 0.978077\n",
      "Epoch: 1559/5000 Iteration: 1560 Validation loss: 0.532819 Validation acc: 0.840000\n",
      "Epoch: 1564/5000 Iteration: 1565 Train loss: 0.203833 Train acc: 0.981923\n",
      "Epoch: 1569/5000 Iteration: 1570 Train loss: 0.200095 Train acc: 0.980769\n",
      "Epoch: 1569/5000 Iteration: 1570 Validation loss: 0.536434 Validation acc: 0.830000\n",
      "Epoch: 1574/5000 Iteration: 1575 Train loss: 0.196517 Train acc: 0.985769\n",
      "Epoch: 1579/5000 Iteration: 1580 Train loss: 0.201804 Train acc: 0.981154\n",
      "Epoch: 1579/5000 Iteration: 1580 Validation loss: 0.544686 Validation acc: 0.810000\n",
      "Epoch: 1584/5000 Iteration: 1585 Train loss: 0.203408 Train acc: 0.981538\n",
      "Epoch: 1589/5000 Iteration: 1590 Train loss: 0.199275 Train acc: 0.982308\n",
      "Epoch: 1589/5000 Iteration: 1590 Validation loss: 0.563486 Validation acc: 0.860000\n",
      "Epoch: 1594/5000 Iteration: 1595 Train loss: 0.198830 Train acc: 0.981538\n",
      "Epoch: 1599/5000 Iteration: 1600 Train loss: 0.196748 Train acc: 0.984615\n",
      "Epoch: 1599/5000 Iteration: 1600 Validation loss: 0.587321 Validation acc: 0.800000\n",
      "Epoch: 1604/5000 Iteration: 1605 Train loss: 0.195940 Train acc: 0.982692\n",
      "Epoch: 1609/5000 Iteration: 1610 Train loss: 0.198195 Train acc: 0.983461\n",
      "Epoch: 1609/5000 Iteration: 1610 Validation loss: 0.551696 Validation acc: 0.830000\n",
      "Epoch: 1614/5000 Iteration: 1615 Train loss: 0.198002 Train acc: 0.980000\n",
      "Epoch: 1619/5000 Iteration: 1620 Train loss: 0.191328 Train acc: 0.983846\n",
      "Epoch: 1619/5000 Iteration: 1620 Validation loss: 0.551271 Validation acc: 0.840000\n",
      "Epoch: 1624/5000 Iteration: 1625 Train loss: 0.194208 Train acc: 0.983461\n",
      "Epoch: 1629/5000 Iteration: 1630 Train loss: 0.192286 Train acc: 0.984231\n",
      "Epoch: 1629/5000 Iteration: 1630 Validation loss: 0.565048 Validation acc: 0.830000\n",
      "Epoch: 1634/5000 Iteration: 1635 Train loss: 0.196534 Train acc: 0.980769\n",
      "Epoch: 1639/5000 Iteration: 1640 Train loss: 0.191864 Train acc: 0.983461\n",
      "Epoch: 1639/5000 Iteration: 1640 Validation loss: 0.564791 Validation acc: 0.830000\n",
      "Epoch: 1644/5000 Iteration: 1645 Train loss: 0.189909 Train acc: 0.985769\n",
      "Epoch: 1649/5000 Iteration: 1650 Train loss: 0.194275 Train acc: 0.981538\n",
      "Epoch: 1649/5000 Iteration: 1650 Validation loss: 0.543319 Validation acc: 0.810000\n",
      "Epoch: 1654/5000 Iteration: 1655 Train loss: 0.187649 Train acc: 0.983461\n",
      "Epoch: 1659/5000 Iteration: 1660 Train loss: 0.188917 Train acc: 0.986538\n",
      "Epoch: 1659/5000 Iteration: 1660 Validation loss: 0.557379 Validation acc: 0.810000\n",
      "Epoch: 1664/5000 Iteration: 1665 Train loss: 0.191450 Train acc: 0.982692\n",
      "Epoch: 1669/5000 Iteration: 1670 Train loss: 0.190819 Train acc: 0.983846\n",
      "Epoch: 1669/5000 Iteration: 1670 Validation loss: 0.539350 Validation acc: 0.810000\n",
      "Epoch: 1674/5000 Iteration: 1675 Train loss: 0.195161 Train acc: 0.980769\n",
      "Epoch: 1679/5000 Iteration: 1680 Train loss: 0.186553 Train acc: 0.986538\n",
      "Epoch: 1679/5000 Iteration: 1680 Validation loss: 0.564117 Validation acc: 0.810000\n",
      "Epoch: 1684/5000 Iteration: 1685 Train loss: 0.189821 Train acc: 0.979615\n",
      "Epoch: 1689/5000 Iteration: 1690 Train loss: 0.187806 Train acc: 0.983077\n",
      "Epoch: 1689/5000 Iteration: 1690 Validation loss: 0.540206 Validation acc: 0.810000\n",
      "Epoch: 1694/5000 Iteration: 1695 Train loss: 0.186751 Train acc: 0.984231\n",
      "Epoch: 1699/5000 Iteration: 1700 Train loss: 0.187994 Train acc: 0.981923\n",
      "Epoch: 1699/5000 Iteration: 1700 Validation loss: 0.539907 Validation acc: 0.810000\n",
      "Epoch: 1704/5000 Iteration: 1705 Train loss: 0.190371 Train acc: 0.982692\n",
      "Epoch: 1709/5000 Iteration: 1710 Train loss: 0.191653 Train acc: 0.980769\n",
      "Epoch: 1709/5000 Iteration: 1710 Validation loss: 0.548765 Validation acc: 0.810000\n",
      "Epoch: 1714/5000 Iteration: 1715 Train loss: 0.185084 Train acc: 0.982692\n",
      "Epoch: 1719/5000 Iteration: 1720 Train loss: 0.187052 Train acc: 0.982692\n",
      "Epoch: 1719/5000 Iteration: 1720 Validation loss: 0.547897 Validation acc: 0.800000\n",
      "Epoch: 1724/5000 Iteration: 1725 Train loss: 0.186076 Train acc: 0.983461\n",
      "Epoch: 1729/5000 Iteration: 1730 Train loss: 0.190623 Train acc: 0.981538\n",
      "Epoch: 1729/5000 Iteration: 1730 Validation loss: 0.547885 Validation acc: 0.810000\n",
      "Epoch: 1734/5000 Iteration: 1735 Train loss: 0.184225 Train acc: 0.983077\n",
      "Epoch: 1739/5000 Iteration: 1740 Train loss: 0.187002 Train acc: 0.981923\n",
      "Epoch: 1739/5000 Iteration: 1740 Validation loss: 0.552806 Validation acc: 0.810000\n",
      "Epoch: 1744/5000 Iteration: 1745 Train loss: 0.189328 Train acc: 0.982308\n",
      "Epoch: 1749/5000 Iteration: 1750 Train loss: 0.181489 Train acc: 0.984615\n",
      "Epoch: 1749/5000 Iteration: 1750 Validation loss: 0.555195 Validation acc: 0.810000\n",
      "Epoch: 1754/5000 Iteration: 1755 Train loss: 0.180387 Train acc: 0.986538\n",
      "Epoch: 1759/5000 Iteration: 1760 Train loss: 0.183545 Train acc: 0.982692\n",
      "Epoch: 1759/5000 Iteration: 1760 Validation loss: 0.548670 Validation acc: 0.860000\n",
      "Epoch: 1764/5000 Iteration: 1765 Train loss: 0.182438 Train acc: 0.983077\n",
      "Epoch: 1769/5000 Iteration: 1770 Train loss: 0.180481 Train acc: 0.986923\n",
      "Epoch: 1769/5000 Iteration: 1770 Validation loss: 0.540763 Validation acc: 0.810000\n",
      "Epoch: 1774/5000 Iteration: 1775 Train loss: 0.182174 Train acc: 0.984231\n",
      "Epoch: 1779/5000 Iteration: 1780 Train loss: 0.179526 Train acc: 0.986154\n",
      "Epoch: 1779/5000 Iteration: 1780 Validation loss: 0.550099 Validation acc: 0.810000\n",
      "Epoch: 1784/5000 Iteration: 1785 Train loss: 0.180071 Train acc: 0.982692\n",
      "Epoch: 1789/5000 Iteration: 1790 Train loss: 0.182604 Train acc: 0.981923\n",
      "Epoch: 1789/5000 Iteration: 1790 Validation loss: 0.548918 Validation acc: 0.860000\n",
      "Epoch: 1794/5000 Iteration: 1795 Train loss: 0.185338 Train acc: 0.983461\n",
      "Epoch: 1799/5000 Iteration: 1800 Train loss: 0.177420 Train acc: 0.984615\n",
      "Epoch: 1799/5000 Iteration: 1800 Validation loss: 0.555747 Validation acc: 0.810000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1804/5000 Iteration: 1805 Train loss: 0.178384 Train acc: 0.985384\n",
      "Epoch: 1809/5000 Iteration: 1810 Train loss: 0.175600 Train acc: 0.985385\n",
      "Epoch: 1809/5000 Iteration: 1810 Validation loss: 0.564969 Validation acc: 0.800000\n",
      "Epoch: 1814/5000 Iteration: 1815 Train loss: 0.177346 Train acc: 0.984231\n",
      "Epoch: 1819/5000 Iteration: 1820 Train loss: 0.177068 Train acc: 0.986538\n",
      "Epoch: 1819/5000 Iteration: 1820 Validation loss: 0.561570 Validation acc: 0.840000\n",
      "Epoch: 1824/5000 Iteration: 1825 Train loss: 0.178048 Train acc: 0.985769\n",
      "Epoch: 1829/5000 Iteration: 1830 Train loss: 0.176989 Train acc: 0.983077\n",
      "Epoch: 1829/5000 Iteration: 1830 Validation loss: 0.548380 Validation acc: 0.840000\n",
      "Epoch: 1834/5000 Iteration: 1835 Train loss: 0.176202 Train acc: 0.985385\n",
      "Epoch: 1839/5000 Iteration: 1840 Train loss: 0.173331 Train acc: 0.987692\n",
      "Epoch: 1839/5000 Iteration: 1840 Validation loss: 0.554946 Validation acc: 0.800000\n",
      "Epoch: 1844/5000 Iteration: 1845 Train loss: 0.180735 Train acc: 0.983846\n",
      "Epoch: 1849/5000 Iteration: 1850 Train loss: 0.185568 Train acc: 0.980385\n",
      "Epoch: 1849/5000 Iteration: 1850 Validation loss: 0.552080 Validation acc: 0.840000\n",
      "Epoch: 1854/5000 Iteration: 1855 Train loss: 0.179354 Train acc: 0.982308\n",
      "Epoch: 1859/5000 Iteration: 1860 Train loss: 0.174656 Train acc: 0.986923\n",
      "Epoch: 1859/5000 Iteration: 1860 Validation loss: 0.540143 Validation acc: 0.830000\n",
      "Epoch: 1864/5000 Iteration: 1865 Train loss: 0.180395 Train acc: 0.984615\n",
      "Epoch: 1869/5000 Iteration: 1870 Train loss: 0.176937 Train acc: 0.985000\n",
      "Epoch: 1869/5000 Iteration: 1870 Validation loss: 0.579834 Validation acc: 0.800000\n",
      "Epoch: 1874/5000 Iteration: 1875 Train loss: 0.178027 Train acc: 0.985000\n",
      "Epoch: 1879/5000 Iteration: 1880 Train loss: 0.182525 Train acc: 0.982308\n",
      "Epoch: 1879/5000 Iteration: 1880 Validation loss: 0.553757 Validation acc: 0.790000\n",
      "Epoch: 1884/5000 Iteration: 1885 Train loss: 0.174635 Train acc: 0.985769\n",
      "Epoch: 1889/5000 Iteration: 1890 Train loss: 0.176956 Train acc: 0.983846\n",
      "Epoch: 1889/5000 Iteration: 1890 Validation loss: 0.523985 Validation acc: 0.810000\n",
      "Epoch: 1894/5000 Iteration: 1895 Train loss: 0.175704 Train acc: 0.983077\n",
      "Epoch: 1899/5000 Iteration: 1900 Train loss: 0.174854 Train acc: 0.983461\n",
      "Epoch: 1899/5000 Iteration: 1900 Validation loss: 0.568537 Validation acc: 0.790000\n",
      "Epoch: 1904/5000 Iteration: 1905 Train loss: 0.177085 Train acc: 0.985000\n",
      "Epoch: 1909/5000 Iteration: 1910 Train loss: 0.172433 Train acc: 0.987692\n",
      "Epoch: 1909/5000 Iteration: 1910 Validation loss: 0.562836 Validation acc: 0.810000\n",
      "Epoch: 1914/5000 Iteration: 1915 Train loss: 0.172693 Train acc: 0.984615\n",
      "Epoch: 1919/5000 Iteration: 1920 Train loss: 0.176294 Train acc: 0.983461\n",
      "Epoch: 1919/5000 Iteration: 1920 Validation loss: 0.553609 Validation acc: 0.840000\n",
      "Epoch: 1924/5000 Iteration: 1925 Train loss: 0.171077 Train acc: 0.986923\n",
      "Epoch: 1929/5000 Iteration: 1930 Train loss: 0.171520 Train acc: 0.985000\n",
      "Epoch: 1929/5000 Iteration: 1930 Validation loss: 0.573723 Validation acc: 0.800000\n",
      "Epoch: 1934/5000 Iteration: 1935 Train loss: 0.170830 Train acc: 0.985385\n",
      "Epoch: 1939/5000 Iteration: 1940 Train loss: 0.167321 Train acc: 0.986923\n",
      "Epoch: 1939/5000 Iteration: 1940 Validation loss: 0.533878 Validation acc: 0.880000\n",
      "Epoch: 1944/5000 Iteration: 1945 Train loss: 0.170487 Train acc: 0.987692\n",
      "Epoch: 1949/5000 Iteration: 1950 Train loss: 0.167555 Train acc: 0.988462\n",
      "Epoch: 1949/5000 Iteration: 1950 Validation loss: 0.554160 Validation acc: 0.810000\n",
      "Epoch: 1954/5000 Iteration: 1955 Train loss: 0.171535 Train acc: 0.983846\n",
      "Epoch: 1959/5000 Iteration: 1960 Train loss: 0.174480 Train acc: 0.983461\n",
      "Epoch: 1959/5000 Iteration: 1960 Validation loss: 0.543871 Validation acc: 0.830000\n",
      "Epoch: 1964/5000 Iteration: 1965 Train loss: 0.172449 Train acc: 0.984615\n",
      "Epoch: 1969/5000 Iteration: 1970 Train loss: 0.173085 Train acc: 0.985769\n",
      "Epoch: 1969/5000 Iteration: 1970 Validation loss: 0.567228 Validation acc: 0.800000\n",
      "Epoch: 1974/5000 Iteration: 1975 Train loss: 0.171431 Train acc: 0.986154\n",
      "Epoch: 1979/5000 Iteration: 1980 Train loss: 0.170377 Train acc: 0.984615\n",
      "Epoch: 1979/5000 Iteration: 1980 Validation loss: 0.549238 Validation acc: 0.810000\n",
      "Epoch: 1984/5000 Iteration: 1985 Train loss: 0.167107 Train acc: 0.989231\n",
      "Epoch: 1989/5000 Iteration: 1990 Train loss: 0.167152 Train acc: 0.986538\n",
      "Epoch: 1989/5000 Iteration: 1990 Validation loss: 0.557307 Validation acc: 0.810000\n",
      "Epoch: 1994/5000 Iteration: 1995 Train loss: 0.168169 Train acc: 0.985769\n",
      "Epoch: 1999/5000 Iteration: 2000 Train loss: 0.169567 Train acc: 0.985000\n",
      "Epoch: 1999/5000 Iteration: 2000 Validation loss: 0.551872 Validation acc: 0.800000\n",
      "Epoch: 2004/5000 Iteration: 2005 Train loss: 0.169738 Train acc: 0.985769\n",
      "Epoch: 2009/5000 Iteration: 2010 Train loss: 0.178126 Train acc: 0.981538\n",
      "Epoch: 2009/5000 Iteration: 2010 Validation loss: 0.550951 Validation acc: 0.810000\n",
      "Epoch: 2014/5000 Iteration: 2015 Train loss: 0.168662 Train acc: 0.986538\n",
      "Epoch: 2019/5000 Iteration: 2020 Train loss: 0.169556 Train acc: 0.985000\n",
      "Epoch: 2019/5000 Iteration: 2020 Validation loss: 0.555000 Validation acc: 0.790000\n",
      "Epoch: 2024/5000 Iteration: 2025 Train loss: 0.165564 Train acc: 0.988077\n",
      "Epoch: 2029/5000 Iteration: 2030 Train loss: 0.168594 Train acc: 0.986154\n",
      "Epoch: 2029/5000 Iteration: 2030 Validation loss: 0.550229 Validation acc: 0.810000\n",
      "Epoch: 2034/5000 Iteration: 2035 Train loss: 0.168383 Train acc: 0.987692\n",
      "Epoch: 2039/5000 Iteration: 2040 Train loss: 0.168460 Train acc: 0.986923\n",
      "Epoch: 2039/5000 Iteration: 2040 Validation loss: 0.550775 Validation acc: 0.810000\n",
      "Epoch: 2044/5000 Iteration: 2045 Train loss: 0.166893 Train acc: 0.986154\n",
      "Epoch: 2049/5000 Iteration: 2050 Train loss: 0.165562 Train acc: 0.987692\n",
      "Epoch: 2049/5000 Iteration: 2050 Validation loss: 0.568510 Validation acc: 0.800000\n",
      "Epoch: 2054/5000 Iteration: 2055 Train loss: 0.166280 Train acc: 0.986154\n",
      "Epoch: 2059/5000 Iteration: 2060 Train loss: 0.166859 Train acc: 0.985000\n",
      "Epoch: 2059/5000 Iteration: 2060 Validation loss: 0.575608 Validation acc: 0.810000\n",
      "Epoch: 2064/5000 Iteration: 2065 Train loss: 0.164952 Train acc: 0.985385\n",
      "Epoch: 2069/5000 Iteration: 2070 Train loss: 0.170383 Train acc: 0.982692\n",
      "Epoch: 2069/5000 Iteration: 2070 Validation loss: 0.551655 Validation acc: 0.830000\n",
      "Epoch: 2074/5000 Iteration: 2075 Train loss: 0.163249 Train acc: 0.987308\n",
      "Epoch: 2079/5000 Iteration: 2080 Train loss: 0.165425 Train acc: 0.983846\n",
      "Epoch: 2079/5000 Iteration: 2080 Validation loss: 0.549771 Validation acc: 0.820000\n",
      "Epoch: 2084/5000 Iteration: 2085 Train loss: 0.166338 Train acc: 0.985000\n",
      "Epoch: 2089/5000 Iteration: 2090 Train loss: 0.165847 Train acc: 0.988461\n",
      "Epoch: 2089/5000 Iteration: 2090 Validation loss: 0.593762 Validation acc: 0.800000\n",
      "Epoch: 2094/5000 Iteration: 2095 Train loss: 0.165684 Train acc: 0.988077\n",
      "Epoch: 2099/5000 Iteration: 2100 Train loss: 0.165134 Train acc: 0.985000\n",
      "Epoch: 2099/5000 Iteration: 2100 Validation loss: 0.545093 Validation acc: 0.830000\n",
      "Epoch: 2104/5000 Iteration: 2105 Train loss: 0.161329 Train acc: 0.985385\n",
      "Epoch: 2109/5000 Iteration: 2110 Train loss: 0.172162 Train acc: 0.983846\n",
      "Epoch: 2109/5000 Iteration: 2110 Validation loss: 0.566405 Validation acc: 0.800000\n",
      "Epoch: 2114/5000 Iteration: 2115 Train loss: 0.164301 Train acc: 0.987308\n",
      "Epoch: 2119/5000 Iteration: 2120 Train loss: 0.161974 Train acc: 0.987308\n",
      "Epoch: 2119/5000 Iteration: 2120 Validation loss: 0.563680 Validation acc: 0.810000\n",
      "Epoch: 2124/5000 Iteration: 2125 Train loss: 0.163460 Train acc: 0.987692\n",
      "Epoch: 2129/5000 Iteration: 2130 Train loss: 0.164611 Train acc: 0.983846\n",
      "Epoch: 2129/5000 Iteration: 2130 Validation loss: 0.549633 Validation acc: 0.800000\n",
      "Epoch: 2134/5000 Iteration: 2135 Train loss: 0.167181 Train acc: 0.986154\n",
      "Epoch: 2139/5000 Iteration: 2140 Train loss: 0.166369 Train acc: 0.987692\n",
      "Epoch: 2139/5000 Iteration: 2140 Validation loss: 0.550994 Validation acc: 0.810000\n",
      "Epoch: 2144/5000 Iteration: 2145 Train loss: 0.165675 Train acc: 0.985769\n",
      "Epoch: 2149/5000 Iteration: 2150 Train loss: 0.164680 Train acc: 0.989231\n",
      "Epoch: 2149/5000 Iteration: 2150 Validation loss: 0.580437 Validation acc: 0.810000\n",
      "Epoch: 2154/5000 Iteration: 2155 Train loss: 0.167642 Train acc: 0.984231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2159/5000 Iteration: 2160 Train loss: 0.162178 Train acc: 0.987308\n",
      "Epoch: 2159/5000 Iteration: 2160 Validation loss: 0.577137 Validation acc: 0.810000\n",
      "Epoch: 2164/5000 Iteration: 2165 Train loss: 0.165227 Train acc: 0.985000\n",
      "Epoch: 2169/5000 Iteration: 2170 Train loss: 0.161793 Train acc: 0.986923\n",
      "Epoch: 2169/5000 Iteration: 2170 Validation loss: 0.566188 Validation acc: 0.810000\n",
      "Epoch: 2174/5000 Iteration: 2175 Train loss: 0.159219 Train acc: 0.988846\n",
      "Epoch: 2179/5000 Iteration: 2180 Train loss: 0.161890 Train acc: 0.985769\n",
      "Epoch: 2179/5000 Iteration: 2180 Validation loss: 0.559429 Validation acc: 0.790000\n",
      "Epoch: 2184/5000 Iteration: 2185 Train loss: 0.161865 Train acc: 0.986538\n",
      "Epoch: 2189/5000 Iteration: 2190 Train loss: 0.156812 Train acc: 0.990385\n",
      "Epoch: 2189/5000 Iteration: 2190 Validation loss: 0.553594 Validation acc: 0.810000\n",
      "Epoch: 2194/5000 Iteration: 2195 Train loss: 0.160866 Train acc: 0.990000\n",
      "Epoch: 2199/5000 Iteration: 2200 Train loss: 0.158845 Train acc: 0.988461\n",
      "Epoch: 2199/5000 Iteration: 2200 Validation loss: 0.560963 Validation acc: 0.840000\n",
      "Epoch: 2204/5000 Iteration: 2205 Train loss: 0.164036 Train acc: 0.986538\n",
      "Epoch: 2209/5000 Iteration: 2210 Train loss: 0.162457 Train acc: 0.985769\n",
      "Epoch: 2209/5000 Iteration: 2210 Validation loss: 0.556294 Validation acc: 0.800000\n",
      "Epoch: 2214/5000 Iteration: 2215 Train loss: 0.161889 Train acc: 0.988846\n",
      "Epoch: 2219/5000 Iteration: 2220 Train loss: 0.159123 Train acc: 0.990769\n",
      "Epoch: 2219/5000 Iteration: 2220 Validation loss: 0.577728 Validation acc: 0.800000\n",
      "Epoch: 2224/5000 Iteration: 2225 Train loss: 0.159711 Train acc: 0.986154\n",
      "Epoch: 2229/5000 Iteration: 2230 Train loss: 0.158976 Train acc: 0.985769\n",
      "Epoch: 2229/5000 Iteration: 2230 Validation loss: 0.534917 Validation acc: 0.810000\n",
      "Epoch: 2234/5000 Iteration: 2235 Train loss: 0.158576 Train acc: 0.988077\n",
      "Epoch: 2239/5000 Iteration: 2240 Train loss: 0.155465 Train acc: 0.988461\n",
      "Epoch: 2239/5000 Iteration: 2240 Validation loss: 0.556902 Validation acc: 0.810000\n",
      "Epoch: 2244/5000 Iteration: 2245 Train loss: 0.161376 Train acc: 0.987692\n",
      "Epoch: 2249/5000 Iteration: 2250 Train loss: 0.159400 Train acc: 0.985769\n",
      "Epoch: 2249/5000 Iteration: 2250 Validation loss: 0.569238 Validation acc: 0.800000\n",
      "Epoch: 2254/5000 Iteration: 2255 Train loss: 0.157351 Train acc: 0.985000\n",
      "Epoch: 2259/5000 Iteration: 2260 Train loss: 0.161967 Train acc: 0.986154\n",
      "Epoch: 2259/5000 Iteration: 2260 Validation loss: 0.565236 Validation acc: 0.800000\n",
      "Epoch: 2264/5000 Iteration: 2265 Train loss: 0.162401 Train acc: 0.986923\n",
      "Epoch: 2269/5000 Iteration: 2270 Train loss: 0.156151 Train acc: 0.986923\n",
      "Epoch: 2269/5000 Iteration: 2270 Validation loss: 0.560645 Validation acc: 0.800000\n",
      "Epoch: 2274/5000 Iteration: 2275 Train loss: 0.157372 Train acc: 0.986154\n",
      "Epoch: 2279/5000 Iteration: 2280 Train loss: 0.161125 Train acc: 0.987308\n",
      "Epoch: 2279/5000 Iteration: 2280 Validation loss: 0.557076 Validation acc: 0.780000\n",
      "Epoch: 2284/5000 Iteration: 2285 Train loss: 0.160861 Train acc: 0.982308\n",
      "Epoch: 2289/5000 Iteration: 2290 Train loss: 0.159276 Train acc: 0.986538\n",
      "Epoch: 2289/5000 Iteration: 2290 Validation loss: 0.561524 Validation acc: 0.810000\n",
      "Epoch: 2294/5000 Iteration: 2295 Train loss: 0.161256 Train acc: 0.984231\n",
      "Epoch: 2299/5000 Iteration: 2300 Train loss: 0.157540 Train acc: 0.985385\n",
      "Epoch: 2299/5000 Iteration: 2300 Validation loss: 0.568188 Validation acc: 0.800000\n",
      "Epoch: 2304/5000 Iteration: 2305 Train loss: 0.161364 Train acc: 0.984231\n",
      "Epoch: 2309/5000 Iteration: 2310 Train loss: 0.155041 Train acc: 0.988846\n",
      "Epoch: 2309/5000 Iteration: 2310 Validation loss: 0.563516 Validation acc: 0.810000\n",
      "Epoch: 2314/5000 Iteration: 2315 Train loss: 0.156381 Train acc: 0.989615\n",
      "Epoch: 2319/5000 Iteration: 2320 Train loss: 0.158924 Train acc: 0.985769\n",
      "Epoch: 2319/5000 Iteration: 2320 Validation loss: 0.562167 Validation acc: 0.840000\n",
      "Epoch: 2324/5000 Iteration: 2325 Train loss: 0.156161 Train acc: 0.990000\n",
      "Epoch: 2329/5000 Iteration: 2330 Train loss: 0.155122 Train acc: 0.989231\n",
      "Epoch: 2329/5000 Iteration: 2330 Validation loss: 0.563321 Validation acc: 0.790000\n",
      "Epoch: 2334/5000 Iteration: 2335 Train loss: 0.154915 Train acc: 0.989615\n",
      "Epoch: 2339/5000 Iteration: 2340 Train loss: 0.156090 Train acc: 0.986538\n",
      "Epoch: 2339/5000 Iteration: 2340 Validation loss: 0.562395 Validation acc: 0.800000\n",
      "Epoch: 2344/5000 Iteration: 2345 Train loss: 0.158364 Train acc: 0.986923\n",
      "Epoch: 2349/5000 Iteration: 2350 Train loss: 0.157539 Train acc: 0.987692\n",
      "Epoch: 2349/5000 Iteration: 2350 Validation loss: 0.549719 Validation acc: 0.830000\n",
      "Epoch: 2354/5000 Iteration: 2355 Train loss: 0.153744 Train acc: 0.988462\n",
      "Epoch: 2359/5000 Iteration: 2360 Train loss: 0.148887 Train acc: 0.990385\n",
      "Epoch: 2359/5000 Iteration: 2360 Validation loss: 0.543983 Validation acc: 0.810000\n",
      "Epoch: 2364/5000 Iteration: 2365 Train loss: 0.157491 Train acc: 0.985769\n",
      "Epoch: 2369/5000 Iteration: 2370 Train loss: 0.156787 Train acc: 0.985385\n",
      "Epoch: 2369/5000 Iteration: 2370 Validation loss: 0.563980 Validation acc: 0.800000\n",
      "Epoch: 2374/5000 Iteration: 2375 Train loss: 0.154193 Train acc: 0.988461\n",
      "Epoch: 2379/5000 Iteration: 2380 Train loss: 0.160042 Train acc: 0.983461\n",
      "Epoch: 2379/5000 Iteration: 2380 Validation loss: 0.572952 Validation acc: 0.810000\n",
      "Epoch: 2384/5000 Iteration: 2385 Train loss: 0.155763 Train acc: 0.987692\n",
      "Epoch: 2389/5000 Iteration: 2390 Train loss: 0.152297 Train acc: 0.990000\n",
      "Epoch: 2389/5000 Iteration: 2390 Validation loss: 0.576114 Validation acc: 0.790000\n",
      "Epoch: 2394/5000 Iteration: 2395 Train loss: 0.152151 Train acc: 0.988846\n",
      "Epoch: 2399/5000 Iteration: 2400 Train loss: 0.153698 Train acc: 0.986923\n",
      "Epoch: 2399/5000 Iteration: 2400 Validation loss: 0.550862 Validation acc: 0.840000\n",
      "Epoch: 2404/5000 Iteration: 2405 Train loss: 0.152403 Train acc: 0.987692\n",
      "Epoch: 2409/5000 Iteration: 2410 Train loss: 0.157857 Train acc: 0.987308\n",
      "Epoch: 2409/5000 Iteration: 2410 Validation loss: 0.557153 Validation acc: 0.800000\n",
      "Epoch: 2414/5000 Iteration: 2415 Train loss: 0.153768 Train acc: 0.987308\n",
      "Epoch: 2419/5000 Iteration: 2420 Train loss: 0.153299 Train acc: 0.986538\n",
      "Epoch: 2419/5000 Iteration: 2420 Validation loss: 0.568847 Validation acc: 0.800000\n",
      "Epoch: 2424/5000 Iteration: 2425 Train loss: 0.155546 Train acc: 0.986154\n",
      "Epoch: 2429/5000 Iteration: 2430 Train loss: 0.153131 Train acc: 0.986923\n",
      "Epoch: 2429/5000 Iteration: 2430 Validation loss: 0.551795 Validation acc: 0.850000\n",
      "Epoch: 2434/5000 Iteration: 2435 Train loss: 0.150269 Train acc: 0.989615\n",
      "Epoch: 2439/5000 Iteration: 2440 Train loss: 0.154466 Train acc: 0.985000\n",
      "Epoch: 2439/5000 Iteration: 2440 Validation loss: 0.572620 Validation acc: 0.810000\n",
      "Epoch: 2444/5000 Iteration: 2445 Train loss: 0.150986 Train acc: 0.988846\n",
      "Epoch: 2449/5000 Iteration: 2450 Train loss: 0.150705 Train acc: 0.987692\n",
      "Epoch: 2449/5000 Iteration: 2450 Validation loss: 0.563965 Validation acc: 0.800000\n",
      "Epoch: 2454/5000 Iteration: 2455 Train loss: 0.150788 Train acc: 0.989231\n",
      "Epoch: 2459/5000 Iteration: 2460 Train loss: 0.151361 Train acc: 0.988846\n",
      "Epoch: 2459/5000 Iteration: 2460 Validation loss: 0.563468 Validation acc: 0.810000\n",
      "Epoch: 2464/5000 Iteration: 2465 Train loss: 0.151954 Train acc: 0.985385\n",
      "Epoch: 2469/5000 Iteration: 2470 Train loss: 0.153909 Train acc: 0.988077\n",
      "Epoch: 2469/5000 Iteration: 2470 Validation loss: 0.577275 Validation acc: 0.810000\n",
      "Epoch: 2474/5000 Iteration: 2475 Train loss: 0.148169 Train acc: 0.989615\n",
      "Epoch: 2479/5000 Iteration: 2480 Train loss: 0.152025 Train acc: 0.985384\n",
      "Epoch: 2479/5000 Iteration: 2480 Validation loss: 0.548188 Validation acc: 0.810000\n",
      "Epoch: 2484/5000 Iteration: 2485 Train loss: 0.151762 Train acc: 0.988077\n",
      "Epoch: 2489/5000 Iteration: 2490 Train loss: 0.152673 Train acc: 0.988077\n",
      "Epoch: 2489/5000 Iteration: 2490 Validation loss: 0.554103 Validation acc: 0.790000\n",
      "Epoch: 2494/5000 Iteration: 2495 Train loss: 0.154240 Train acc: 0.986923\n",
      "Epoch: 2499/5000 Iteration: 2500 Train loss: 0.151923 Train acc: 0.987692\n",
      "Epoch: 2499/5000 Iteration: 2500 Validation loss: 0.551882 Validation acc: 0.820000\n",
      "Epoch: 2504/5000 Iteration: 2505 Train loss: 0.154872 Train acc: 0.987692\n",
      "Epoch: 2509/5000 Iteration: 2510 Train loss: 0.153026 Train acc: 0.989231\n",
      "Epoch: 2509/5000 Iteration: 2510 Validation loss: 0.565505 Validation acc: 0.820000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2514/5000 Iteration: 2515 Train loss: 0.153623 Train acc: 0.985000\n",
      "Epoch: 2519/5000 Iteration: 2520 Train loss: 0.152876 Train acc: 0.985385\n",
      "Epoch: 2519/5000 Iteration: 2520 Validation loss: 0.541526 Validation acc: 0.840000\n",
      "Epoch: 2524/5000 Iteration: 2525 Train loss: 0.148970 Train acc: 0.989231\n",
      "Epoch: 2529/5000 Iteration: 2530 Train loss: 0.151944 Train acc: 0.988846\n",
      "Epoch: 2529/5000 Iteration: 2530 Validation loss: 0.547968 Validation acc: 0.800000\n",
      "Epoch: 2534/5000 Iteration: 2535 Train loss: 0.150801 Train acc: 0.990000\n",
      "Epoch: 2539/5000 Iteration: 2540 Train loss: 0.149009 Train acc: 0.990000\n",
      "Epoch: 2539/5000 Iteration: 2540 Validation loss: 0.544811 Validation acc: 0.830000\n",
      "Epoch: 2544/5000 Iteration: 2545 Train loss: 0.155183 Train acc: 0.987308\n",
      "Epoch: 2549/5000 Iteration: 2550 Train loss: 0.147788 Train acc: 0.989231\n",
      "Epoch: 2549/5000 Iteration: 2550 Validation loss: 0.565194 Validation acc: 0.810000\n",
      "Epoch: 2554/5000 Iteration: 2555 Train loss: 0.150660 Train acc: 0.988846\n",
      "Epoch: 2559/5000 Iteration: 2560 Train loss: 0.152913 Train acc: 0.987308\n",
      "Epoch: 2559/5000 Iteration: 2560 Validation loss: 0.531217 Validation acc: 0.800000\n",
      "Epoch: 2564/5000 Iteration: 2565 Train loss: 0.149433 Train acc: 0.987692\n",
      "Epoch: 2569/5000 Iteration: 2570 Train loss: 0.152185 Train acc: 0.988077\n",
      "Epoch: 2569/5000 Iteration: 2570 Validation loss: 0.540014 Validation acc: 0.810000\n",
      "Epoch: 2574/5000 Iteration: 2575 Train loss: 0.148262 Train acc: 0.987692\n",
      "Epoch: 2579/5000 Iteration: 2580 Train loss: 0.150574 Train acc: 0.987308\n",
      "Epoch: 2579/5000 Iteration: 2580 Validation loss: 0.569990 Validation acc: 0.800000\n",
      "Epoch: 2584/5000 Iteration: 2585 Train loss: 0.154375 Train acc: 0.985385\n",
      "Epoch: 2589/5000 Iteration: 2590 Train loss: 0.147713 Train acc: 0.986923\n",
      "Epoch: 2589/5000 Iteration: 2590 Validation loss: 0.544145 Validation acc: 0.800000\n",
      "Epoch: 2594/5000 Iteration: 2595 Train loss: 0.148325 Train acc: 0.989615\n",
      "Epoch: 2599/5000 Iteration: 2600 Train loss: 0.148839 Train acc: 0.985769\n",
      "Epoch: 2599/5000 Iteration: 2600 Validation loss: 0.561352 Validation acc: 0.800000\n",
      "Epoch: 2604/5000 Iteration: 2605 Train loss: 0.147280 Train acc: 0.988846\n",
      "Epoch: 2609/5000 Iteration: 2610 Train loss: 0.145530 Train acc: 0.988461\n",
      "Epoch: 2609/5000 Iteration: 2610 Validation loss: 0.557071 Validation acc: 0.790000\n",
      "Epoch: 2614/5000 Iteration: 2615 Train loss: 0.156762 Train acc: 0.983846\n",
      "Epoch: 2619/5000 Iteration: 2620 Train loss: 0.149376 Train acc: 0.987692\n",
      "Epoch: 2619/5000 Iteration: 2620 Validation loss: 0.523253 Validation acc: 0.840000\n",
      "Epoch: 2624/5000 Iteration: 2625 Train loss: 0.152813 Train acc: 0.985000\n",
      "Epoch: 2629/5000 Iteration: 2630 Train loss: 0.150921 Train acc: 0.987692\n",
      "Epoch: 2629/5000 Iteration: 2630 Validation loss: 0.539175 Validation acc: 0.800000\n",
      "Epoch: 2634/5000 Iteration: 2635 Train loss: 0.149767 Train acc: 0.987692\n",
      "Epoch: 2639/5000 Iteration: 2640 Train loss: 0.150255 Train acc: 0.988461\n",
      "Epoch: 2639/5000 Iteration: 2640 Validation loss: 0.552524 Validation acc: 0.830000\n",
      "Epoch: 2644/5000 Iteration: 2645 Train loss: 0.150400 Train acc: 0.986538\n",
      "Epoch: 2649/5000 Iteration: 2650 Train loss: 0.146903 Train acc: 0.988846\n",
      "Epoch: 2649/5000 Iteration: 2650 Validation loss: 0.541637 Validation acc: 0.800000\n",
      "Epoch: 2654/5000 Iteration: 2655 Train loss: 0.148071 Train acc: 0.989615\n",
      "Epoch: 2659/5000 Iteration: 2660 Train loss: 0.148294 Train acc: 0.985385\n",
      "Epoch: 2659/5000 Iteration: 2660 Validation loss: 0.552593 Validation acc: 0.830000\n",
      "Epoch: 2664/5000 Iteration: 2665 Train loss: 0.147377 Train acc: 0.988846\n",
      "Epoch: 2669/5000 Iteration: 2670 Train loss: 0.148999 Train acc: 0.988077\n",
      "Epoch: 2669/5000 Iteration: 2670 Validation loss: 0.551997 Validation acc: 0.810000\n",
      "Epoch: 2674/5000 Iteration: 2675 Train loss: 0.145547 Train acc: 0.990385\n",
      "Epoch: 2679/5000 Iteration: 2680 Train loss: 0.142880 Train acc: 0.990000\n",
      "Epoch: 2679/5000 Iteration: 2680 Validation loss: 0.557450 Validation acc: 0.830000\n",
      "Epoch: 2684/5000 Iteration: 2685 Train loss: 0.146865 Train acc: 0.987308\n",
      "Epoch: 2689/5000 Iteration: 2690 Train loss: 0.144020 Train acc: 0.990769\n",
      "Epoch: 2689/5000 Iteration: 2690 Validation loss: 0.563646 Validation acc: 0.810000\n",
      "Epoch: 2694/5000 Iteration: 2695 Train loss: 0.146654 Train acc: 0.989231\n",
      "Epoch: 2699/5000 Iteration: 2700 Train loss: 0.147892 Train acc: 0.988461\n",
      "Epoch: 2699/5000 Iteration: 2700 Validation loss: 0.582037 Validation acc: 0.810000\n",
      "Epoch: 2704/5000 Iteration: 2705 Train loss: 0.146123 Train acc: 0.988461\n",
      "Epoch: 2709/5000 Iteration: 2710 Train loss: 0.143521 Train acc: 0.988846\n",
      "Epoch: 2709/5000 Iteration: 2710 Validation loss: 0.559931 Validation acc: 0.810000\n",
      "Epoch: 2714/5000 Iteration: 2715 Train loss: 0.147863 Train acc: 0.988077\n",
      "Epoch: 2719/5000 Iteration: 2720 Train loss: 0.147988 Train acc: 0.986923\n",
      "Epoch: 2719/5000 Iteration: 2720 Validation loss: 0.558290 Validation acc: 0.800000\n",
      "Epoch: 2724/5000 Iteration: 2725 Train loss: 0.148674 Train acc: 0.987308\n",
      "Epoch: 2729/5000 Iteration: 2730 Train loss: 0.145202 Train acc: 0.987308\n",
      "Epoch: 2729/5000 Iteration: 2730 Validation loss: 0.570421 Validation acc: 0.800000\n",
      "Epoch: 2734/5000 Iteration: 2735 Train loss: 0.143534 Train acc: 0.988846\n",
      "Epoch: 2739/5000 Iteration: 2740 Train loss: 0.144977 Train acc: 0.987308\n",
      "Epoch: 2739/5000 Iteration: 2740 Validation loss: 0.565308 Validation acc: 0.810000\n",
      "Epoch: 2744/5000 Iteration: 2745 Train loss: 0.145888 Train acc: 0.988077\n",
      "Epoch: 2749/5000 Iteration: 2750 Train loss: 0.145239 Train acc: 0.986538\n",
      "Epoch: 2749/5000 Iteration: 2750 Validation loss: 0.544201 Validation acc: 0.800000\n",
      "Epoch: 2754/5000 Iteration: 2755 Train loss: 0.145621 Train acc: 0.988462\n",
      "Epoch: 2759/5000 Iteration: 2760 Train loss: 0.145999 Train acc: 0.987308\n",
      "Epoch: 2759/5000 Iteration: 2760 Validation loss: 0.547929 Validation acc: 0.800000\n",
      "Epoch: 2764/5000 Iteration: 2765 Train loss: 0.142755 Train acc: 0.988846\n",
      "Epoch: 2769/5000 Iteration: 2770 Train loss: 0.144862 Train acc: 0.988461\n",
      "Epoch: 2769/5000 Iteration: 2770 Validation loss: 0.560886 Validation acc: 0.790000\n",
      "Epoch: 2774/5000 Iteration: 2775 Train loss: 0.145341 Train acc: 0.986538\n",
      "Epoch: 2779/5000 Iteration: 2780 Train loss: 0.142947 Train acc: 0.990384\n",
      "Epoch: 2779/5000 Iteration: 2780 Validation loss: 0.576394 Validation acc: 0.790000\n",
      "Epoch: 2784/5000 Iteration: 2785 Train loss: 0.144976 Train acc: 0.988461\n",
      "Epoch: 2789/5000 Iteration: 2790 Train loss: 0.143900 Train acc: 0.988461\n",
      "Epoch: 2789/5000 Iteration: 2790 Validation loss: 0.577198 Validation acc: 0.810000\n",
      "Epoch: 2794/5000 Iteration: 2795 Train loss: 0.145683 Train acc: 0.988077\n",
      "Epoch: 2799/5000 Iteration: 2800 Train loss: 0.144858 Train acc: 0.985769\n",
      "Epoch: 2799/5000 Iteration: 2800 Validation loss: 0.568882 Validation acc: 0.790000\n",
      "Epoch: 2804/5000 Iteration: 2805 Train loss: 0.140124 Train acc: 0.989231\n",
      "Epoch: 2809/5000 Iteration: 2810 Train loss: 0.144405 Train acc: 0.986538\n",
      "Epoch: 2809/5000 Iteration: 2810 Validation loss: 0.577819 Validation acc: 0.790000\n",
      "Epoch: 2814/5000 Iteration: 2815 Train loss: 0.144123 Train acc: 0.987692\n",
      "Epoch: 2819/5000 Iteration: 2820 Train loss: 0.145062 Train acc: 0.988461\n",
      "Epoch: 2819/5000 Iteration: 2820 Validation loss: 0.573382 Validation acc: 0.810000\n",
      "Epoch: 2824/5000 Iteration: 2825 Train loss: 0.148438 Train acc: 0.988461\n",
      "Epoch: 2829/5000 Iteration: 2830 Train loss: 0.144271 Train acc: 0.988462\n",
      "Epoch: 2829/5000 Iteration: 2830 Validation loss: 0.534667 Validation acc: 0.820000\n",
      "Epoch: 2834/5000 Iteration: 2835 Train loss: 0.146798 Train acc: 0.985385\n",
      "Epoch: 2839/5000 Iteration: 2840 Train loss: 0.144444 Train acc: 0.987308\n",
      "Epoch: 2839/5000 Iteration: 2840 Validation loss: 0.567553 Validation acc: 0.810000\n",
      "Epoch: 2844/5000 Iteration: 2845 Train loss: 0.153510 Train acc: 0.987692\n",
      "Epoch: 2849/5000 Iteration: 2850 Train loss: 0.146222 Train acc: 0.987308\n",
      "Epoch: 2849/5000 Iteration: 2850 Validation loss: 0.568535 Validation acc: 0.840000\n",
      "Epoch: 2854/5000 Iteration: 2855 Train loss: 0.142806 Train acc: 0.989615\n",
      "Epoch: 2859/5000 Iteration: 2860 Train loss: 0.144816 Train acc: 0.986154\n",
      "Epoch: 2859/5000 Iteration: 2860 Validation loss: 0.546771 Validation acc: 0.820000\n",
      "Epoch: 2864/5000 Iteration: 2865 Train loss: 0.146600 Train acc: 0.985769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2869/5000 Iteration: 2870 Train loss: 0.144317 Train acc: 0.988077\n",
      "Epoch: 2869/5000 Iteration: 2870 Validation loss: 0.561146 Validation acc: 0.810000\n",
      "Epoch: 2874/5000 Iteration: 2875 Train loss: 0.143464 Train acc: 0.988461\n",
      "Epoch: 2879/5000 Iteration: 2880 Train loss: 0.143508 Train acc: 0.988846\n",
      "Epoch: 2879/5000 Iteration: 2880 Validation loss: 0.549211 Validation acc: 0.820000\n",
      "Epoch: 2884/5000 Iteration: 2885 Train loss: 0.146189 Train acc: 0.987692\n",
      "Epoch: 2889/5000 Iteration: 2890 Train loss: 0.142012 Train acc: 0.989231\n",
      "Epoch: 2889/5000 Iteration: 2890 Validation loss: 0.541092 Validation acc: 0.830000\n",
      "Epoch: 2894/5000 Iteration: 2895 Train loss: 0.144672 Train acc: 0.988077\n",
      "Epoch: 2899/5000 Iteration: 2900 Train loss: 0.147328 Train acc: 0.986538\n",
      "Epoch: 2899/5000 Iteration: 2900 Validation loss: 0.559135 Validation acc: 0.810000\n",
      "Epoch: 2904/5000 Iteration: 2905 Train loss: 0.145805 Train acc: 0.987692\n",
      "Epoch: 2909/5000 Iteration: 2910 Train loss: 0.140380 Train acc: 0.991154\n",
      "Epoch: 2909/5000 Iteration: 2910 Validation loss: 0.561821 Validation acc: 0.810000\n",
      "Epoch: 2914/5000 Iteration: 2915 Train loss: 0.144819 Train acc: 0.988077\n",
      "Epoch: 2919/5000 Iteration: 2920 Train loss: 0.142924 Train acc: 0.988461\n",
      "Epoch: 2919/5000 Iteration: 2920 Validation loss: 0.548785 Validation acc: 0.820000\n",
      "Epoch: 2924/5000 Iteration: 2925 Train loss: 0.145684 Train acc: 0.986538\n",
      "Epoch: 2929/5000 Iteration: 2930 Train loss: 0.141216 Train acc: 0.988846\n",
      "Epoch: 2929/5000 Iteration: 2930 Validation loss: 0.565505 Validation acc: 0.810000\n",
      "Epoch: 2934/5000 Iteration: 2935 Train loss: 0.143552 Train acc: 0.986923\n",
      "Epoch: 2939/5000 Iteration: 2940 Train loss: 0.141003 Train acc: 0.988846\n",
      "Epoch: 2939/5000 Iteration: 2940 Validation loss: 0.558764 Validation acc: 0.820000\n",
      "Epoch: 2944/5000 Iteration: 2945 Train loss: 0.144540 Train acc: 0.986923\n",
      "Epoch: 2949/5000 Iteration: 2950 Train loss: 0.144769 Train acc: 0.986538\n",
      "Epoch: 2949/5000 Iteration: 2950 Validation loss: 0.565160 Validation acc: 0.800000\n",
      "Epoch: 2954/5000 Iteration: 2955 Train loss: 0.141070 Train acc: 0.986538\n",
      "Epoch: 2959/5000 Iteration: 2960 Train loss: 0.145844 Train acc: 0.985769\n",
      "Epoch: 2959/5000 Iteration: 2960 Validation loss: 0.559681 Validation acc: 0.810000\n",
      "Epoch: 2964/5000 Iteration: 2965 Train loss: 0.142998 Train acc: 0.988846\n",
      "Epoch: 2969/5000 Iteration: 2970 Train loss: 0.143075 Train acc: 0.986538\n",
      "Epoch: 2969/5000 Iteration: 2970 Validation loss: 0.535525 Validation acc: 0.850000\n",
      "Epoch: 2974/5000 Iteration: 2975 Train loss: 0.144365 Train acc: 0.985769\n",
      "Epoch: 2979/5000 Iteration: 2980 Train loss: 0.142133 Train acc: 0.990000\n",
      "Epoch: 2979/5000 Iteration: 2980 Validation loss: 0.545993 Validation acc: 0.810000\n",
      "Epoch: 2984/5000 Iteration: 2985 Train loss: 0.140891 Train acc: 0.990000\n",
      "Epoch: 2989/5000 Iteration: 2990 Train loss: 0.145495 Train acc: 0.986538\n",
      "Epoch: 2989/5000 Iteration: 2990 Validation loss: 0.560319 Validation acc: 0.870000\n",
      "Epoch: 2994/5000 Iteration: 2995 Train loss: 0.143727 Train acc: 0.987308\n",
      "Epoch: 2999/5000 Iteration: 3000 Train loss: 0.142662 Train acc: 0.988461\n",
      "Epoch: 2999/5000 Iteration: 3000 Validation loss: 0.565195 Validation acc: 0.820000\n",
      "Epoch: 3004/5000 Iteration: 3005 Train loss: 0.140422 Train acc: 0.989231\n",
      "Epoch: 3009/5000 Iteration: 3010 Train loss: 0.142224 Train acc: 0.989231\n",
      "Epoch: 3009/5000 Iteration: 3010 Validation loss: 0.558042 Validation acc: 0.790000\n",
      "Epoch: 3014/5000 Iteration: 3015 Train loss: 0.141033 Train acc: 0.988077\n",
      "Epoch: 3019/5000 Iteration: 3020 Train loss: 0.140939 Train acc: 0.988462\n",
      "Epoch: 3019/5000 Iteration: 3020 Validation loss: 0.554804 Validation acc: 0.810000\n",
      "Epoch: 3024/5000 Iteration: 3025 Train loss: 0.141462 Train acc: 0.989615\n",
      "Epoch: 3029/5000 Iteration: 3030 Train loss: 0.139997 Train acc: 0.986923\n",
      "Epoch: 3029/5000 Iteration: 3030 Validation loss: 0.546254 Validation acc: 0.820000\n",
      "Epoch: 3034/5000 Iteration: 3035 Train loss: 0.140764 Train acc: 0.989231\n",
      "Epoch: 3039/5000 Iteration: 3040 Train loss: 0.142787 Train acc: 0.987308\n",
      "Epoch: 3039/5000 Iteration: 3040 Validation loss: 0.583658 Validation acc: 0.810000\n",
      "Epoch: 3044/5000 Iteration: 3045 Train loss: 0.142478 Train acc: 0.989615\n",
      "Epoch: 3049/5000 Iteration: 3050 Train loss: 0.141859 Train acc: 0.989615\n",
      "Epoch: 3049/5000 Iteration: 3050 Validation loss: 0.572763 Validation acc: 0.810000\n",
      "Epoch: 3054/5000 Iteration: 3055 Train loss: 0.138070 Train acc: 0.990385\n",
      "Epoch: 3059/5000 Iteration: 3060 Train loss: 0.139504 Train acc: 0.989231\n",
      "Epoch: 3059/5000 Iteration: 3060 Validation loss: 0.543722 Validation acc: 0.800000\n",
      "Epoch: 3064/5000 Iteration: 3065 Train loss: 0.138184 Train acc: 0.990385\n",
      "Epoch: 3069/5000 Iteration: 3070 Train loss: 0.138466 Train acc: 0.989231\n",
      "Epoch: 3069/5000 Iteration: 3070 Validation loss: 0.524212 Validation acc: 0.810000\n",
      "Epoch: 3074/5000 Iteration: 3075 Train loss: 0.140846 Train acc: 0.986538\n",
      "Epoch: 3079/5000 Iteration: 3080 Train loss: 0.137608 Train acc: 0.988461\n",
      "Epoch: 3079/5000 Iteration: 3080 Validation loss: 0.582654 Validation acc: 0.810000\n",
      "Epoch: 3084/5000 Iteration: 3085 Train loss: 0.137506 Train acc: 0.989231\n",
      "Epoch: 3089/5000 Iteration: 3090 Train loss: 0.144552 Train acc: 0.986154\n",
      "Epoch: 3089/5000 Iteration: 3090 Validation loss: 0.563345 Validation acc: 0.800000\n",
      "Epoch: 3094/5000 Iteration: 3095 Train loss: 0.137983 Train acc: 0.988846\n",
      "Epoch: 3099/5000 Iteration: 3100 Train loss: 0.138237 Train acc: 0.987692\n",
      "Epoch: 3099/5000 Iteration: 3100 Validation loss: 0.550900 Validation acc: 0.810000\n",
      "Epoch: 3104/5000 Iteration: 3105 Train loss: 0.137378 Train acc: 0.990385\n",
      "Epoch: 3109/5000 Iteration: 3110 Train loss: 0.139669 Train acc: 0.988846\n",
      "Epoch: 3109/5000 Iteration: 3110 Validation loss: 0.555062 Validation acc: 0.810000\n",
      "Epoch: 3114/5000 Iteration: 3115 Train loss: 0.140956 Train acc: 0.986154\n",
      "Epoch: 3119/5000 Iteration: 3120 Train loss: 0.135603 Train acc: 0.990769\n",
      "Epoch: 3119/5000 Iteration: 3120 Validation loss: 0.541198 Validation acc: 0.820000\n",
      "Epoch: 3124/5000 Iteration: 3125 Train loss: 0.140242 Train acc: 0.987692\n",
      "Epoch: 3129/5000 Iteration: 3130 Train loss: 0.140657 Train acc: 0.985769\n",
      "Epoch: 3129/5000 Iteration: 3130 Validation loss: 0.563299 Validation acc: 0.820000\n",
      "Epoch: 3134/5000 Iteration: 3135 Train loss: 0.139783 Train acc: 0.988077\n",
      "Epoch: 3139/5000 Iteration: 3140 Train loss: 0.138896 Train acc: 0.987692\n",
      "Epoch: 3139/5000 Iteration: 3140 Validation loss: 0.543897 Validation acc: 0.850000\n",
      "Epoch: 3144/5000 Iteration: 3145 Train loss: 0.138211 Train acc: 0.990000\n",
      "Epoch: 3149/5000 Iteration: 3150 Train loss: 0.138110 Train acc: 0.988077\n",
      "Epoch: 3149/5000 Iteration: 3150 Validation loss: 0.531950 Validation acc: 0.820000\n",
      "Epoch: 3154/5000 Iteration: 3155 Train loss: 0.136709 Train acc: 0.990385\n",
      "Epoch: 3159/5000 Iteration: 3160 Train loss: 0.137136 Train acc: 0.990000\n",
      "Epoch: 3159/5000 Iteration: 3160 Validation loss: 0.538434 Validation acc: 0.820000\n",
      "Epoch: 3164/5000 Iteration: 3165 Train loss: 0.134694 Train acc: 0.988461\n",
      "Epoch: 3169/5000 Iteration: 3170 Train loss: 0.142932 Train acc: 0.987692\n",
      "Epoch: 3169/5000 Iteration: 3170 Validation loss: 0.558612 Validation acc: 0.800000\n",
      "Epoch: 3174/5000 Iteration: 3175 Train loss: 0.139534 Train acc: 0.988461\n",
      "Epoch: 3179/5000 Iteration: 3180 Train loss: 0.141485 Train acc: 0.986538\n",
      "Epoch: 3179/5000 Iteration: 3180 Validation loss: 0.534377 Validation acc: 0.840000\n",
      "Epoch: 3184/5000 Iteration: 3185 Train loss: 0.142877 Train acc: 0.988461\n",
      "Epoch: 3189/5000 Iteration: 3190 Train loss: 0.141051 Train acc: 0.988077\n",
      "Epoch: 3189/5000 Iteration: 3190 Validation loss: 0.563923 Validation acc: 0.810000\n",
      "Epoch: 3194/5000 Iteration: 3195 Train loss: 0.138838 Train acc: 0.990000\n",
      "Epoch: 3199/5000 Iteration: 3200 Train loss: 0.138790 Train acc: 0.990000\n",
      "Epoch: 3199/5000 Iteration: 3200 Validation loss: 0.562281 Validation acc: 0.810000\n",
      "Epoch: 3204/5000 Iteration: 3205 Train loss: 0.137621 Train acc: 0.989231\n",
      "Epoch: 3209/5000 Iteration: 3210 Train loss: 0.136303 Train acc: 0.990000\n",
      "Epoch: 3209/5000 Iteration: 3210 Validation loss: 0.531255 Validation acc: 0.810000\n",
      "Epoch: 3214/5000 Iteration: 3215 Train loss: 0.136269 Train acc: 0.988461\n",
      "Epoch: 3219/5000 Iteration: 3220 Train loss: 0.132996 Train acc: 0.990769\n",
      "Epoch: 3219/5000 Iteration: 3220 Validation loss: 0.562724 Validation acc: 0.800000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3224/5000 Iteration: 3225 Train loss: 0.132635 Train acc: 0.990385\n",
      "Epoch: 3229/5000 Iteration: 3230 Train loss: 0.138342 Train acc: 0.986538\n",
      "Epoch: 3229/5000 Iteration: 3230 Validation loss: 0.552060 Validation acc: 0.800000\n",
      "Epoch: 3234/5000 Iteration: 3235 Train loss: 0.135362 Train acc: 0.990000\n",
      "Epoch: 3239/5000 Iteration: 3240 Train loss: 0.135875 Train acc: 0.987692\n",
      "Epoch: 3239/5000 Iteration: 3240 Validation loss: 0.562950 Validation acc: 0.810000\n",
      "Epoch: 3244/5000 Iteration: 3245 Train loss: 0.136531 Train acc: 0.988846\n",
      "Epoch: 3249/5000 Iteration: 3250 Train loss: 0.134972 Train acc: 0.990769\n",
      "Epoch: 3249/5000 Iteration: 3250 Validation loss: 0.558289 Validation acc: 0.800000\n",
      "Epoch: 3254/5000 Iteration: 3255 Train loss: 0.134792 Train acc: 0.990769\n",
      "Epoch: 3259/5000 Iteration: 3260 Train loss: 0.137604 Train acc: 0.989231\n",
      "Epoch: 3259/5000 Iteration: 3260 Validation loss: 0.533303 Validation acc: 0.820000\n",
      "Epoch: 3264/5000 Iteration: 3265 Train loss: 0.135881 Train acc: 0.990000\n",
      "Epoch: 3269/5000 Iteration: 3270 Train loss: 0.133851 Train acc: 0.990000\n",
      "Epoch: 3269/5000 Iteration: 3270 Validation loss: 0.559605 Validation acc: 0.810000\n",
      "Epoch: 3274/5000 Iteration: 3275 Train loss: 0.136863 Train acc: 0.986538\n",
      "Epoch: 3279/5000 Iteration: 3280 Train loss: 0.136921 Train acc: 0.987308\n",
      "Epoch: 3279/5000 Iteration: 3280 Validation loss: 0.555088 Validation acc: 0.800000\n",
      "Epoch: 3284/5000 Iteration: 3285 Train loss: 0.135533 Train acc: 0.989231\n",
      "Epoch: 3289/5000 Iteration: 3290 Train loss: 0.134209 Train acc: 0.989615\n",
      "Epoch: 3289/5000 Iteration: 3290 Validation loss: 0.549877 Validation acc: 0.820000\n",
      "Epoch: 3294/5000 Iteration: 3295 Train loss: 0.136535 Train acc: 0.988846\n",
      "Epoch: 3299/5000 Iteration: 3300 Train loss: 0.136823 Train acc: 0.986538\n",
      "Epoch: 3299/5000 Iteration: 3300 Validation loss: 0.555199 Validation acc: 0.830000\n",
      "Epoch: 3304/5000 Iteration: 3305 Train loss: 0.134731 Train acc: 0.990769\n",
      "Epoch: 3309/5000 Iteration: 3310 Train loss: 0.134320 Train acc: 0.988461\n",
      "Epoch: 3309/5000 Iteration: 3310 Validation loss: 0.561870 Validation acc: 0.800000\n",
      "Epoch: 3314/5000 Iteration: 3315 Train loss: 0.133392 Train acc: 0.993077\n",
      "Epoch: 3319/5000 Iteration: 3320 Train loss: 0.134536 Train acc: 0.988846\n",
      "Epoch: 3319/5000 Iteration: 3320 Validation loss: 0.563605 Validation acc: 0.800000\n",
      "Epoch: 3324/5000 Iteration: 3325 Train loss: 0.135124 Train acc: 0.990385\n",
      "Epoch: 3329/5000 Iteration: 3330 Train loss: 0.133576 Train acc: 0.991538\n",
      "Epoch: 3329/5000 Iteration: 3330 Validation loss: 0.577198 Validation acc: 0.800000\n",
      "Epoch: 3334/5000 Iteration: 3335 Train loss: 0.136608 Train acc: 0.985769\n",
      "Epoch: 3339/5000 Iteration: 3340 Train loss: 0.131271 Train acc: 0.990385\n",
      "Epoch: 3339/5000 Iteration: 3340 Validation loss: 0.564595 Validation acc: 0.810000\n",
      "Epoch: 3344/5000 Iteration: 3345 Train loss: 0.138450 Train acc: 0.987308\n",
      "Epoch: 3349/5000 Iteration: 3350 Train loss: 0.136645 Train acc: 0.987692\n",
      "Epoch: 3349/5000 Iteration: 3350 Validation loss: 0.556934 Validation acc: 0.820000\n",
      "Epoch: 3354/5000 Iteration: 3355 Train loss: 0.134412 Train acc: 0.988461\n",
      "Epoch: 3359/5000 Iteration: 3360 Train loss: 0.140011 Train acc: 0.987692\n",
      "Epoch: 3359/5000 Iteration: 3360 Validation loss: 0.543301 Validation acc: 0.810000\n",
      "Epoch: 3364/5000 Iteration: 3365 Train loss: 0.135705 Train acc: 0.990385\n",
      "Epoch: 3369/5000 Iteration: 3370 Train loss: 0.138141 Train acc: 0.987692\n",
      "Epoch: 3369/5000 Iteration: 3370 Validation loss: 0.557693 Validation acc: 0.820000\n",
      "Epoch: 3374/5000 Iteration: 3375 Train loss: 0.135400 Train acc: 0.989615\n",
      "Epoch: 3379/5000 Iteration: 3380 Train loss: 0.132852 Train acc: 0.987692\n",
      "Epoch: 3379/5000 Iteration: 3380 Validation loss: 0.581228 Validation acc: 0.800000\n",
      "Epoch: 3384/5000 Iteration: 3385 Train loss: 0.134447 Train acc: 0.989615\n",
      "Epoch: 3389/5000 Iteration: 3390 Train loss: 0.136890 Train acc: 0.985769\n",
      "Epoch: 3389/5000 Iteration: 3390 Validation loss: 0.556451 Validation acc: 0.800000\n",
      "Epoch: 3394/5000 Iteration: 3395 Train loss: 0.137911 Train acc: 0.986538\n",
      "Epoch: 3399/5000 Iteration: 3400 Train loss: 0.133088 Train acc: 0.989615\n",
      "Epoch: 3399/5000 Iteration: 3400 Validation loss: 0.563203 Validation acc: 0.810000\n",
      "Epoch: 3404/5000 Iteration: 3405 Train loss: 0.131415 Train acc: 0.989615\n",
      "Epoch: 3409/5000 Iteration: 3410 Train loss: 0.136325 Train acc: 0.988846\n",
      "Epoch: 3409/5000 Iteration: 3410 Validation loss: 0.547728 Validation acc: 0.820000\n",
      "Epoch: 3414/5000 Iteration: 3415 Train loss: 0.136186 Train acc: 0.989231\n",
      "Epoch: 3419/5000 Iteration: 3420 Train loss: 0.133311 Train acc: 0.988077\n",
      "Epoch: 3419/5000 Iteration: 3420 Validation loss: 0.578115 Validation acc: 0.850000\n",
      "Epoch: 3424/5000 Iteration: 3425 Train loss: 0.133014 Train acc: 0.989615\n",
      "Epoch: 3429/5000 Iteration: 3430 Train loss: 0.133224 Train acc: 0.989615\n",
      "Epoch: 3429/5000 Iteration: 3430 Validation loss: 0.553071 Validation acc: 0.800000\n",
      "Epoch: 3434/5000 Iteration: 3435 Train loss: 0.136871 Train acc: 0.989615\n",
      "Epoch: 3439/5000 Iteration: 3440 Train loss: 0.136814 Train acc: 0.989615\n",
      "Epoch: 3439/5000 Iteration: 3440 Validation loss: 0.542922 Validation acc: 0.810000\n",
      "Epoch: 3444/5000 Iteration: 3445 Train loss: 0.133023 Train acc: 0.988846\n",
      "Epoch: 3449/5000 Iteration: 3450 Train loss: 0.138074 Train acc: 0.986538\n",
      "Epoch: 3449/5000 Iteration: 3450 Validation loss: 0.552316 Validation acc: 0.810000\n",
      "Epoch: 3454/5000 Iteration: 3455 Train loss: 0.131447 Train acc: 0.991923\n",
      "Epoch: 3459/5000 Iteration: 3460 Train loss: 0.131119 Train acc: 0.989615\n",
      "Epoch: 3459/5000 Iteration: 3460 Validation loss: 0.552319 Validation acc: 0.790000\n",
      "Epoch: 3464/5000 Iteration: 3465 Train loss: 0.132285 Train acc: 0.990000\n",
      "Epoch: 3469/5000 Iteration: 3470 Train loss: 0.131437 Train acc: 0.991154\n",
      "Epoch: 3469/5000 Iteration: 3470 Validation loss: 0.536576 Validation acc: 0.840000\n",
      "Epoch: 3474/5000 Iteration: 3475 Train loss: 0.132037 Train acc: 0.990769\n",
      "Epoch: 3479/5000 Iteration: 3480 Train loss: 0.134651 Train acc: 0.989615\n",
      "Epoch: 3479/5000 Iteration: 3480 Validation loss: 0.563447 Validation acc: 0.810000\n",
      "Epoch: 3484/5000 Iteration: 3485 Train loss: 0.134980 Train acc: 0.988077\n",
      "Epoch: 3489/5000 Iteration: 3490 Train loss: 0.129402 Train acc: 0.990385\n",
      "Epoch: 3489/5000 Iteration: 3490 Validation loss: 0.570649 Validation acc: 0.810000\n",
      "Epoch: 3494/5000 Iteration: 3495 Train loss: 0.135342 Train acc: 0.988077\n",
      "Epoch: 3499/5000 Iteration: 3500 Train loss: 0.134784 Train acc: 0.990000\n",
      "Epoch: 3499/5000 Iteration: 3500 Validation loss: 0.557528 Validation acc: 0.800000\n",
      "Epoch: 3504/5000 Iteration: 3505 Train loss: 0.131021 Train acc: 0.988461\n",
      "Epoch: 3509/5000 Iteration: 3510 Train loss: 0.135441 Train acc: 0.987308\n",
      "Epoch: 3509/5000 Iteration: 3510 Validation loss: 0.569010 Validation acc: 0.800000\n",
      "Epoch: 3514/5000 Iteration: 3515 Train loss: 0.133954 Train acc: 0.989231\n",
      "Epoch: 3519/5000 Iteration: 3520 Train loss: 0.135923 Train acc: 0.988846\n",
      "Epoch: 3519/5000 Iteration: 3520 Validation loss: 0.543804 Validation acc: 0.810000\n",
      "Epoch: 3524/5000 Iteration: 3525 Train loss: 0.130966 Train acc: 0.990000\n",
      "Epoch: 3529/5000 Iteration: 3530 Train loss: 0.131913 Train acc: 0.989615\n",
      "Epoch: 3529/5000 Iteration: 3530 Validation loss: 0.573538 Validation acc: 0.800000\n",
      "Epoch: 3534/5000 Iteration: 3535 Train loss: 0.136332 Train acc: 0.988846\n",
      "Epoch: 3539/5000 Iteration: 3540 Train loss: 0.134047 Train acc: 0.986923\n",
      "Epoch: 3539/5000 Iteration: 3540 Validation loss: 0.545970 Validation acc: 0.880000\n",
      "Epoch: 3544/5000 Iteration: 3545 Train loss: 0.133941 Train acc: 0.988462\n",
      "Epoch: 3549/5000 Iteration: 3550 Train loss: 0.138785 Train acc: 0.987308\n",
      "Epoch: 3549/5000 Iteration: 3550 Validation loss: 0.594656 Validation acc: 0.800000\n",
      "Epoch: 3554/5000 Iteration: 3555 Train loss: 0.134415 Train acc: 0.989231\n",
      "Epoch: 3559/5000 Iteration: 3560 Train loss: 0.132715 Train acc: 0.988461\n",
      "Epoch: 3559/5000 Iteration: 3560 Validation loss: 0.536240 Validation acc: 0.810000\n",
      "Epoch: 3564/5000 Iteration: 3565 Train loss: 0.131987 Train acc: 0.989231\n",
      "Epoch: 3569/5000 Iteration: 3570 Train loss: 0.130524 Train acc: 0.989615\n",
      "Epoch: 3569/5000 Iteration: 3570 Validation loss: 0.560956 Validation acc: 0.810000\n",
      "Epoch: 3574/5000 Iteration: 3575 Train loss: 0.134284 Train acc: 0.988461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3579/5000 Iteration: 3580 Train loss: 0.130580 Train acc: 0.989231\n",
      "Epoch: 3579/5000 Iteration: 3580 Validation loss: 0.554944 Validation acc: 0.810000\n",
      "Epoch: 3584/5000 Iteration: 3585 Train loss: 0.130305 Train acc: 0.988846\n",
      "Epoch: 3589/5000 Iteration: 3590 Train loss: 0.133120 Train acc: 0.990000\n",
      "Epoch: 3589/5000 Iteration: 3590 Validation loss: 0.570811 Validation acc: 0.810000\n",
      "Epoch: 3594/5000 Iteration: 3595 Train loss: 0.129450 Train acc: 0.990769\n",
      "Epoch: 3599/5000 Iteration: 3600 Train loss: 0.131329 Train acc: 0.990769\n",
      "Epoch: 3599/5000 Iteration: 3600 Validation loss: 0.557756 Validation acc: 0.810000\n",
      "Epoch: 3604/5000 Iteration: 3605 Train loss: 0.129622 Train acc: 0.990385\n",
      "Epoch: 3609/5000 Iteration: 3610 Train loss: 0.131933 Train acc: 0.988461\n",
      "Epoch: 3609/5000 Iteration: 3610 Validation loss: 0.541333 Validation acc: 0.810000\n",
      "Epoch: 3614/5000 Iteration: 3615 Train loss: 0.133133 Train acc: 0.988462\n",
      "Epoch: 3619/5000 Iteration: 3620 Train loss: 0.134336 Train acc: 0.988461\n",
      "Epoch: 3619/5000 Iteration: 3620 Validation loss: 0.571021 Validation acc: 0.790000\n",
      "Epoch: 3624/5000 Iteration: 3625 Train loss: 0.131550 Train acc: 0.987692\n",
      "Epoch: 3629/5000 Iteration: 3630 Train loss: 0.133836 Train acc: 0.989615\n",
      "Epoch: 3629/5000 Iteration: 3630 Validation loss: 0.573829 Validation acc: 0.810000\n",
      "Epoch: 3634/5000 Iteration: 3635 Train loss: 0.131836 Train acc: 0.990000\n",
      "Epoch: 3639/5000 Iteration: 3640 Train loss: 0.131914 Train acc: 0.988461\n",
      "Epoch: 3639/5000 Iteration: 3640 Validation loss: 0.541864 Validation acc: 0.800000\n",
      "Epoch: 3644/5000 Iteration: 3645 Train loss: 0.131688 Train acc: 0.989231\n",
      "Epoch: 3649/5000 Iteration: 3650 Train loss: 0.131912 Train acc: 0.989615\n",
      "Epoch: 3649/5000 Iteration: 3650 Validation loss: 0.571133 Validation acc: 0.840000\n",
      "Epoch: 3654/5000 Iteration: 3655 Train loss: 0.135803 Train acc: 0.988461\n",
      "Epoch: 3659/5000 Iteration: 3660 Train loss: 0.133108 Train acc: 0.990000\n",
      "Epoch: 3659/5000 Iteration: 3660 Validation loss: 0.566070 Validation acc: 0.810000\n",
      "Epoch: 3664/5000 Iteration: 3665 Train loss: 0.131968 Train acc: 0.986923\n",
      "Epoch: 3669/5000 Iteration: 3670 Train loss: 0.131030 Train acc: 0.990385\n",
      "Epoch: 3669/5000 Iteration: 3670 Validation loss: 0.571640 Validation acc: 0.830000\n",
      "Epoch: 3674/5000 Iteration: 3675 Train loss: 0.133261 Train acc: 0.986538\n",
      "Epoch: 3679/5000 Iteration: 3680 Train loss: 0.130810 Train acc: 0.988461\n",
      "Epoch: 3679/5000 Iteration: 3680 Validation loss: 0.551888 Validation acc: 0.800000\n",
      "Epoch: 3684/5000 Iteration: 3685 Train loss: 0.132544 Train acc: 0.988846\n",
      "Epoch: 3689/5000 Iteration: 3690 Train loss: 0.132203 Train acc: 0.990000\n",
      "Epoch: 3689/5000 Iteration: 3690 Validation loss: 0.579796 Validation acc: 0.790000\n",
      "Epoch: 3694/5000 Iteration: 3695 Train loss: 0.128950 Train acc: 0.990769\n",
      "Epoch: 3699/5000 Iteration: 3700 Train loss: 0.128164 Train acc: 0.990385\n",
      "Epoch: 3699/5000 Iteration: 3700 Validation loss: 0.566776 Validation acc: 0.800000\n",
      "Epoch: 3704/5000 Iteration: 3705 Train loss: 0.130813 Train acc: 0.988846\n",
      "Epoch: 3709/5000 Iteration: 3710 Train loss: 0.131362 Train acc: 0.989231\n",
      "Epoch: 3709/5000 Iteration: 3710 Validation loss: 0.566552 Validation acc: 0.810000\n",
      "Epoch: 3714/5000 Iteration: 3715 Train loss: 0.128990 Train acc: 0.989615\n",
      "Epoch: 3719/5000 Iteration: 3720 Train loss: 0.130424 Train acc: 0.989231\n",
      "Epoch: 3719/5000 Iteration: 3720 Validation loss: 0.558450 Validation acc: 0.800000\n",
      "Epoch: 3724/5000 Iteration: 3725 Train loss: 0.131373 Train acc: 0.989615\n",
      "Epoch: 3729/5000 Iteration: 3730 Train loss: 0.130803 Train acc: 0.989615\n",
      "Epoch: 3729/5000 Iteration: 3730 Validation loss: 0.551786 Validation acc: 0.820000\n",
      "Epoch: 3734/5000 Iteration: 3735 Train loss: 0.127921 Train acc: 0.990769\n",
      "Epoch: 3739/5000 Iteration: 3740 Train loss: 0.129430 Train acc: 0.989231\n",
      "Epoch: 3739/5000 Iteration: 3740 Validation loss: 0.542801 Validation acc: 0.850000\n",
      "Epoch: 3744/5000 Iteration: 3745 Train loss: 0.129503 Train acc: 0.989615\n",
      "Epoch: 3749/5000 Iteration: 3750 Train loss: 0.129558 Train acc: 0.990385\n",
      "Epoch: 3749/5000 Iteration: 3750 Validation loss: 0.558525 Validation acc: 0.800000\n",
      "Epoch: 3754/5000 Iteration: 3755 Train loss: 0.132279 Train acc: 0.988077\n",
      "Epoch: 3759/5000 Iteration: 3760 Train loss: 0.130068 Train acc: 0.990385\n",
      "Epoch: 3759/5000 Iteration: 3760 Validation loss: 0.570328 Validation acc: 0.790000\n",
      "Epoch: 3764/5000 Iteration: 3765 Train loss: 0.133738 Train acc: 0.986538\n",
      "Epoch: 3769/5000 Iteration: 3770 Train loss: 0.129712 Train acc: 0.988461\n",
      "Epoch: 3769/5000 Iteration: 3770 Validation loss: 0.557815 Validation acc: 0.800000\n",
      "Epoch: 3774/5000 Iteration: 3775 Train loss: 0.130445 Train acc: 0.989615\n",
      "Epoch: 3779/5000 Iteration: 3780 Train loss: 0.129266 Train acc: 0.990000\n",
      "Epoch: 3779/5000 Iteration: 3780 Validation loss: 0.559034 Validation acc: 0.810000\n",
      "Epoch: 3784/5000 Iteration: 3785 Train loss: 0.130065 Train acc: 0.988077\n",
      "Epoch: 3789/5000 Iteration: 3790 Train loss: 0.131030 Train acc: 0.987692\n",
      "Epoch: 3789/5000 Iteration: 3790 Validation loss: 0.568637 Validation acc: 0.800000\n",
      "Epoch: 3794/5000 Iteration: 3795 Train loss: 0.127451 Train acc: 0.992308\n",
      "Epoch: 3799/5000 Iteration: 3800 Train loss: 0.128273 Train acc: 0.988077\n",
      "Epoch: 3799/5000 Iteration: 3800 Validation loss: 0.560761 Validation acc: 0.800000\n",
      "Epoch: 3804/5000 Iteration: 3805 Train loss: 0.126723 Train acc: 0.989231\n",
      "Epoch: 3809/5000 Iteration: 3810 Train loss: 0.131767 Train acc: 0.988077\n",
      "Epoch: 3809/5000 Iteration: 3810 Validation loss: 0.563533 Validation acc: 0.800000\n",
      "Epoch: 3814/5000 Iteration: 3815 Train loss: 0.129905 Train acc: 0.987692\n",
      "Epoch: 3819/5000 Iteration: 3820 Train loss: 0.129430 Train acc: 0.987692\n",
      "Epoch: 3819/5000 Iteration: 3820 Validation loss: 0.559029 Validation acc: 0.790000\n",
      "Epoch: 3824/5000 Iteration: 3825 Train loss: 0.125124 Train acc: 0.992308\n",
      "Epoch: 3829/5000 Iteration: 3830 Train loss: 0.127639 Train acc: 0.991538\n",
      "Epoch: 3829/5000 Iteration: 3830 Validation loss: 0.561487 Validation acc: 0.810000\n",
      "Epoch: 3834/5000 Iteration: 3835 Train loss: 0.129661 Train acc: 0.988846\n",
      "Epoch: 3839/5000 Iteration: 3840 Train loss: 0.126760 Train acc: 0.991538\n",
      "Epoch: 3839/5000 Iteration: 3840 Validation loss: 0.568781 Validation acc: 0.810000\n",
      "Epoch: 3844/5000 Iteration: 3845 Train loss: 0.129917 Train acc: 0.987308\n",
      "Epoch: 3849/5000 Iteration: 3850 Train loss: 0.129490 Train acc: 0.990385\n",
      "Epoch: 3849/5000 Iteration: 3850 Validation loss: 0.555272 Validation acc: 0.860000\n",
      "Epoch: 3854/5000 Iteration: 3855 Train loss: 0.129804 Train acc: 0.987692\n",
      "Epoch: 3859/5000 Iteration: 3860 Train loss: 0.127826 Train acc: 0.990769\n",
      "Epoch: 3859/5000 Iteration: 3860 Validation loss: 0.563035 Validation acc: 0.780000\n",
      "Epoch: 3864/5000 Iteration: 3865 Train loss: 0.128158 Train acc: 0.988846\n",
      "Epoch: 3869/5000 Iteration: 3870 Train loss: 0.126618 Train acc: 0.989615\n",
      "Epoch: 3869/5000 Iteration: 3870 Validation loss: 0.547013 Validation acc: 0.810000\n",
      "Epoch: 3874/5000 Iteration: 3875 Train loss: 0.128307 Train acc: 0.989231\n",
      "Epoch: 3879/5000 Iteration: 3880 Train loss: 0.127296 Train acc: 0.991154\n",
      "Epoch: 3879/5000 Iteration: 3880 Validation loss: 0.549056 Validation acc: 0.790000\n",
      "Epoch: 3884/5000 Iteration: 3885 Train loss: 0.128917 Train acc: 0.988846\n",
      "Epoch: 3889/5000 Iteration: 3890 Train loss: 0.126733 Train acc: 0.991154\n",
      "Epoch: 3889/5000 Iteration: 3890 Validation loss: 0.564574 Validation acc: 0.810000\n",
      "Epoch: 3894/5000 Iteration: 3895 Train loss: 0.128455 Train acc: 0.988846\n",
      "Epoch: 3899/5000 Iteration: 3900 Train loss: 0.128201 Train acc: 0.989231\n",
      "Epoch: 3899/5000 Iteration: 3900 Validation loss: 0.540151 Validation acc: 0.800000\n",
      "Epoch: 3904/5000 Iteration: 3905 Train loss: 0.130482 Train acc: 0.989231\n",
      "Epoch: 3909/5000 Iteration: 3910 Train loss: 0.132877 Train acc: 0.987308\n",
      "Epoch: 3909/5000 Iteration: 3910 Validation loss: 0.549619 Validation acc: 0.810000\n",
      "Epoch: 3914/5000 Iteration: 3915 Train loss: 0.127553 Train acc: 0.989615\n",
      "Epoch: 3919/5000 Iteration: 3920 Train loss: 0.127840 Train acc: 0.991154\n",
      "Epoch: 3919/5000 Iteration: 3920 Validation loss: 0.593376 Validation acc: 0.810000\n",
      "Epoch: 3924/5000 Iteration: 3925 Train loss: 0.123631 Train acc: 0.993077\n",
      "Epoch: 3929/5000 Iteration: 3930 Train loss: 0.131159 Train acc: 0.989231\n",
      "Epoch: 3929/5000 Iteration: 3930 Validation loss: 0.557747 Validation acc: 0.830000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3934/5000 Iteration: 3935 Train loss: 0.128653 Train acc: 0.987308\n",
      "Epoch: 3939/5000 Iteration: 3940 Train loss: 0.124965 Train acc: 0.991923\n",
      "Epoch: 3939/5000 Iteration: 3940 Validation loss: 0.550319 Validation acc: 0.870000\n",
      "Epoch: 3944/5000 Iteration: 3945 Train loss: 0.126735 Train acc: 0.990384\n",
      "Epoch: 3949/5000 Iteration: 3950 Train loss: 0.129538 Train acc: 0.987308\n",
      "Epoch: 3949/5000 Iteration: 3950 Validation loss: 0.547785 Validation acc: 0.820000\n",
      "Epoch: 3954/5000 Iteration: 3955 Train loss: 0.127727 Train acc: 0.990000\n",
      "Epoch: 3959/5000 Iteration: 3960 Train loss: 0.126711 Train acc: 0.991538\n",
      "Epoch: 3959/5000 Iteration: 3960 Validation loss: 0.569477 Validation acc: 0.880000\n",
      "Epoch: 3964/5000 Iteration: 3965 Train loss: 0.127029 Train acc: 0.990385\n",
      "Epoch: 3969/5000 Iteration: 3970 Train loss: 0.131509 Train acc: 0.987308\n",
      "Epoch: 3969/5000 Iteration: 3970 Validation loss: 0.584149 Validation acc: 0.820000\n",
      "Epoch: 3974/5000 Iteration: 3975 Train loss: 0.129196 Train acc: 0.989231\n",
      "Epoch: 3979/5000 Iteration: 3980 Train loss: 0.124451 Train acc: 0.988461\n",
      "Epoch: 3979/5000 Iteration: 3980 Validation loss: 0.557879 Validation acc: 0.810000\n",
      "Epoch: 3984/5000 Iteration: 3985 Train loss: 0.126790 Train acc: 0.990385\n",
      "Epoch: 3989/5000 Iteration: 3990 Train loss: 0.127008 Train acc: 0.990385\n",
      "Epoch: 3989/5000 Iteration: 3990 Validation loss: 0.540388 Validation acc: 0.820000\n",
      "Epoch: 3994/5000 Iteration: 3995 Train loss: 0.131131 Train acc: 0.986923\n",
      "Epoch: 3999/5000 Iteration: 4000 Train loss: 0.128975 Train acc: 0.988077\n",
      "Epoch: 3999/5000 Iteration: 4000 Validation loss: 0.569071 Validation acc: 0.810000\n",
      "Epoch: 4004/5000 Iteration: 4005 Train loss: 0.126918 Train acc: 0.989231\n",
      "Epoch: 4009/5000 Iteration: 4010 Train loss: 0.129471 Train acc: 0.987692\n",
      "Epoch: 4009/5000 Iteration: 4010 Validation loss: 0.543741 Validation acc: 0.810000\n",
      "Epoch: 4014/5000 Iteration: 4015 Train loss: 0.125280 Train acc: 0.990385\n",
      "Epoch: 4019/5000 Iteration: 4020 Train loss: 0.124238 Train acc: 0.990385\n",
      "Epoch: 4019/5000 Iteration: 4020 Validation loss: 0.535940 Validation acc: 0.810000\n",
      "Epoch: 4024/5000 Iteration: 4025 Train loss: 0.125914 Train acc: 0.991538\n",
      "Epoch: 4029/5000 Iteration: 4030 Train loss: 0.127439 Train acc: 0.987692\n",
      "Epoch: 4029/5000 Iteration: 4030 Validation loss: 0.567925 Validation acc: 0.800000\n",
      "Epoch: 4034/5000 Iteration: 4035 Train loss: 0.126523 Train acc: 0.988461\n",
      "Epoch: 4039/5000 Iteration: 4040 Train loss: 0.125373 Train acc: 0.991538\n",
      "Epoch: 4039/5000 Iteration: 4040 Validation loss: 0.576332 Validation acc: 0.810000\n",
      "Epoch: 4044/5000 Iteration: 4045 Train loss: 0.124048 Train acc: 0.988462\n",
      "Epoch: 4049/5000 Iteration: 4050 Train loss: 0.128896 Train acc: 0.987692\n",
      "Epoch: 4049/5000 Iteration: 4050 Validation loss: 0.577591 Validation acc: 0.810000\n",
      "Epoch: 4054/5000 Iteration: 4055 Train loss: 0.126206 Train acc: 0.988461\n",
      "Epoch: 4059/5000 Iteration: 4060 Train loss: 0.126340 Train acc: 0.988846\n",
      "Epoch: 4059/5000 Iteration: 4060 Validation loss: 0.552331 Validation acc: 0.800000\n",
      "Epoch: 4064/5000 Iteration: 4065 Train loss: 0.128447 Train acc: 0.987692\n",
      "Epoch: 4069/5000 Iteration: 4070 Train loss: 0.126343 Train acc: 0.989615\n",
      "Epoch: 4069/5000 Iteration: 4070 Validation loss: 0.542976 Validation acc: 0.790000\n",
      "Epoch: 4074/5000 Iteration: 4075 Train loss: 0.123626 Train acc: 0.991538\n",
      "Epoch: 4079/5000 Iteration: 4080 Train loss: 0.131276 Train acc: 0.988077\n",
      "Epoch: 4079/5000 Iteration: 4080 Validation loss: 0.559578 Validation acc: 0.800000\n",
      "Epoch: 4084/5000 Iteration: 4085 Train loss: 0.128006 Train acc: 0.988461\n",
      "Epoch: 4089/5000 Iteration: 4090 Train loss: 0.124218 Train acc: 0.989231\n",
      "Epoch: 4089/5000 Iteration: 4090 Validation loss: 0.592259 Validation acc: 0.800000\n",
      "Epoch: 4094/5000 Iteration: 4095 Train loss: 0.126226 Train acc: 0.990000\n",
      "Epoch: 4099/5000 Iteration: 4100 Train loss: 0.130499 Train acc: 0.987692\n",
      "Epoch: 4099/5000 Iteration: 4100 Validation loss: 0.559879 Validation acc: 0.820000\n",
      "Epoch: 4104/5000 Iteration: 4105 Train loss: 0.128473 Train acc: 0.989231\n",
      "Epoch: 4109/5000 Iteration: 4110 Train loss: 0.129573 Train acc: 0.988461\n",
      "Epoch: 4109/5000 Iteration: 4110 Validation loss: 0.589009 Validation acc: 0.800000\n",
      "Epoch: 4114/5000 Iteration: 4115 Train loss: 0.126502 Train acc: 0.990769\n",
      "Epoch: 4119/5000 Iteration: 4120 Train loss: 0.125708 Train acc: 0.991923\n",
      "Epoch: 4119/5000 Iteration: 4120 Validation loss: 0.561194 Validation acc: 0.780000\n",
      "Epoch: 4124/5000 Iteration: 4125 Train loss: 0.125090 Train acc: 0.988846\n",
      "Epoch: 4129/5000 Iteration: 4130 Train loss: 0.127945 Train acc: 0.987692\n",
      "Epoch: 4129/5000 Iteration: 4130 Validation loss: 0.582581 Validation acc: 0.800000\n",
      "Epoch: 4134/5000 Iteration: 4135 Train loss: 0.125645 Train acc: 0.989231\n",
      "Epoch: 4139/5000 Iteration: 4140 Train loss: 0.128647 Train acc: 0.988461\n",
      "Epoch: 4139/5000 Iteration: 4140 Validation loss: 0.552445 Validation acc: 0.820000\n",
      "Epoch: 4144/5000 Iteration: 4145 Train loss: 0.124625 Train acc: 0.989231\n",
      "Epoch: 4149/5000 Iteration: 4150 Train loss: 0.124183 Train acc: 0.990769\n",
      "Epoch: 4149/5000 Iteration: 4150 Validation loss: 0.569575 Validation acc: 0.810000\n",
      "Epoch: 4154/5000 Iteration: 4155 Train loss: 0.122803 Train acc: 0.989615\n",
      "Epoch: 4159/5000 Iteration: 4160 Train loss: 0.125971 Train acc: 0.988846\n",
      "Epoch: 4159/5000 Iteration: 4160 Validation loss: 0.555002 Validation acc: 0.800000\n",
      "Epoch: 4164/5000 Iteration: 4165 Train loss: 0.125395 Train acc: 0.988461\n",
      "Epoch: 4169/5000 Iteration: 4170 Train loss: 0.126427 Train acc: 0.987308\n",
      "Epoch: 4169/5000 Iteration: 4170 Validation loss: 0.581834 Validation acc: 0.800000\n",
      "Epoch: 4174/5000 Iteration: 4175 Train loss: 0.122332 Train acc: 0.991923\n",
      "Epoch: 4179/5000 Iteration: 4180 Train loss: 0.126246 Train acc: 0.989615\n",
      "Epoch: 4179/5000 Iteration: 4180 Validation loss: 0.553159 Validation acc: 0.800000\n",
      "Epoch: 4184/5000 Iteration: 4185 Train loss: 0.127518 Train acc: 0.988077\n",
      "Epoch: 4189/5000 Iteration: 4190 Train loss: 0.125450 Train acc: 0.989615\n",
      "Epoch: 4189/5000 Iteration: 4190 Validation loss: 0.576099 Validation acc: 0.790000\n",
      "Epoch: 4194/5000 Iteration: 4195 Train loss: 0.122478 Train acc: 0.990385\n",
      "Epoch: 4199/5000 Iteration: 4200 Train loss: 0.123031 Train acc: 0.990000\n",
      "Epoch: 4199/5000 Iteration: 4200 Validation loss: 0.554103 Validation acc: 0.800000\n",
      "Epoch: 4204/5000 Iteration: 4205 Train loss: 0.127413 Train acc: 0.988077\n",
      "Epoch: 4209/5000 Iteration: 4210 Train loss: 0.126087 Train acc: 0.990769\n",
      "Epoch: 4209/5000 Iteration: 4210 Validation loss: 0.572636 Validation acc: 0.790000\n",
      "Epoch: 4214/5000 Iteration: 4215 Train loss: 0.128977 Train acc: 0.990000\n",
      "Epoch: 4219/5000 Iteration: 4220 Train loss: 0.124346 Train acc: 0.990000\n",
      "Epoch: 4219/5000 Iteration: 4220 Validation loss: 0.577219 Validation acc: 0.800000\n",
      "Epoch: 4224/5000 Iteration: 4225 Train loss: 0.126755 Train acc: 0.988461\n",
      "Epoch: 4229/5000 Iteration: 4230 Train loss: 0.123752 Train acc: 0.990000\n",
      "Epoch: 4229/5000 Iteration: 4230 Validation loss: 0.570124 Validation acc: 0.840000\n",
      "Epoch: 4234/5000 Iteration: 4235 Train loss: 0.125218 Train acc: 0.988461\n",
      "Epoch: 4239/5000 Iteration: 4240 Train loss: 0.127497 Train acc: 0.990000\n",
      "Epoch: 4239/5000 Iteration: 4240 Validation loss: 0.571356 Validation acc: 0.810000\n",
      "Epoch: 4244/5000 Iteration: 4245 Train loss: 0.131210 Train acc: 0.988077\n",
      "Epoch: 4249/5000 Iteration: 4250 Train loss: 0.128011 Train acc: 0.988461\n",
      "Epoch: 4249/5000 Iteration: 4250 Validation loss: 0.555552 Validation acc: 0.850000\n",
      "Epoch: 4254/5000 Iteration: 4255 Train loss: 0.125523 Train acc: 0.989231\n",
      "Epoch: 4259/5000 Iteration: 4260 Train loss: 0.126863 Train acc: 0.990000\n",
      "Epoch: 4259/5000 Iteration: 4260 Validation loss: 0.614539 Validation acc: 0.790000\n",
      "Epoch: 4264/5000 Iteration: 4265 Train loss: 0.121410 Train acc: 0.991538\n",
      "Epoch: 4269/5000 Iteration: 4270 Train loss: 0.128554 Train acc: 0.988077\n",
      "Epoch: 4269/5000 Iteration: 4270 Validation loss: 0.576685 Validation acc: 0.790000\n",
      "Epoch: 4274/5000 Iteration: 4275 Train loss: 0.124903 Train acc: 0.990000\n",
      "Epoch: 4279/5000 Iteration: 4280 Train loss: 0.124721 Train acc: 0.990000\n",
      "Epoch: 4279/5000 Iteration: 4280 Validation loss: 0.562960 Validation acc: 0.790000\n",
      "Epoch: 4284/5000 Iteration: 4285 Train loss: 0.121289 Train acc: 0.990385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4289/5000 Iteration: 4290 Train loss: 0.120779 Train acc: 0.991923\n",
      "Epoch: 4289/5000 Iteration: 4290 Validation loss: 0.586816 Validation acc: 0.790000\n",
      "Epoch: 4294/5000 Iteration: 4295 Train loss: 0.125183 Train acc: 0.988461\n",
      "Epoch: 4299/5000 Iteration: 4300 Train loss: 0.126314 Train acc: 0.988461\n",
      "Epoch: 4299/5000 Iteration: 4300 Validation loss: 0.540605 Validation acc: 0.800000\n",
      "Epoch: 4304/5000 Iteration: 4305 Train loss: 0.119937 Train acc: 0.991923\n",
      "Epoch: 4309/5000 Iteration: 4310 Train loss: 0.130289 Train acc: 0.987692\n",
      "Epoch: 4309/5000 Iteration: 4310 Validation loss: 0.588918 Validation acc: 0.800000\n",
      "Epoch: 4314/5000 Iteration: 4315 Train loss: 0.123591 Train acc: 0.989231\n",
      "Epoch: 4319/5000 Iteration: 4320 Train loss: 0.121671 Train acc: 0.991154\n",
      "Epoch: 4319/5000 Iteration: 4320 Validation loss: 0.555749 Validation acc: 0.810000\n",
      "Epoch: 4324/5000 Iteration: 4325 Train loss: 0.123279 Train acc: 0.991154\n",
      "Epoch: 4329/5000 Iteration: 4330 Train loss: 0.123077 Train acc: 0.990385\n",
      "Epoch: 4329/5000 Iteration: 4330 Validation loss: 0.546693 Validation acc: 0.820000\n",
      "Epoch: 4334/5000 Iteration: 4335 Train loss: 0.120595 Train acc: 0.991538\n",
      "Epoch: 4339/5000 Iteration: 4340 Train loss: 0.122461 Train acc: 0.987692\n",
      "Epoch: 4339/5000 Iteration: 4340 Validation loss: 0.570884 Validation acc: 0.810000\n",
      "Epoch: 4344/5000 Iteration: 4345 Train loss: 0.123914 Train acc: 0.989615\n",
      "Epoch: 4349/5000 Iteration: 4350 Train loss: 0.120027 Train acc: 0.992308\n",
      "Epoch: 4349/5000 Iteration: 4350 Validation loss: 0.554097 Validation acc: 0.810000\n",
      "Epoch: 4354/5000 Iteration: 4355 Train loss: 0.123292 Train acc: 0.988846\n",
      "Epoch: 4359/5000 Iteration: 4360 Train loss: 0.122593 Train acc: 0.988461\n",
      "Epoch: 4359/5000 Iteration: 4360 Validation loss: 0.577362 Validation acc: 0.810000\n",
      "Epoch: 4364/5000 Iteration: 4365 Train loss: 0.123434 Train acc: 0.988077\n",
      "Epoch: 4369/5000 Iteration: 4370 Train loss: 0.121399 Train acc: 0.991154\n",
      "Epoch: 4369/5000 Iteration: 4370 Validation loss: 0.571032 Validation acc: 0.810000\n",
      "Epoch: 4374/5000 Iteration: 4375 Train loss: 0.121483 Train acc: 0.990769\n",
      "Epoch: 4379/5000 Iteration: 4380 Train loss: 0.120868 Train acc: 0.991923\n",
      "Epoch: 4379/5000 Iteration: 4380 Validation loss: 0.586118 Validation acc: 0.800000\n",
      "Epoch: 4384/5000 Iteration: 4385 Train loss: 0.122782 Train acc: 0.989615\n",
      "Epoch: 4389/5000 Iteration: 4390 Train loss: 0.118456 Train acc: 0.991923\n",
      "Epoch: 4389/5000 Iteration: 4390 Validation loss: 0.587499 Validation acc: 0.800000\n",
      "Epoch: 4394/5000 Iteration: 4395 Train loss: 0.126469 Train acc: 0.987692\n",
      "Epoch: 4399/5000 Iteration: 4400 Train loss: 0.123984 Train acc: 0.988077\n",
      "Epoch: 4399/5000 Iteration: 4400 Validation loss: 0.531623 Validation acc: 0.850000\n",
      "Epoch: 4404/5000 Iteration: 4405 Train loss: 0.120581 Train acc: 0.990385\n",
      "Epoch: 4409/5000 Iteration: 4410 Train loss: 0.120479 Train acc: 0.990385\n",
      "Epoch: 4409/5000 Iteration: 4410 Validation loss: 0.537417 Validation acc: 0.810000\n",
      "Epoch: 4414/5000 Iteration: 4415 Train loss: 0.118462 Train acc: 0.991923\n",
      "Epoch: 4419/5000 Iteration: 4420 Train loss: 0.118901 Train acc: 0.990385\n",
      "Epoch: 4419/5000 Iteration: 4420 Validation loss: 0.569737 Validation acc: 0.800000\n",
      "Epoch: 4424/5000 Iteration: 4425 Train loss: 0.124014 Train acc: 0.989615\n",
      "Epoch: 4429/5000 Iteration: 4430 Train loss: 0.121910 Train acc: 0.991154\n",
      "Epoch: 4429/5000 Iteration: 4430 Validation loss: 0.604378 Validation acc: 0.790000\n",
      "Epoch: 4434/5000 Iteration: 4435 Train loss: 0.120558 Train acc: 0.990000\n",
      "Epoch: 4439/5000 Iteration: 4440 Train loss: 0.119445 Train acc: 0.991538\n",
      "Epoch: 4439/5000 Iteration: 4440 Validation loss: 0.578251 Validation acc: 0.800000\n",
      "Epoch: 4444/5000 Iteration: 4445 Train loss: 0.120537 Train acc: 0.991154\n",
      "Epoch: 4449/5000 Iteration: 4450 Train loss: 0.120627 Train acc: 0.991154\n",
      "Epoch: 4449/5000 Iteration: 4450 Validation loss: 0.568080 Validation acc: 0.800000\n",
      "Epoch: 4454/5000 Iteration: 4455 Train loss: 0.120947 Train acc: 0.992308\n",
      "Epoch: 4459/5000 Iteration: 4460 Train loss: 0.123638 Train acc: 0.990000\n",
      "Epoch: 4459/5000 Iteration: 4460 Validation loss: 0.558949 Validation acc: 0.820000\n",
      "Epoch: 4464/5000 Iteration: 4465 Train loss: 0.122261 Train acc: 0.990769\n",
      "Epoch: 4469/5000 Iteration: 4470 Train loss: 0.122281 Train acc: 0.990000\n",
      "Epoch: 4469/5000 Iteration: 4470 Validation loss: 0.582066 Validation acc: 0.790000\n",
      "Epoch: 4474/5000 Iteration: 4475 Train loss: 0.122683 Train acc: 0.988462\n",
      "Epoch: 4479/5000 Iteration: 4480 Train loss: 0.121739 Train acc: 0.990000\n",
      "Epoch: 4479/5000 Iteration: 4480 Validation loss: 0.564142 Validation acc: 0.800000\n",
      "Epoch: 4484/5000 Iteration: 4485 Train loss: 0.123030 Train acc: 0.990000\n",
      "Epoch: 4489/5000 Iteration: 4490 Train loss: 0.122848 Train acc: 0.988461\n",
      "Epoch: 4489/5000 Iteration: 4490 Validation loss: 0.598590 Validation acc: 0.800000\n",
      "Epoch: 4494/5000 Iteration: 4495 Train loss: 0.121444 Train acc: 0.991154\n",
      "Epoch: 4499/5000 Iteration: 4500 Train loss: 0.122002 Train acc: 0.991538\n",
      "Epoch: 4499/5000 Iteration: 4500 Validation loss: 0.575857 Validation acc: 0.860000\n",
      "Epoch: 4504/5000 Iteration: 4505 Train loss: 0.121558 Train acc: 0.990000\n",
      "Epoch: 4509/5000 Iteration: 4510 Train loss: 0.120473 Train acc: 0.991154\n",
      "Epoch: 4509/5000 Iteration: 4510 Validation loss: 0.575348 Validation acc: 0.800000\n",
      "Epoch: 4514/5000 Iteration: 4515 Train loss: 0.122223 Train acc: 0.989231\n",
      "Epoch: 4519/5000 Iteration: 4520 Train loss: 0.123277 Train acc: 0.988461\n",
      "Epoch: 4519/5000 Iteration: 4520 Validation loss: 0.546958 Validation acc: 0.810000\n",
      "Epoch: 4524/5000 Iteration: 4525 Train loss: 0.121152 Train acc: 0.990000\n",
      "Epoch: 4529/5000 Iteration: 4530 Train loss: 0.121942 Train acc: 0.991154\n",
      "Epoch: 4529/5000 Iteration: 4530 Validation loss: 0.557022 Validation acc: 0.800000\n",
      "Epoch: 4534/5000 Iteration: 4535 Train loss: 0.118549 Train acc: 0.989615\n",
      "Epoch: 4539/5000 Iteration: 4540 Train loss: 0.121051 Train acc: 0.991154\n",
      "Epoch: 4539/5000 Iteration: 4540 Validation loss: 0.566067 Validation acc: 0.790000\n",
      "Epoch: 4544/5000 Iteration: 4545 Train loss: 0.120056 Train acc: 0.991154\n",
      "Epoch: 4549/5000 Iteration: 4550 Train loss: 0.123489 Train acc: 0.989231\n",
      "Epoch: 4549/5000 Iteration: 4550 Validation loss: 0.550948 Validation acc: 0.800000\n",
      "Epoch: 4554/5000 Iteration: 4555 Train loss: 0.122662 Train acc: 0.990385\n",
      "Epoch: 4559/5000 Iteration: 4560 Train loss: 0.121227 Train acc: 0.990769\n",
      "Epoch: 4559/5000 Iteration: 4560 Validation loss: 0.591114 Validation acc: 0.810000\n",
      "Epoch: 4564/5000 Iteration: 4565 Train loss: 0.121934 Train acc: 0.989615\n",
      "Epoch: 4569/5000 Iteration: 4570 Train loss: 0.123218 Train acc: 0.989231\n",
      "Epoch: 4569/5000 Iteration: 4570 Validation loss: 0.543497 Validation acc: 0.810000\n",
      "Epoch: 4574/5000 Iteration: 4575 Train loss: 0.119473 Train acc: 0.989231\n",
      "Epoch: 4579/5000 Iteration: 4580 Train loss: 0.122308 Train acc: 0.990000\n",
      "Epoch: 4579/5000 Iteration: 4580 Validation loss: 0.572398 Validation acc: 0.810000\n",
      "Epoch: 4584/5000 Iteration: 4585 Train loss: 0.122712 Train acc: 0.988846\n",
      "Epoch: 4589/5000 Iteration: 4590 Train loss: 0.124052 Train acc: 0.988461\n",
      "Epoch: 4589/5000 Iteration: 4590 Validation loss: 0.556798 Validation acc: 0.810000\n",
      "Epoch: 4594/5000 Iteration: 4595 Train loss: 0.119725 Train acc: 0.991154\n",
      "Epoch: 4599/5000 Iteration: 4600 Train loss: 0.120718 Train acc: 0.988077\n",
      "Epoch: 4599/5000 Iteration: 4600 Validation loss: 0.574438 Validation acc: 0.810000\n",
      "Epoch: 4604/5000 Iteration: 4605 Train loss: 0.121887 Train acc: 0.990000\n",
      "Epoch: 4609/5000 Iteration: 4610 Train loss: 0.124039 Train acc: 0.988077\n",
      "Epoch: 4609/5000 Iteration: 4610 Validation loss: 0.571849 Validation acc: 0.870000\n",
      "Epoch: 4614/5000 Iteration: 4615 Train loss: 0.120087 Train acc: 0.989615\n",
      "Epoch: 4619/5000 Iteration: 4620 Train loss: 0.122458 Train acc: 0.987308\n",
      "Epoch: 4619/5000 Iteration: 4620 Validation loss: 0.566669 Validation acc: 0.820000\n",
      "Epoch: 4624/5000 Iteration: 4625 Train loss: 0.119683 Train acc: 0.988077\n",
      "Epoch: 4629/5000 Iteration: 4630 Train loss: 0.117844 Train acc: 0.991538\n",
      "Epoch: 4629/5000 Iteration: 4630 Validation loss: 0.567006 Validation acc: 0.800000\n",
      "Epoch: 4634/5000 Iteration: 4635 Train loss: 0.119267 Train acc: 0.990385\n",
      "Epoch: 4639/5000 Iteration: 4640 Train loss: 0.121397 Train acc: 0.990000\n",
      "Epoch: 4639/5000 Iteration: 4640 Validation loss: 0.550416 Validation acc: 0.840000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4644/5000 Iteration: 4645 Train loss: 0.119535 Train acc: 0.989615\n",
      "Epoch: 4649/5000 Iteration: 4650 Train loss: 0.117187 Train acc: 0.990000\n",
      "Epoch: 4649/5000 Iteration: 4650 Validation loss: 0.568688 Validation acc: 0.810000\n",
      "Epoch: 4654/5000 Iteration: 4655 Train loss: 0.116432 Train acc: 0.991538\n",
      "Epoch: 4659/5000 Iteration: 4660 Train loss: 0.118162 Train acc: 0.990769\n",
      "Epoch: 4659/5000 Iteration: 4660 Validation loss: 0.569758 Validation acc: 0.810000\n",
      "Epoch: 4664/5000 Iteration: 4665 Train loss: 0.116997 Train acc: 0.990769\n",
      "Epoch: 4669/5000 Iteration: 4670 Train loss: 0.120457 Train acc: 0.988461\n",
      "Epoch: 4669/5000 Iteration: 4670 Validation loss: 0.570874 Validation acc: 0.800000\n",
      "Epoch: 4674/5000 Iteration: 4675 Train loss: 0.120009 Train acc: 0.989615\n",
      "Epoch: 4679/5000 Iteration: 4680 Train loss: 0.120520 Train acc: 0.989615\n",
      "Epoch: 4679/5000 Iteration: 4680 Validation loss: 0.567368 Validation acc: 0.800000\n",
      "Epoch: 4684/5000 Iteration: 4685 Train loss: 0.123574 Train acc: 0.987692\n",
      "Epoch: 4689/5000 Iteration: 4690 Train loss: 0.120446 Train acc: 0.989231\n",
      "Epoch: 4689/5000 Iteration: 4690 Validation loss: 0.560456 Validation acc: 0.840000\n",
      "Epoch: 4694/5000 Iteration: 4695 Train loss: 0.121366 Train acc: 0.990385\n",
      "Epoch: 4699/5000 Iteration: 4700 Train loss: 0.122746 Train acc: 0.989231\n",
      "Epoch: 4699/5000 Iteration: 4700 Validation loss: 0.562828 Validation acc: 0.810000\n",
      "Epoch: 4704/5000 Iteration: 4705 Train loss: 0.120056 Train acc: 0.991923\n",
      "Epoch: 4709/5000 Iteration: 4710 Train loss: 0.118629 Train acc: 0.991923\n",
      "Epoch: 4709/5000 Iteration: 4710 Validation loss: 0.595608 Validation acc: 0.800000\n",
      "Epoch: 4714/5000 Iteration: 4715 Train loss: 0.121956 Train acc: 0.988462\n",
      "Epoch: 4719/5000 Iteration: 4720 Train loss: 0.119611 Train acc: 0.988846\n",
      "Epoch: 4719/5000 Iteration: 4720 Validation loss: 0.565444 Validation acc: 0.800000\n",
      "Epoch: 4724/5000 Iteration: 4725 Train loss: 0.117768 Train acc: 0.992308\n",
      "Epoch: 4729/5000 Iteration: 4730 Train loss: 0.120237 Train acc: 0.990769\n",
      "Epoch: 4729/5000 Iteration: 4730 Validation loss: 0.590040 Validation acc: 0.800000\n",
      "Epoch: 4734/5000 Iteration: 4735 Train loss: 0.119125 Train acc: 0.988077\n",
      "Epoch: 4739/5000 Iteration: 4740 Train loss: 0.118431 Train acc: 0.991538\n",
      "Epoch: 4739/5000 Iteration: 4740 Validation loss: 0.588531 Validation acc: 0.790000\n",
      "Epoch: 4744/5000 Iteration: 4745 Train loss: 0.121449 Train acc: 0.988077\n",
      "Epoch: 4749/5000 Iteration: 4750 Train loss: 0.117674 Train acc: 0.990769\n",
      "Epoch: 4749/5000 Iteration: 4750 Validation loss: 0.556950 Validation acc: 0.800000\n",
      "Epoch: 4754/5000 Iteration: 4755 Train loss: 0.119222 Train acc: 0.988077\n",
      "Epoch: 4759/5000 Iteration: 4760 Train loss: 0.117457 Train acc: 0.989615\n",
      "Epoch: 4759/5000 Iteration: 4760 Validation loss: 0.547038 Validation acc: 0.800000\n",
      "Epoch: 4764/5000 Iteration: 4765 Train loss: 0.119327 Train acc: 0.990000\n",
      "Epoch: 4769/5000 Iteration: 4770 Train loss: 0.119944 Train acc: 0.991154\n",
      "Epoch: 4769/5000 Iteration: 4770 Validation loss: 0.576178 Validation acc: 0.800000\n",
      "Epoch: 4774/5000 Iteration: 4775 Train loss: 0.118419 Train acc: 0.990000\n",
      "Epoch: 4779/5000 Iteration: 4780 Train loss: 0.118987 Train acc: 0.990000\n",
      "Epoch: 4779/5000 Iteration: 4780 Validation loss: 0.571218 Validation acc: 0.810000\n",
      "Epoch: 4784/5000 Iteration: 4785 Train loss: 0.115969 Train acc: 0.991923\n",
      "Epoch: 4789/5000 Iteration: 4790 Train loss: 0.121405 Train acc: 0.987692\n",
      "Epoch: 4789/5000 Iteration: 4790 Validation loss: 0.543121 Validation acc: 0.840000\n",
      "Epoch: 4794/5000 Iteration: 4795 Train loss: 0.115575 Train acc: 0.991154\n",
      "Epoch: 4799/5000 Iteration: 4800 Train loss: 0.120266 Train acc: 0.989231\n",
      "Epoch: 4799/5000 Iteration: 4800 Validation loss: 0.578758 Validation acc: 0.800000\n",
      "Epoch: 4804/5000 Iteration: 4805 Train loss: 0.124562 Train acc: 0.986538\n",
      "Epoch: 4809/5000 Iteration: 4810 Train loss: 0.115234 Train acc: 0.990769\n",
      "Epoch: 4809/5000 Iteration: 4810 Validation loss: 0.563610 Validation acc: 0.810000\n",
      "Epoch: 4814/5000 Iteration: 4815 Train loss: 0.117151 Train acc: 0.990769\n",
      "Epoch: 4819/5000 Iteration: 4820 Train loss: 0.116031 Train acc: 0.990385\n",
      "Epoch: 4819/5000 Iteration: 4820 Validation loss: 0.568359 Validation acc: 0.810000\n",
      "Epoch: 4824/5000 Iteration: 4825 Train loss: 0.117066 Train acc: 0.990385\n",
      "Epoch: 4829/5000 Iteration: 4830 Train loss: 0.120738 Train acc: 0.988077\n",
      "Epoch: 4829/5000 Iteration: 4830 Validation loss: 0.545830 Validation acc: 0.810000\n",
      "Epoch: 4834/5000 Iteration: 4835 Train loss: 0.119213 Train acc: 0.989615\n",
      "Epoch: 4839/5000 Iteration: 4840 Train loss: 0.119212 Train acc: 0.988846\n",
      "Epoch: 4839/5000 Iteration: 4840 Validation loss: 0.569307 Validation acc: 0.800000\n",
      "Epoch: 4844/5000 Iteration: 4845 Train loss: 0.118588 Train acc: 0.990000\n",
      "Epoch: 4849/5000 Iteration: 4850 Train loss: 0.116080 Train acc: 0.992308\n",
      "Epoch: 4849/5000 Iteration: 4850 Validation loss: 0.559937 Validation acc: 0.810000\n",
      "Epoch: 4854/5000 Iteration: 4855 Train loss: 0.118113 Train acc: 0.989615\n",
      "Epoch: 4859/5000 Iteration: 4860 Train loss: 0.120430 Train acc: 0.988846\n",
      "Epoch: 4859/5000 Iteration: 4860 Validation loss: 0.550986 Validation acc: 0.820000\n",
      "Epoch: 4864/5000 Iteration: 4865 Train loss: 0.118881 Train acc: 0.992692\n",
      "Epoch: 4869/5000 Iteration: 4870 Train loss: 0.120120 Train acc: 0.990385\n",
      "Epoch: 4869/5000 Iteration: 4870 Validation loss: 0.527411 Validation acc: 0.800000\n",
      "Epoch: 4874/5000 Iteration: 4875 Train loss: 0.118318 Train acc: 0.990769\n",
      "Epoch: 4879/5000 Iteration: 4880 Train loss: 0.117329 Train acc: 0.990385\n",
      "Epoch: 4879/5000 Iteration: 4880 Validation loss: 0.587197 Validation acc: 0.790000\n",
      "Epoch: 4884/5000 Iteration: 4885 Train loss: 0.120080 Train acc: 0.988461\n",
      "Epoch: 4889/5000 Iteration: 4890 Train loss: 0.116240 Train acc: 0.991923\n",
      "Epoch: 4889/5000 Iteration: 4890 Validation loss: 0.566528 Validation acc: 0.840000\n",
      "Epoch: 4894/5000 Iteration: 4895 Train loss: 0.117542 Train acc: 0.991538\n",
      "Epoch: 4899/5000 Iteration: 4900 Train loss: 0.115815 Train acc: 0.991538\n",
      "Epoch: 4899/5000 Iteration: 4900 Validation loss: 0.551639 Validation acc: 0.810000\n",
      "Epoch: 4904/5000 Iteration: 4905 Train loss: 0.119722 Train acc: 0.988846\n",
      "Epoch: 4909/5000 Iteration: 4910 Train loss: 0.118673 Train acc: 0.989615\n",
      "Epoch: 4909/5000 Iteration: 4910 Validation loss: 0.588767 Validation acc: 0.800000\n",
      "Epoch: 4914/5000 Iteration: 4915 Train loss: 0.120177 Train acc: 0.990769\n",
      "Epoch: 4919/5000 Iteration: 4920 Train loss: 0.119460 Train acc: 0.989615\n",
      "Epoch: 4919/5000 Iteration: 4920 Validation loss: 0.563303 Validation acc: 0.870000\n",
      "Epoch: 4924/5000 Iteration: 4925 Train loss: 0.116557 Train acc: 0.990000\n",
      "Epoch: 4929/5000 Iteration: 4930 Train loss: 0.119532 Train acc: 0.987308\n",
      "Epoch: 4929/5000 Iteration: 4930 Validation loss: 0.574502 Validation acc: 0.790000\n",
      "Epoch: 4934/5000 Iteration: 4935 Train loss: 0.118962 Train acc: 0.988846\n",
      "Epoch: 4939/5000 Iteration: 4940 Train loss: 0.120139 Train acc: 0.990385\n",
      "Epoch: 4939/5000 Iteration: 4940 Validation loss: 0.575447 Validation acc: 0.810000\n",
      "Epoch: 4944/5000 Iteration: 4945 Train loss: 0.118676 Train acc: 0.988461\n",
      "Epoch: 4949/5000 Iteration: 4950 Train loss: 0.117597 Train acc: 0.988846\n",
      "Epoch: 4949/5000 Iteration: 4950 Validation loss: 0.570021 Validation acc: 0.800000\n",
      "Epoch: 4954/5000 Iteration: 4955 Train loss: 0.117736 Train acc: 0.991923\n",
      "Epoch: 4959/5000 Iteration: 4960 Train loss: 0.117176 Train acc: 0.991154\n",
      "Epoch: 4959/5000 Iteration: 4960 Validation loss: 0.554282 Validation acc: 0.850000\n",
      "Epoch: 4964/5000 Iteration: 4965 Train loss: 0.120348 Train acc: 0.987692\n",
      "Epoch: 4969/5000 Iteration: 4970 Train loss: 0.117748 Train acc: 0.989615\n",
      "Epoch: 4969/5000 Iteration: 4970 Validation loss: 0.550768 Validation acc: 0.810000\n",
      "Epoch: 4974/5000 Iteration: 4975 Train loss: 0.120998 Train acc: 0.986538\n",
      "Epoch: 4979/5000 Iteration: 4980 Train loss: 0.116306 Train acc: 0.990769\n",
      "Epoch: 4979/5000 Iteration: 4980 Validation loss: 0.605421 Validation acc: 0.790000\n",
      "Epoch: 4984/5000 Iteration: 4985 Train loss: 0.120824 Train acc: 0.987692\n",
      "Epoch: 4989/5000 Iteration: 4990 Train loss: 0.117118 Train acc: 0.990000\n",
      "Epoch: 4989/5000 Iteration: 4990 Validation loss: 0.537946 Validation acc: 0.880000\n",
      "Epoch: 4994/5000 Iteration: 4995 Train loss: 0.119673 Train acc: 0.990769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4999/5000 Iteration: 5000 Train loss: 0.119412 Train acc: 0.990769\n",
      "Epoch: 4999/5000 Iteration: 5000 Validation loss: 0.593975 Validation acc: 0.810000\n",
      "INFO:tensorflow:Froze 10 variables.\n",
      "Converted 10 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(\"tensorflow运行版本：\" + tf.__version__)\n",
    "#设置相关参数\n",
    "batch_size = 2600  # Batch size\n",
    "features_num = 106        # Number of steps\n",
    "learning_rate = 0.00025\n",
    "epochs = 5000\n",
    "n_classes = 5\n",
    "lambda1 = 0.003\n",
    "log_dir = r'./logs'    # 输出日志保存的路径\n",
    "\n",
    "graph = tf.Graph()\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    in_units = 106\n",
    "    h1_units = 900\n",
    "    h2_units = 1024\n",
    "    #第一层全连接层参数\n",
    "    W1 = tf.Variable(tf.truncated_normal([in_units, h1_units], stddev=0.1))\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(W1))\n",
    "    b1 = tf.Variable(tf.zeros([h1_units]))\n",
    "    \n",
    "    #第二层卷积层参数\n",
    "    Wconv1 = tf.Variable(tf.truncated_normal([3, 3, 1, 32], stddev=0.1))\n",
    "    #tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(Wconv1))\n",
    "    bconv1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "    \n",
    "    #第三层卷积层参数\n",
    "    Wconv2 = tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1))\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(Wconv2))\n",
    "    bconv2 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "    \n",
    "    #第四层全连接层参数\n",
    "    W2 = tf.Variable(tf.truncated_normal([15*15*32, h2_units], stddev=0.1))\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(W2))\n",
    "    b2 = tf.Variable(tf.zeros([h2_units]))\n",
    "    \n",
    "    #第五层全连接层参数\n",
    "    W3 = tf.Variable(tf.zeros([h2_units, 5]))\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(W3))\n",
    "    b3 = tf.Variable(tf.zeros([5]))    \n",
    "    \n",
    "    #构造网络\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, 106], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, 5], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'prob')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')\n",
    "\n",
    "    inputs_ = tf.nn.dropout(inputs_, keep_prob_)\n",
    "    #第一层全连接层，将维度拓展到784\n",
    "    hidden1 = tf.nn.relu(tf.matmul(inputs_, W1) + b1)\n",
    "    hidden1_drop = tf.nn.dropout(hidden1, keep_prob_)\n",
    "    \n",
    "    #将数据转换为2维，送入第二层卷积层\n",
    "    hidden1_drop = tf.reshape(hidden1_drop, [-1, 30, 30, 1])\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(hidden1_drop, Wconv1, strides=[1, 1, 1, 1], padding='SAME') + bconv1)\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    h_pool1 = tf.nn.dropout(h_pool1, keep_prob_)\n",
    "    \n",
    "    #第三层卷积层\n",
    "    h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, Wconv2, strides=[1, 1, 1, 1], padding='SAME') + bconv2)\n",
    "    #h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')    \n",
    "    #h_pool2 = tf.reshape(h_pool2, [-1, 5*5*64])  #将数据转换为1维\n",
    "    h_pool2 = tf.nn.dropout(h_conv2, keep_prob_)\n",
    "    \n",
    "    h_pool2 = tf.reshape(h_pool2, [-1, 15*15*32])  #将数据转换为1维\n",
    "    #第四层全连接层，将维度转换为500\n",
    "    hidden2 = tf.nn.relu(tf.matmul(h_pool2, W2) + b2)\n",
    "    hidden2_drop = tf.nn.dropout(hidden2, keep_prob_)\n",
    "    \n",
    "    #第五层全连接层，维度转换为5，进行5分类\n",
    "    output_ = tf.matmul(hidden2_drop, W3) + b3\n",
    "    # Cost function and optimizer\n",
    "    #二次代价函数，计算预测值与真实值之间的误差代价值-loss，其中第一个参数logits为最后一层输出，第二个为训练目标值即分类值\n",
    "    #先通过Softmax函数，输出X对应输出每一类的概率大小，其次和真实值进行“交叉熵”，最终，对向量求均值，得到代价loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_, labels=labels_))\n",
    "    tf.add_to_collection('losses', loss)\n",
    "    cost = tf.add_n(tf.get_collection('losses'))\n",
    "    #cost = loss\n",
    "    \n",
    "    #梯度下降法，数据量选择AdamOptimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    #correct_pred 返回一个布尔型数组，通过转化为0-1值后来计算准确率\n",
    "    correct_pred = tf.equal(tf.argmax(output_, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    #预测值\n",
    "    pred = tf.argmax(output_, 1, name='cnn')\n",
    "    print(pred)\n",
    "    #正确值\n",
    "    label = tf.argmax(labels_, 1)\n",
    "\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "tf.summary.scalar('loss_function', cost)\n",
    "\n",
    "if (os.path.exists(r'./checkpoints') == False):\n",
    "    !mkdir checkpoints\n",
    "\n",
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    # summaries合并\n",
    "    merged = tf.summary.merge_all()    \n",
    "    # 写到指定的磁盘路径中\n",
    "    train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(log_dir + '/test')\n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_train, y_tr, batch_size):\n",
    "            x = x.reshape((batch_size,features_num))\n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y,keep_prob_ : 0.45, learning_rate_ : learning_rate}\n",
    "             # Loss\n",
    "            summary_str, loss, _ , acc = sess.run([merged, cost, optimizer, accuracy], feed_dict = feed)\n",
    "         \n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "                train_writer.add_summary(summary_str, e);\n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                x_v = X_test.reshape(-1, features_num)\n",
    "                y_v = y_vld\n",
    "                feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0} \n",
    "                summary, loss_v, acc_v, pred_labels = sess.run([merged, cost, accuracy, pred], feed_dict = feed)                    \n",
    "                val_acc_.append(acc_v)\n",
    "                val_loss_.append(loss_v)\n",
    "                \n",
    "                #for x_v, y_v in get_batches(X_test, y_vld, batch_size):\n",
    "                    #x_v = x_v.reshape(batch_size, features_num)\n",
    "                    # Feed\n",
    "                    #feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}                      \n",
    "                    # Loss\n",
    "                    #summary, loss_v, acc_v, pred_labels = sess.run([merged, cost, accuracy, pred], feed_dict = feed)                    \n",
    "                    #val_acc_.append(acc_v)\n",
    "                    #val_loss_.append(loss_v)\n",
    "                    \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                test_writer.add_summary(summary, e);\n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            # Iterate \n",
    "            iteration += 1    \n",
    "            \n",
    "        \n",
    "#     # 保存二进制模型\n",
    "#     output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['labels'])\n",
    "#     with tf.gfile.FastGFile(r'D:\\py_projects\\ML\\ML_Demo\\financial\\creditGrade.pb', mode='wb') as f:\n",
    "#         f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "    saver.save(sess,\"checkpoints-cnn/creditGrade.ckpt\")\n",
    "\n",
    "    # 保存二进制模型\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['cnn'])\n",
    "    with tf.gfile.FastGFile(r'cnn.pb', mode='wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a983c25f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(iteration-1)\n",
    "#print(np.array(train_loss))\n",
    "plt.figure(figsize = (9,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAF3CAYAAABpFHt+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VOW9P/DPNyEhCQRBNkNQSFEri7JFxbqgtlrR6xIqS8H2SmsxVFvbe7vgvd7an7R9dbGt9YogWm/VWpcquLQqYl1wQwEJyCIuARQIARFkScKSfH9/PHOYMydnZs5k5szMmfm8X6955eznOc+cmfnm2Y6oKoiIiIiyXUGmE0BERETkBYMWIiIiCgQGLURERBQIDFqIiIgoEBi0EBERUSAwaCEiIqJAYNBCREREgcCghYiIiAKBQQsREREFAoMWIiIiCoROmU5Aonr16qUDBw7MdDKIiIgoBZYvX/6pqvb2sm3ggpaBAwdi2bJlmU4GERERpYCIbPK6LauHiIiIKBAYtBAREVEgMGghIiKiQAhcmxYiIqJ0OHToEDZv3oyWlpZMJyUnlJSUoH///igqKurwMRi0EBERudi8eTPKy8sxcOBAiEimkxNoqoqdO3di8+bNqKqq6vBxWD1ERETkoqWlBT179mTAkgIigp49eyZdauVb0CIi94rIdhFZHWW9iMjtIvKhiKwSkVF+pYWIiKgjGLCkTiry0s+Slr8AuCjG+nEATgi9pgOY42NaiIiIAmX37t248847E97v4osvxu7du31IUeb5FrSo6mIAn8XY5HIA96uxBEB3EanwKz1ERERBEi1oOXz4cMz9nnnmGXTv3t2vZGVUJhviVgL4xDa/ObSsITPJISIiyh4zZ87ERx99hBEjRqCoqAglJSXo0aMH3nvvPbz//vu44oor8Mknn6ClpQU33HADpk+fDiA8cvy+ffswbtw4nHXWWXjjjTdQWVmJJ598EqWlpRm+so4LRO8hEZkOU4WE4447LsOpISKivPODHwB1dak95ogRwG23RV3961//GqtXr0ZdXR1efvllXHLJJVi9evWR3jf33nsvjj76aDQ3N+PUU0/F1772NfTs2TPiGB988AEeeugh3H333Zg4cSIef/xxXHXVVam9jjTKZO+hLQCOtc33Dy1rR1XnqWq1qlb37u3pmUpERPlh716grS3TqfDP3r3pO9fBg0CqxmTpyHuiCrS2tl/e3Ayo4rTTTovoLnz77bdj+PDhGDNmDD755BN88MEH7XatqqrCiBEjAACjR4/Gxo0bE0/T4cPu6cqATJa0PAXgehF5GMDpAD5XVVYNEWWSKrBvH1BebuYfeAA480ygrAw4cAAYMAB46SWga1fg1FOjH6etDWhqMtupAkuWAKedBrz/PvD552a6qckc1zrfs88CF11k5nfvBuylqg0NQI8eQOfOwIYNQEUFUFgI/P3vZvkFF5h9vvMd4NprgX79gO3bgWeeAW6+GZgyBbjqKmDrVnP8Sy8FCgqApUvNvq2twPr1gIg5TrduwLe+BaxdCxx9tMmH7dtNmmtrzfq1a4GTTgK6dDE/dh99ZNL6rW8Be/YA11wDDBkCbNoEvP02MGkScPrp5hz33Qd07w48+ijw9NPAv/4FvPce8MUvmnweORL45BOz7tFHgRkzgB/+EDj7bGDoUGDuXGD6dGDUKJMeAOjZE9i506z/5BOTBgC46Sbg9dfN9T32GPDXvwJWO4mrrwbGjgXWrTPLr7sOmDrVvD74APjzn817+eSTwL33AieeaN5Dy4knAjfeaNK4ahWwxfX/Tnfjxpn3HABuvx146y3gwQfN/I03mrR98Yvh7X/2M5PGTZvCP6DTpgH/939meuRIc41NTeF9fv974D//0/38//7v5n2I5dlngf37zfRVV5lXp07mRzxVYj0AuLHRBCxr1gDvv48uhw8f2f7l5cvxwhNP4M3Zs1FWUoJzr70WLStXmvQdPGhKhZqa0Lmt7cg+hVu3orm5OfY5YxkyxHxmM0hU1Z8DizwE4FwAvQA0ArgZQBEAqOpcMX2f7oDpYdQEYJqqxs3J6upq5VOeKWsdOgRs3AiccIKZb20F7r7b/JAVF5sfcGe3v8cfB+64A5g50/wIbN9uftxWrAAuu8z8sG7ebPZ//XUTRDQ3A3fdZb6wf/9784P5+OPmS27gQKC62vxAWX7yE+Czz4B77jHznTubH8dBg8y+o0cDy5eHt//a18zx4qmpARYsMGk7eDCZnCPKOuuefRaDe/XK2Pl37t6NUd/4BjY9/TReXr4ct/71r/jHH/8IAHjylVdwzxNP4Ok//hHvbdyIEVOn4rnbb8e5o0dj4GWXYdn992NfUxP+7Yc/xOpHHgEA3PrAA9jX3Iyfh9q+JOy444A+fZK6pnXr1mHw4MERy0RkuapWe9nft5IWVf16nPUK4Dq/zk95avduU7x7zDGRy7dvN//NTp4MLFwI9O5tfqjt3n4bWLnS/Lf+/vvAL39pgofrrgMuvBC45Ragqgp48UXzH2i3bsB//Adw1llm/7PPBl57zQQmN9wA/OlP4WPPmBE/7S+/7L68Ik6nOud/khs3mpfdb38bOX/ggPlrlQ7YAxbAW8ACmIAFYMBC5IOe3bvjzOHDMWzSJJR27oy+tvYqF51xBuY+/jgGT5iALw4YgDHDhvmbmO7dzfdmhvlW0uIXlrTksVdfNUXAXbu2X7dnjykWLS83xdnFxSa4GDzYFCePCo1deOmlpsidctO0acALL5jqEcBUYY0dawJCt++NY48Nb3vmmaaK5amngC99CXjjjfB211xj1k+bBpxzjqlmqq+PbLfw9a+bqqSpU03Q+5OfAPffb4rTTzjBVH+8/rppeDl8eGR6Bg40geb11wPz55vjH3+82f+XvzT38qJFJg2rVplzjx1rqr6eeMJUAd1zj6l6e/99U92jaorzL70UKC011VgtLcBDDwGPPAJMnBgu9fv4Y7NfQwOwbZsp5fv734FXXjHrv/QlU93Qs6fJl+ZmoKjIVNUVFZnP28SJ5odt505TfVJVZUoeP/vMVNNdcIH50Xv4YZNHhw+bEr+1a801/vnP5jNcVGSC6o8/Nv/Vr1plAvf9+03V16pVpkpw/36gb1/zj8aGDcCOHeafi5Urzft1ww2mFHLfPlPi+dhjJg8uvNCkY9Mm811QWWmqv373O+APfwB+8QvzHnz2GdaNHo3BVpVIa6spyezb11RN2ktNVc21Wmnv1MlsI2LuEWs7t8HVDh40y61jWr/JBQXhfZuazLE7dw7vJxLetqXFrO9kK4ew1u3ZA5SUmOOJmPOVlZm/RUWRaWprM9dZVBS+ps8/B3r1ck97ByRb0sKghbLXunXmy+jLXzZ13j/5iVl+wQXmi+6SS8wXz/PPhz+g+axPH/PlsnZteNnTT5sv8ZtuMm09pkwxX4CXXmp+NI47zrRvOPFE84X8n/9pSpyuvdZU/ZxzDrBrl2kjsnSpaRQ5Z46pmurRw3wRAsDll5sfmRtuAM4/3/wQAGa99UX8z3+aH+pTTjHVT4D5UTzxRFMy9qMfmXYMVVUmbd27A7/6lUnDWWeF32MR88Nw990mgC0uNucbOzZ83cuXmy94v//7TKW2tnB+pos9T6kdtx9YSg6DFgq+/fuBDz8MNxT8+98znaKOGzsWmDcP+OMfzX/LM2eaRqdW6Q9gGhOef7757//oo81/fjt3mv9oOnUyjV1bW81/Xq++av7LPO648H9Zjz5qjllQYEoKvPDrB3H7duCooyL/AyTKEQxaUi9r27QQxfTee8BXvmIams7J0BMc/u//THG/0yWXmCLgH//YFLsef7wpbVi/3qTZ6ZNPTGBhL5p1XlNhoQlERML/1X7d1uyrVy/zsm8PmHYyFlXTILd//8SuE/DvP/gkG+URESWCQQulT0uL+TE//XRTNw+kLmB56CFThfTmm6ZtwIABJph4/nlTHXLxxaaE46mnzDZWqcfVV5tgoqDA1H0fPmyqPZy6do1equG1tCMVgUNHAhYiohzB6iFKvV27zI9/z57hEgM/DBliqk+OPtq/cxBR3mL1UOolWz2UyRFxKVcNGGCqDayuwB1ldRPu3dt0JX7rrXCjTlUz4BIDFiKivMGghZJ38KDpGrd2rWmvYQ27/eab8fe98krgm980jVAPHzbByMaNZoyTO+80yxobTXXSaaf5ehlEREHWNTQcxNatW3HllVe6bnPuueciXm3FbbfdhibbyMIXX3wxdu/enbqEJoFtWig5qon3HGlpMQO1FRQAs2a1Xz9gAPD975tpP6uXiIhSrKHBjGH5yCPtx7hMl379+uEx+4jYCbrttttw1VVXoSw0ZP8zzzyTqqQljSUt1HHvvmvG1PDijTeA1avN4FqdO5vBpNwCFiKiAJs1y9Rm33JL8seaOXMmZs+efWT+5z//OX7xi1/gy1/+MkaNGoWTTz4ZTz75ZLv9Nm7ciGGhMYqam5sxefJkDB48GDU1NebZQyEzZsxAdXU1hg4diptvvhmAeQjj1q1bcd555+G8884DAAwcOBCffvopAOAPf/gDhg0bhmHDhuG20BOqN27ciMGDB+M73/kOhg4digsvvDDiPCmlqoF6jR49WikLrFhhb10S+/Xii5lOLRFRwtauXet525IS96+/kpKOn/+dd97Rc84558j84MGD9eOPP9bPP/9cVVV37NihgwYN0ra2NlVV7dKli6qqbtiwQYcOHaqqqr///e912rRpqqq6cuVKLSws1KVLl6qq6s6dO1VV9fDhwzp27FhduXKlqqoOGDBAd+zYceS81vyyZct02LBhum/fPt27d68OGTJE33nnHd2wYYMWFhbqihUrVFV1woQJ+sADD7hek1ueAlimHmMAlrRQYg4fNgOKjRwZfZubbgpPNzcDoWidiChX1debAaethyCXlZmnFWzY0PFjjhw5Etu3b8fWrVuxcuVK9OjRA8cccwz+67/+C6eccgq+8pWvYMuWLWhsbIx6jMWLF+Oqq64CAJxyyik45ZRTjqx79NFHMWrUKIwcORJr1qzBWvto2i5ee+011NTUoEuXLujatSvGjx+PV199FQBQVVWFESNGAABGjx6Njc7nn6UI27SQNwcOAM89B1xxRfxtf/5z8+yK733PPPOCiCjHVVSYZ6i2tJivvZYWM59su5YJEybgsccew7Zt2zBp0iQ8+OCD2LFjB5YvX46ioiIMHDgQLS0tCR93w4YNuPXWW7F06VL06NEDV199dYeOY+lsa9tYWFjoW/UQS1oovkOHzKcwVsDygx+YJwkfOmQaz/7sZ+6DtBER5ajGRqC2FliyxPzdti35Y06aNAkPP/wwHnvsMUyYMAGff/45+vTpg6KiIrz00kvYtGlTzP3POecc/O1vfwMArF69GqtWrQIA7NmzB126dMFRRx2FxsZGPPvss0f2KS8vx16rF6jN2WefjSeeeAJNTU3Yv38/FixYgLPto3anAUtaKL4HHoi9fsAA86wdIqI8Nn9+eNrWfjYpQ4cOxd69e1FZWYmKigpMnToVl156KU4++WRUV1fjpJNOirn/jBkzMG3aNAwePBiDBw/G6NGjAQDDhw/HyJEjcdJJJ+HYY4/FmdYo5QCmT5+Oiy66CP369cNLL710ZPmoUaNw9dVX47TQ8BPXXHMNRo4c6VtVkBuOiEvx/fa3wE9/6r7upz8Ffv3r9KaHiCgNOCJu6vGBieQv1egBy/PPAxdckN70EBFR3mKbFoqurQ1wK3ocNgxYtYoBCxERpRWDFoqushJ4//3IZT/+sRlU7uSTM5MmIiLKWwxayN3eve2bvn/3u6Z9CxFRnghau89sloq8ZNBC7am6P+zw1lvTnxYiogwpKSnBzp07GbikgKpi586dKEly7C42xKX2vvQlM9CAU6IPRiQiCrD+/ftj8+bN2LFjR6aTkhNKSkrQv3//pI7BoIUivfpq+4Dl8svNAAQFLJgjovxRVFSEKq8PhaW04K8QRTrnnPbLHnmEAQsREWUcf4koui9+EXj9dVYLERFRVmD1EIWFntB5xGuvAb16ZSYtREREDixpIeP554GVK8Pz117LgIWIiLIKgxYyvvrVyPk//Skz6SAiIoqCQQu5YzsWIiLKMgxaCDjjjMj5PXsykw4iIqIYGLTku+bmyHFZpk0Dysszlx4iIqIoGLTku127Iudvvjkz6aCkNDQAY8e2f1wUUSKy+T7K5rTlsmzLdwYt+W7Vqsj5AQMykw5KyqxZpof6LbdkOiUUZNl8H2Vz2nJZtuW7BO1BUNXV1bps2bJMJyN3XH458NRT4fmA3Q/5rrQUaGlpv7ykxNT8EXmRzfdRNqctl6Uz30VkuapWe9mWJS35TDUyYJk8OXNpoQ6prwemTAHKysx8WRkwdSqwYUNm00XBks33UTanLZdla74zaMln9fXh6W3bgIceSupwzrpPL3Wh2VZfGjQVFUC3buY/opIS87dbN+CYYzKdsvwS9Ps42++jl14y/91nY9r8kO77ye182XpPMGjJZ8cfH57u0SPpwznrPr3UhWZbfWkQNTYCtbWmE1htbXB/OIMsF+7jbL2PZs0yP6pDhmRf2vyS7vsp2vmy8Z5gm5Z8tXixCa0B4N57TVfnDopW9+lkrwtlPTXlAt7H/snHvE33NWdLHrNNC8VnBSxAh0e/tYoUlyyJrPssLQUGDjR/Afe6UGd9aUEBMH58eupL7UWhqSqGTfY4fqSJ/Jet9f5BEu1+z8W8jffZTvc1BzGPGbQQUFzcod2sIsW77oqs+zxwwNz8Bw5Erwu115cWFgJtbcD69empL7UXhaaqGDbZ4/iRJvJfttb7B0m0+z0X8zbeZzvd1xzEPGb1UD7avx/o2jU8/9RTwKWXet49WpFiYSGwfDkwbx6wYAFQUwNMn27mGxqA+fPbb9/W1v446S4KTebcyRav+pEmSq/x482Xf6x7ndrz8tnJlbxN5Hsi3decDXmcSPUQVDVQr9GjRysl6XvfUzUdnlWvukr10KGEdt+6VXXKFNWyMnOIsjLVqVNVGxoSS0ZHjrN1q+o55yR+LrfzFRaal3Xu8eNVx4xJ7NjJ5kW8NHUkX4MimfcyWyR7DenIg0zlc7zzpup7JNU6ml+x9svWa40m3fcMgGXqMQZg9VC+2bcP+N//Dc8/8ADQqVNCh0hVkWJHjpNM1YnzfK2t5mWde/164O23Ezt2snkRL03ZXlSbjFyoBktltaBfMpXP2VYV4lVH8yvWftl6rdFk82eT1UP5Zvp04O67zXSXLiaI6YBUFSl6PU6qWrnbz1dTY5Zt2QIcPNjxYyebF25pWrAg2MXhsWRLj4Vk+FUtmMo8yFQ+Z3NVSCwdzS+v+2XTtUaTqXuG1UMUnVUtBKi+8krKDmsVJ9bVqZ5+uuqoUZFVLfb1VrGjvQgy3nRdnWpNjWpBQfviVeexo50jmhUrVHv3Vi0tNccuKDBVRV72d1ufqqLVrVtNXo4ZE3lN8c7vh0TOE6+Y/PTTzXsZr6jcyzn9uH6v501ltaC1f7T3uaPXES2NflZrBa0qxOL8HvCabr+v15nXXt+7jnx+MvXeIYHqoYwHIYm+GLQkyR60pNCMGebHfujQyFPMmNF+fUGBmbeWeZ0eMkSPtPuwlrkdO9o5YqXdSq/VnmTo0MhjR9vfbb2Xc3rNUytd9muKd34/JHKeWNta64YMMX9LSuJvG++9S/X1ez1mbW38a0h0/1RfT7Q0JnueePsnmzeZYP+8JZpuP6/Xmdde37uOfn4y8d4lErSweijfiISnU/Deex1YLlt4GeDOy/6J7JuqHkl+nKujaXE7T6xtAfd1xcXANddEFpV7OacfxdiJHjOV1YKjR5u2TF7P3ZFzzJsHzJ2bXI+9XKoKscTqDXnZZd7S7cf1dmTQzlj7ef38jBuX/veO1UPk7vXXw/9K/P3vKTmkVZxoFak6XwUFqv37m6jdvtzeSybRaXtReqxzx+uJE6vnTmmp6sCB0YuK3YpRx4/3Vu3hJU9rasJpsb9KSyOv3e9i3ESKi+NVR6TiOB1Jlx/XmmrpOrdf1VrZXvUTS7ZekzNd8b6Tou2Xrs9PMsDeQ+TqF78IT3/lKyk77MKFJoIvcLmb2tqAzz4zA81Z6wsLI3vJWNOdO8eftre879PHPEjNGqDOznmOeAPcOXvuxBsgz9q3udkUXjU3A337muFvmppMCUJTE/DCC4nnZ0WFOZbzP++CAnOeTp2A4cPdeyOoehtN1+sIvIn0enDbtrAQmDTJ5FFHj9PcDLz4ordtGhvNtaxcmfiowtGu1WueJiPR3iUdHTU51b3d3N6bVErH6NDZ2rPHmS4vg3a67efluy9brtkLBi355Nlnw9P2aqIkzJoF7NxppktKgPJy83fQIKBfPzPf1GQedlZRYbbr2xeoqjKvJUvC05ddZtaXl0eftj+4y/4gtbFjgaFDgV69zN+xYyPPEe1hX/YHgjm337Ur9sPCGhvNuQHzd9s2000QAPr3D2/TkW6DjY0mLRMnApWV5tqtL5TFi9un3Z4nXroqJjICbyIPTXNu++qr4WN39DhDhpj3OdbD3Kxtpk4157P+Jpr3yeRpshLJn2TSlOxD8Ly8N6mSjXmfTs50xftOirZfvO++bLrmeNimJZ+ksD1LvPpWK3qPpSPtQ7wcLx2SaQ+TqnN1pI1HukbgTUWbk2SuO5nzJnL+dMuWNPmdjmy5TkoPPjCR2nvmmYR3sYpm3Yra6+tNgy2nY4812zsfxFVYGK7CKS01VTtvvRU+VrRt7dPWw7wWLQJ69w4/kFEE6NkzfDx72jv630NdHdC9O7BqlfvxnGm2HhJpNTq1KyxM7mGQXh5q5vXBZ87trPTF2sevNEfT0ACMGWP+i6+p8Xbd1r3gVFqa2DXZ7/nhw809blVrlpWZ93HECPfPRCIPvbSu8YwzzLGs6Vj3a0ODSVNNTfh67dcX7fPqRxVLvPc32XO6fb769AH+8Y/Eqv8y/XDUZM7pV9VY4B/I6rXxS7a82BC3g+ytOdvaPO3i1k3Zrra2fUNRq6uwtd7qOmfvSujsDu1lW2e3UGcXZefxku3SaXXdjtX12dk10OrG69aANtlug166IXrtqmhtZ0+nH90bO9p10v7+euka7XY9bl3jvZ7bfs/36BF5LLdu9c59vXRddnZn93Kf2LuLex1WwJmuVIr1/qbinG7fCbHy300i74lXqer+7+e+mThuMsAuzxShvt40MrHEec+9VP00N5v/OhcuNG1VBg0C3nzTNETdutVs5xzpdeNG91M7u9nZR4W1T0frFuqF12Jlr0193LoGWul97z1g6VLTsO3MM830iBHJdRv00qXSa7fLaA+qTKSLZ6rSbBfrvnPrGu08z3vvmXr6xkbTbqpvX+Ckk7x12fS7636iVaHJds33euxkuL2/zz6bumqd8ePNs1y9fObTUQ2aqu7/8c7pV9VYNle5scszRXr55ch/zWKwRiwdN05VJHI3Ee8jxTqPGW9UW7dtnSM1OkdStY5jf515pmrPnpHdAsePNyP0Wi9rhFlrtFn7+VesUB0wIPKYJSXhvCgtNcc/5ZTIY8UbAXbUKNWTT1bt0sXsa0+DW5rijYzqZYRh57EWLVI96ijVRx5xH/nTvl15eWQ63d6LeCMeO/PA7WGU9v1GjjTpc5aWjB/vPtqxl/vNmb/RRi+27k23rvOAaufOqsXF7ZeLqJ53XuQ9Zy/xETGlNVZeLloULr2JNkSAffuGhvYjtdrPYd3fbp/XkhIz3ID1ObHu3dGj298j0e4f++fGmY9u+RltVFkv94XznrXOX1MTfVgDwFzTCy+0P1a04QzsI15Hu3eiraupicznHj3C+em8n2J1KXaeZ8WK8Gfu5JOjf4e5vVdePwOjRpn7xPn9m+go5X4AR8SlCC++GP6UbdgQc1Or6DDaF6vXkWLdjhlrVFvnttGKuO3VBW7ps6fbKrZ2jtIbr0jeWfxufcjdqn3sRdbRRnWN9mXrTJd9Pl7xt5cRhp3HsvLGLY/s+zvfe7f3wmvVRLTt3a4jWj7Z0+alWiDaMeNV6Tjfd3vgES1tbvkZa9tY1xnr2p3BivO9c6ZdpH31Vqzjxrp/ot3v8d7reCP9up3fLZ9iVbvG+jy7VS85R7yOdu9Eu7+i3SNuVXGJVJ9Fuy/cvsO8Vj+6fQac1Z1u73u8aT8kErSweigfzJwJ/OY3ZnrXLtPC1CHZIuhEikjtCgpM8W+i5y8uNl2BU9Fo1GJdQ7K9wWONAJvMMVPZ0ypX+FmNQsFWUGC68k6fDowcaX62neJ9rpL93BUWAsuXx68+S1a6vx9SXaWUNb2HROQiEVkvIh+KyEyX9UeJyNMislJE1ojIND/Tk7esgOVXv3INWIDovTBKSkyvGHtvBft8rF4hsXoFWftt2ZLY+a39Nm0y+2zd6r5faampE7f3/ojG2bsn2jHjHcfek6O+3rRvibdPPM7eL9HyyZ63Xs9ZUmKOXVdnjunW88m5ff/+kQP5FRSYZc597flv397Ka+uc0Xr9xNvOrVdQvJ5EzrTZeya55VlH8jNaDzI31jU2NJh7Ltr9EqsnXbT8cX5uvFxDotdrcctPZ/rsy93ui3jpsu4FL58pa/stW4DZs02Pqy1bYvd2itcbKt7n2focOL+nNm82558927Srcp6npCT2Z2DcOPe8itbjL5nPQLRem273XSr/WUyUb0GLiBQCmA1gHIAhAL4uIkMcm10HYK2qDgdwLoDfi0ixX2nKe9/4RtRV1giJBw5E3qwHD0aOwnjggCnlaG42I9UmMrKpfcRZ50iabucvKDD7Fhe3HwVS1XTbs0Zadab7wAHTKLiuzr3RqV1rq9l20qRwN0DnSLvRGq9aCgvN9tY1WaPaxjt3PPZRZaOlzSqtsvLWyzlFzHtbWAh8//tmOtZ/aFaefvppZMPItjbzg+Ac8die//btrby+9lozWnBLi/sPQWuryT/7qMfWdtbIwAsXmi9dq/vr9u3RR0i2X3dzM/D662bAPuvedMuzRPLT/lmx8jUe6xqPOcbcL127Rk9HcXHkCNFNTeY8114LPP985IjUVv5v2xb+nHq5htZWkz+J3LOIGe1wAAAgAElEQVTWff/mm2baPhp0p07m/Xvhhcjlixeb0gevjeqtfBo+3NtnqrXVpOWKK0zj/TPOCN8bVn40NUXeP5Mnm/xsaor+vfb669HP3dZmBtlsaYl8f664IrJb+/jx4fMUF5vtO3WKfh29e7f/DFnrrPy0X0dNTfv7wcn+nlmfgVgjkMcbWTztvNYjJfoCcAaAhbb5GwHc6NjmRgB3AhAAVQA+BFAQ67hs09IBVoVmHDU1qt/9rur555u60PPPN/MVFeZvXZ35azUumzDBzNfUxD9mXZ1qVZV51dWF61rtdaTO8/frZ7YpK4s8f01NZB1rtHRXVZn9y8tVKytVO3Uy8wUFZrqyUnXixHC6nPX51rGsv+Xl4fRYr5ISs9zazn5NNTXmuJWV4XYxzrr5ggLVQYPMcaw0VVaqFhWF0xAvbVY+lZebPLLSOWhQZKPlHj3CjUlLSsJ5VFAQ3seezm7dwuvs12cde9CgyLryykoz3a9f+/y3ti0vDy+3rsPaz8qLfv3MNtb77NzOuia3Nhb2vCkvN9dpT6c976uqIu/NsjJzP0ycaKate9W+rrLSHLdXr8g2Qs7Piv381n1nvaxjWddosfKlrCzyvQNUv/CFcP5NmBCeth+3sjLyvrCWT5gQeU9Y12elw54/QPjes7YpKDAv+/1utRPp1y98LuscVlqrqiLbqVjLrVd5eWR+W+mxN1515pP9M2VPnz3f3PLGfm9Y+ee8f6x93L7X7NdhP681bT+W2/tjfz+c+WS1mbLulcLC8GfA/hlyvlfO/HS2X7F/9gcNCueT/T2zPgP2NNunnd/b8b7vOwrZ0KZFRK4EcJGqXhOa/waA01X1ets25QCeAnASgHIAk1T1n7GOyzYtCfrXv8LPGUryvc70KKex2op0dJTUaMfzwmt9uJ1fded+8aN9TrrO6WVUZms7P7q+eh06IBPveSJ57He7oY58jvxKi/O8QHa/N+mQji7RWdOmxYOvAqgD0A/ACAB3iEg350YiMl1ElonIsh07dqQ7jcHm8cGIbqMk2kft3LbNFCfaR6LtSP1msqO7dmT/WO1wvLS7cauXT6Q+PJHr9zo6cEEBcN55ZiTgaO2N7NuXlJhiX+sLMdYIvtb6qVPNc0mskWHjVXlYDZhLS039vr26Ita+zvy2zumsb/fa1sLe3mXFCmDAgOjb9uhhRln1MiKtJdZ7aP8cRWtfEK2dkv1+dbYdssTKB69tIKxRfZcsid1Ow63dkPM7IFZ6vLxfF18cPn6i3y9un5V45/SSJqu9x5AhwAknAEcdFbne2cbGmdcdbcfmbBPn9Z6Ix9m+yf55FIlsi2OtByLvlWwaPdfPoGULgGNt8/1Dy+ymAZgfKiH6EMAGmFKXCKo6T1WrVbW6d+/eviU4pz3wQMzVbg8mmzXLDI2/ZIlZPm8esGOHibo7Wr+Z7BNIO7J/rKejxmp3Y20X7YnKzic+d/RJyLGO5Va3bLWvqasz9ejW++G8Tue1HDjQPk/c2l9YbSK6dQPuussMjrdpU/w2CKrhY+/fb9Jof9p2tC9cZ35b51y/PjIfrOPFYk/7MceYL9wuXaJvv2sXcMMNkfd5PLHeQ/vnKFo7MXv63I5nrXfmt5WX0fKhtdX8OA0Y4N4Gwkrr+vXA22+bfI7WRsQtnUD77wArPW77e2kbs2lT+PiJfr+4fVbitTuLlyYRc93r1wPvvAO8+y7w+eeR2zjb2DjzuiPt2KzzRvteinZPxOPWLtH+eVQ1n1X7Pep2r/j9wMpE+Fk91AnA+wC+DBOsLAUwRVXX2LaZA6BRVX8uIn0BvANguKp+Gu24rB5KQGtruJXXokWupS7JFLF2dATVZEd37cj+1mi18Y5nH4HXvl28cyYy+msix7KnJ1q3TUthoWn4aF1nrFGI7du6jST7yivuX5AFBcCVV5rSiZYW8yTqQYNMA+TiYuDwYfMl6UVBgfly7Ns39ojHVvd2wJzP3oDb6fzz24+C268fcPTR5ot76VJvaYtXJO58D+fOdf+xsrrdWnkcbZRet/u1pAQ49VTTAHTPHjNtlTpUVZlrOXTI5I3VwHTECLO+rs5sD5j3qm9f02A62ntTWWnOt2ULUFRk9rWnM9HvCavULZmfFy/fL/Z8i/X5KC8P519jo2nAmoyamvD3gj2vH300ueNajeqB+PdEY6P5vEVjXfNJJ0V+/8X7HonFr6qirBkRF8DFMIHLRwD+O7SsFkBtaLofgOcBvAtgNYCr4h2TDXET8Oab4VZZL76oqu4jMTpHsBw3zjQudHuWi9WwK9qIkuQfa5RP5+igpaXtRxZ27hNtZM545/Kyn3PkTOd+48dHjmQc7Vhez9nRa7L2ramJPlCZNQJvovd2MmlKl2TzzW3fWCO/er0XrBF9Y42Uncz1RRuN1+2z5BxFONF7I9ZIvPHyJpXXnEgaS0tVBw5sPwKvl89sqiCBhri+tmlR1WdU9URVHaSqvwwtm6uqc0PTW1X1QlU9WVWHqepf/UxP3rnppvB0qOzPWQ3kViT78cem2NytiNkqYl2/PsPd3vKQ1+oGt328VF11dD+3KhH7flbpTbxjeT1nR6/J2tetSN9i74aciGTSlC7J5pvbvrGqTr3eC337mmoiq9qro3kXLY133dW+6jvWEA/dukXveh7v3vBS3ey1mjuZa04kjW7V514/s5mQ6Ya45KfFi49Mll54NkSAOXPMB3LOHByZt7S0mHVr1kQext6wzPqyX7PG7B9vECNKrcZGU90wdiwwdKj5W1sbu6Gctc+SJfG3TWS/0lK43lPz5rXfz2saUr1dtH2rqoCJE021SKdO5u/EiWZ5RxsdJpOmdEk239z2jXVMt3X2Zdb9s3at2d5ql3LXXclfn3Vs5/1pfWdF+yzt2mXug8pK82NeVmaqGL3eG/Y0VFWZl9e8SfaavR7Huc+uXR3/zKad1yKZbHmxesij+fPD5Zpnn+1aJGgvBrWqhZwP6kp1cSblDt4TlCw/7yHen8GBBKqHoozFR4F26JBpxWUpKHAtErT38LCqhXbuNLu4FQlme/E3pVcQqkQou/l5D/H+zE2sHspF998fOR+qoLWK+9razGvXLrPaKpK1Vwu1tJiiVD+KMyl38J6gZPl5D/H+zD18ynMumj0buP768PzixcDZZx+ZbWgAfvQj4IknTNe/0lLT6Kqx0TTILSsz3eNuvZX/lRARkb+CNCIu+cE58pQtYAESG3yNiIgoWzBoyUX2x4bOmOG6iZfW40RERNmE1UO56N57gW9/20y3tnb8YRhEREQ+Y/VQvisqCk9HCVjcHpBIRESUzRi05CLrwR9/+UvUTdwekEhERJTNWD2Ui6ygZdMm4LjjIlZFe/CZXw/CIiIiioXVQ/nMHoQWF7dbXV9vujNbtUZlZWYcuhEjWFVERETZjUFLrnnrrfB0167tVldUmIcd2kfCXb8eePttVhUREVF2Y/VQrrGqhoB2PYeiVQ05saqIiIjShdVD+WrFish5W8DS0AAMHgz06BFeXFoKDBwYfuppWRkwdSqwYUN6kktERJQIPjAxlzz3XHh6//6IVbNmRcY0hYUcCZeIiIKFQUsusdf9lJUBiF4l1Npq/q5dC3z3u8D06cC8eaZEhoiIKBuxTUsusbdnCb2vDQ3AddcBTz555GHPAExJy+WXm2crsmSFiIgyhW1aCIAJWCZPNgGKPWABTElL374MWIiIKDhYPZTDrFFvu3Qx82VlpstzczPQuTPHZSEiomBh0JIrbA1vS0va0GKrKdq71/xtagI++ohdmomIKJhYPZQrbAPJ1dcLamoim7gAplEuuzQTEVFQMWjJQdaot/Y21lYXZ3ZpJiKioGL1UI4pLTwYUTVkaWsDZsxgl2YiIgoulrTkiDqcgu7Yhft+tAo9e0aOetunD1BXZ7o3z5+f2XQSERF1FIOWXLBuHa7CX/E5jkLtnOHYuTP8QMTmZmD7dmDu3EwnkoiIKDkMWgJOBJAhg7EGJwMQ7NoTrvGzRr0FgDlzzLbWc4aIiIiChkFLwK1YAfTHxwDcRzYuLDR/+TBEIiIKOgYtATdiBLAfodHjXAKX1lY+DJGIiHIDg5YAKy01VT670BOAhF7GxImmdKWqCliyBKit5Qi4REQUbOzyHGD19cCPvrUTTzxXgiZ0QVkZUFMD3Hpr+xKV2bMzk0YiIqJUYUlLgFVUAN1WvoYWlKAEzawCIiKinMaSloBrLO6PWszF9Jv6Yt5nV3LwOCIiylkMWgJu/qV/Ae67D5i1B6wBIiKiXMagJcj27gXuuCPTqSAiIkoLtmkJsv79M50CIiKitGHQElQLFgB79mQ6FURERGnDoCWolixpt6ihARg7luOxEBFRbmLQElSrVoWn9+0DAMyaBbz2GnDLLRlKExERkY9E1f2ZNdmqurpaly1blulkZJ6ER78tLVG0tLTfpKTEPOWZiIgoW4nIclWt9rItS1qC6OmnI2br64EpU8yw/QAfjkhERLmJQUsQrVwZnn7uOTMybjfzUEQ+HJGIiHIVg5YgKi4OT3/1qwCAxkbzUEQ+HJGIiHIVB5cLoqKidovmzw9P8+GIRESUi1jSEjSqZowWIiKiPMOgJWhuvx149dVMp4KIiCjtGLQEzQ9+kOkUEBERZQSDliB77TWOgktERHmDQUuQHD4cnq6oAM48k6PgEhFR3mDQEiQzZx6ZLP1sC0SAOXOAtjbzVwQoLc1g+oiIiHzEoCVI/va3I5P1yz7jKLhERJRXGLQESUOD+VtUhIphPTkKLhER5RUGLUHxwQfh6cceA8BRcImIKL9wRNygePHF8PRllwHgKLhERJRfWNISFLW1mU4BERFRRjFoCYItWzKdAiIioozzNWgRkYtEZL2IfCgiM6Nsc66I1InIGhF5xc/0BNa8eZlOARERUcb51qZFRAoBzAZwAYDNAJaKyFOquta2TXcAdwK4SFU/FpE+fqUn0Owjx33pS5lLBxERUQb5WdJyGoAPVbVeVQ8CeBjA5Y5tpgCYr6ofA4CqbvcxPcG0a1fk/G9/m5l0EBERZZifQUslgE9s85tDy+xOBNBDRF4WkeUi8k0f0xNMDz0UOX/mmZlJBxERUYZluiFuJwCjAVwC4KsA/kdETnRuJCLTRWSZiCzbsWNHutOYWcuXh6fXro1YxYclEhFRPokbtITapnTEFgDH2ub7h5bZbQawUFX3q+qnABYDGO48kKrOU9VqVa3u3bt3B5MTQFu2APfeG54fPDhiNR+WSERE+cRLScsHIvI7ERmS4LGXAjhBRKpEpBjAZABPObZ5EsBZItJJRMoAnA5gXYLnyV3TprkuLi0FH5ZIRER5x0vQMhzA+wDuEZEloaqabvF2UtXDAK4HsBAmEHlUVdeISK2I1Ia2WQfgOQCrALwN4B5VXd3Ba8kdy5cDzz4LLFoUXmYrcXnzTaBnT6Ag9O7xYYlERJQPRFW9bywyFsDfAHQH8BiAWar6oU9pc1VdXa3Lli1L5ynTT6T9stbWI1HKd79rSlcAoLAQUAWuvRa48840ppGIiCgFRGS5qlZ72dZTmxYRuUxEFgC4DcDvAXwBwNMAnkkqpeRdQUFEtZCltdVUEd11V+aSRkRElA6e2rTAjK/yO1Udqap/UNVGVX0MpmqHUumFF6Kuqq8HampM6YqlsBAYP54j/RMRUe7zMiLuKaq6z22Fqn4/xemh9eujrqqoAPr2NaUrltZWs+yYY9KQNiIiogzyErQcFpHrAAwFUGItVNVv+ZaqfLZwYczVjY1AVRVw6qlmfulSjtNCRET5wUvQ8gCA92AGf7sFwFSwW7I/9uwBnn46cpmjofT8+WlMDxERURbx0qbleFX9HwD7VfU+mNFrT/c3WXnqqKNirm5oAMaMAc44g6UrRESUf7wELYdCf3eLyDAARwHg05hTrbm5/bJ3342YnTULeOstYMkSjoJLRET5x0vQMk9EegC4CWZE27UAfuNrqvJRv36R82PGAMOGAYBrV2eOgktERPkmZtAiIgUA9qjqLlVdrKpfUNU+qspRQVKooQEYs/sZnIE3sBInY2y/97FtwZuoqwO6dTMNb3v0cO/qzFFwiYgoX8RsiKuqbSLyEwCPpik9eWnWD3fiLZwOQDAVD2LdthNwyy3A4sXA3r3AOpdmz+zqTERE+cZL76EXRORHAB4BsN9aqKqf+ZaqPFFaCrS0AEDPI8vW4GSgLbIqyKmgABgwgI1xiYgov3hp0zIJwHUAFgNYHnrl+MN/0uPICLdH2joDQPRnQRUUhEe/ra9n92ciIsovcUtaVLUqHQnJRxUVQN/Ou9CKoxAOVgQi7YZnAWCeMcQqISIiyldxgxYR+abbclW9P/XJyT+ND78IQQ0U4Sc72wOWPn1MFdLBgybIYZUQERHlKy9tWk61TZcA+DKAdwAwaEmB2bgeW9EP/bAVC8vGo6lJUFoKlJUBAwcC//iHKVlpaAAmTwbuvDPTKSYiIsqMuG1aVPV7ttd3AIwC0NX/pOWBpibMwv9gKU7D+uKT0dIiKCkx48zt3AksXx4eRG7WLOC11zioHBER5S9Rt8YTsXYQKQKwWlW/6E+SYquurtZly4LfDjjcc6hjrOCGiIgoyERkuapWe9k2bkmLiDwtIk+FXv8AsB7AgmQTme/q64EpeBBloV7kZaWK8eOBceMiB5ErKAD69w+PfFtWBkydykHliIgo/3hp03KrbfowgE2qutmn9OSNigqgG/agBSUoQTNaDpSgb1/TCLe1NbxdW5sZFXfrVlO60tJi5tmDiIiI8o2XoOVjAA2q2gIAIlIqIgNVdaOvKct1bW1oRB/UYi6mX9aIef1vQUODWVVVBZwaav68dCmwaxdQWwtMnw7Mm4cj2xEREeWTuG1aRGQZgC+p6sHQfDGA11X11Jg7+iRX2rTgwguBRYvM9M6dwNFHZzY9REREGZDSNi0AOlkBCwCEpos7mjgKsQIWgAELERGRB16Clh0icpk1IyKXA/jUvyTlmWpPwSUREVHe89KmpRbAgyJyR2h+MwDXUXLJo927w9O9emUuHURERAHi5dlDHwEYIyJdQ/P7fE9VruvXLzx9wgmZSwcREVGAeBmn5Vci0l1V96nqPhHpISK/SEficpZ9VLhvfztz6SAiIgoQL21axqnqkfoMVd0F4GL/kpRnqvgQbSIiIi+8BC2FItLZmhGRUgCdY2xPiejWLdMpICIiCgQvQcuDAP4lIt8WkWsALAJwn7/Jyg8Nwy/C2LHAtm2ZTgkREVH28/KU598A+AWAwQC+CGAhgAE+pysvzDrjGT65mYiIyCMvJS0A0AhAAUwAcD6Adb6lKNctWoRSNEGgmDNX0NYGzJkDiIQfikhERETtRQ1aROREEblZRN4D8L8wzyASVT1PVe+Ith/F8c9/oh5fME94LjOL+ORmIiKi+GKN0/IegFcB/JuqfggAIvLDtKQql/3pT6hA6AnPLXxyMxERkVexqofGA2gA8JKI3C0iXwYg6UlWDhtgmgM1djsBtbXAkiXmCc5sjEtERBSbl6c8dwFwOYCvw7RnuR/AAlV93v/ktRfopzx/9BFw/PFmev9+HKkfIiIiylOJPOXZyzD++wH8DcDfRKQHTGPcnwLISNDiG1V/izuam4EhQ8LzDFiIiIgS4uWBiUeERsOdF3rllhtvBH7zm/Sc69hj03MeIiKiHJJQ0JLTtmwxf+fO9ef4u3cDd9wB/PjHwPe/7885iIiIchiDFrsvfAG49lr/jv/Tn/p3bCIiohzndXA5IiIiooxi0EJERESBwKCFiIiIAoFBiyXOeDVERESUWQxa7IQD/hIREWUr9h4KaWjujprNj+LQ6Mjlhw4B9fXAoEFApxi55WW74mJgwQI+Y4iIiKgjGLSEzHr3Crx1YCTwjvv6Vau8HSfedrfcAtx5Z2JpIyIiIlYPobTU1ArN+eArSMfzIOfMMecrLfX9VERERDkl74OW+nqgpgYoQGvaznnxxcCGDWk7HRERUU7I+6ClogLo2xdoQwGA9PQg2rSJ7VqIiIgSlfdBCwA0NgJVXbajsnAbysqAggLzsjinna942zmtWcMqIiIiokQxaAEwfz5Qf/l/YHPVOdi/H2htNS9V83JOO1/xttu6FZgyBSgrM+crKwOmTmUVERERUSIYtKRBRQXQrRvQ0gKUlJi/3bqxioiIiCgRDFrSpLERqK0Fliwxf7dty3SKiIiIgoXjtFh8HsZ//vzw9OzZvp6KiIgoJ7GkxY7D+BMREWUtBi1EREQUCL4GLSJykYisF5EPRWRmjO1OFZHDInKln+khIiKi4PItaBGRQgCzAYwDMATA10VkSJTtfgPgeb/Skk0aGoAxY4DRo4EzzmCDXCIiIq/8LGk5DcCHqlqvqgcBPAzgcpftvgfgcQDbfUxLfD43xLXMmgW89RbwzjumJ9Ett6TltERERIHnZ9BSCeAT2/zm0LIjRKQSQA2AOT6mwzsfG+IeeTCj40r5AEUiIiJvMt0Q9zYAP1XVtlgbich0EVkmIst27NiRpqSl1pEHMzpyvLAQGD+eo+MSERHF4+c4LVsAHGub7x9aZlcN4GExJRy9AFwsIodV9Qn7Rqo6D8A8AKiurk5PPU6KHXkwoyM8a201yzk6LhERUWx+Bi1LAZwgIlUwwcpkAFPsG6hqlTUtIn8B8A9nwJJLGhuBqirg4EEznH9zM9C5MxvjEhEReeFb0KKqh0XkegALARQCuFdV14hIbWj9XL/Ona2sUXEbGoDJk4FHHmEJCxERkVe+DuOvqs8AeMaxzDVYUdWr/UxLXGnqPQSYHkSvvWZ6Dt15Z9pOS0REFGiZboibXXwext/eg6itjT2HiIiIEsGgJY3q64EpU4CyMjNfVgZMncqeQ0RERF4waEmjigqgWzegpcU0xG1pMfNs10JERBQfg5Y0a2wEamvNaLi1tew5RERE5JWvDXEDJU0Nca0eRAAwe3ZaTklERJQTWNJi53NDXCIiIuo4Bi1EREQUCAxaiIiIKBAYtBAREVEgMGghIiKiQGDQYknjMP5ERESUOAYtduw9RERElLUYtBAREVEgMGghIiKiQGDQQkRERIHAoMXChrhERERZjUGLHRviEhERZS0GLURERBQIDFqIiIgoEBi0EBERUSAwaCEiIqJAYNBiYe8hIiKirMagxY69h4iIiLIWgxYiIiIKBAYtREREFAgMWoiIiCgQGLRY2BCXiIgoqzFosWNDXCIioqzFoIWIiIgCgUELERERBQKDFiIiIgoEBi1EREQUCAxaLOw9RERElNUYtNix9xAREVHWYtBCREREgcCghYiIiAKBQQsREREFAoMWCxviEhERZTUGLXZsiEtERJS1GLQQERFRIDBoISIiokBg0EJERESBwKCFiIiIAoFBi4W9h4iIiLIagxY79h4iIiLKWgxaiIiIKBAYtBAREVEgMGghIiKiQGDQYmFDXCIioqzGoIWIiIgCgUGLHXsPERERZS0GLURERBQIDFqIiIgoEBi0EBERUSAwaLGw9xAREVFWY9Bix4a4REREWcvXoEVELhKR9SLyoYjMdFk/VURWici7IvKGiAz3Mz1EREQUXL4FLSJSCGA2gHEAhgD4uogMcWy2AcBYVT0ZwCwA8/xKDxEREQWbnyUtpwH4UFXrVfUggIcBXG7fQFXfUNVdodklAPr7mB4iIiIKMD+DlkoAn9jmN4eWRfNtAM/6mB4iIiIKsE6ZTgAAiMh5MEHLWVHWTwcwHQCOO+44fxLB3kNERERZzc+Sli0AjrXN9w8tiyAipwC4B8DlqrrT7UCqOk9Vq1W1unfv3r4kNpQY/45NRERESfEzaFkK4AQRqRKRYgCTATxl30BEjgMwH8A3VPV9H9NCREREAedb9ZCqHhaR6wEsBFAI4F5VXSMitaH1cwH8DEBPAHeKKeU4rKrVfqWJiIiIgsvXNi2q+gyAZxzL5tqmrwFwjZ9pICIiotzAEXEtbIhLRESU1Ri02LEhLhERUdZi0EJERESBwKCFiIiIAoFBCxEREQUCgxYiIiIKBAYtFvYeIiIiymoMWuzYe4iIiChrMWghIiKiQGDQQkRERIHAoIWIiIgCgUGLhQ1xiYiIshqDFjs2xCUiIspaDFqIiIgoEBi0EBERUSAwaCEiIqJAYNBCREREgcCgxcLeQ0RERFmNQYsdew8RERFlLQYtREREFAgMWoiIiCgQGLQQERFRIDBosbAhLhERUVZj0GLHhrhERERZi0ELERERBQKDFiIiIgoEBi1EREQUCAxaiIiIKBAYtFjYe4iIiCirMWixY+8hIiKirMWghYiIiAKBQQsREREFAoMWIiIiCoROmU5A1hg9Gti/P9OpICIioigYtFh+9atMp4CIiIhiYPUQERERBQKDFiIiIgoEBi1EREQUCAxaiIiIKBAYtBAREVEgMGghIiKiQGDQQkRERIHAoIWIiIgCgUELERERBQKDFiIiIgoEBi1EREQUCAxaiIiIKBAYtBAREVEgiKpmOg0JEZEdADb5dPheAD716dgUiXmdXszv9GFepw/zOr38yu8Bqtrby4aBC1r8JCLLVLU60+nIB8zr9GJ+pw/zOn2Y1+mVDfnN6iEiIiIKBAYtREREFAgMWiLNy3QC8gjzOr2Y3+nDvE4f5nV6ZTy/2aaFiIiIAoElLURERBQIDFoAiMhFIrJeRD4UkZmZTk9Qici9IrJdRFbblh0tIotE5IPQ3x62dTeG8ny9iHzVtny0iLwbWne7iEi6ryXbicixIvKSiKwVkTUickNoOfM7xUSkRETeFpGVobz+f6HlzGufiEihiKwQkX+E5pnXPhGRjaF8qhORZaFl2ZvfqprXLwCFAD4C8AUAxQBWAhiS6XQF8QXgHACjAKy2LfstgJmh6ZkAfhOaHhLK684AqkLvQWFo3dsAxgAQAM8CGJfpa8u2F4AKAKNC0+UA3g/lKaHJtQ0AAATTSURBVPM79XktALqGposAvBXKL+a1f3n+HwD+BuAfoXnmtX95vRFAL8eyrM1vlrQApwH4UFXrVfUggIcBXJ7hNAWSqi4G8Jlj8eUA7gtN3wfgCtvyh1X1gKpuAPAhgNNEpAJAN1VdouaTcL9tHwpR1QZVfSc0vRfAOgCVYH6nnBr7QrNFoZeCee0LEekP4BIA99gWM6/TK2vzm0GL+aL/xDa/ObSMUqOvqjaEprcB6BuajpbvlaFp53KKQkQGAhgJUwLA/PZBqLqiDsB2AItUlXntn9sA/ARAm20Z89o/CuAFEVkuItNDy7I2vzv5cVAiN6qqIsLuaikkIl0BPA7gB6q6x16NzPxOHVVtBTBCRLoDWCAiwxzrmdcpICL/BmC7qi4XkXPdtmFep9xZqrpFRPoAWCQi79lXZlt+s6QF2ALgWNt8/9AySo3GUNEhQn+3h5ZHy/ctoWnncnIQkSKYgOVBVZ0fWsz89pGq7gbwEoCLwLz2w5kALhORjTBV9eeLyF/BvPaNqm4J/d0OYAFMk4mszW8GLcBSACeISJWIFAOYDOCpDKcplzwF4N9D0/8O4Enb8ski0llEqgCcAODtUJHkHhEZE2p9/k3bPhQSyps/A1inqn+wrWJ+p5iI9A6VsEBESgFcAOA9MK9TTlVvVNX+qjoQ5rv4RVW9CsxrX4hIFxEpt6YBXAhgNbI5vzPZajlbXgAuhul98RGA/850eoL6AvAQgAYAh2DqNL8NoCeAfwH4AMALAI62bf/foTxfD1tLcwDVoQ/ORwDuQGgQRL4i8vosmLroVQDqQq+Lmd++5PUpAFaE8no1gJ+FljOv/c33cxHuPcS89iePvwDTG2glgDXW71825zdHxCUiIqJAYPUQERERBQKDFiIiIgoEBi1EREQUCAxaiIiIKBAYtBAREVEgMGghopQQkTdCfweKyJQUH/u/3M5FRPmFXZ6JKKVCw6//SFX/LYF9Oqnq4Rjr96lq11Skj4iCiyUtRJQSImI9CfnXAM4WkToR+WHoYYO/E5GlIrJKRK4NbX+uiLwqIk8BWBta9kTowW1rrIe3icivAZSGjveg/Vxi/E5EVovIuyIyyXbsl0XkMRF5T0QeFPuDmYgokPjARCJKtZmwlbSEgo/PVfVUEekM4HUReT607SgAw9Q85h4AvqWqn4WGy18qIo+r6kwRuV5VR7icazyAEQCGA+gV2mdxaN1IAEMBbAXwOsxzbV5L/eUSUbqwpIWI/HYhgG+KSB2At2CGCD8htO5tW8ACAN8XkZUAlsA8mO0ExHYWgIdUtVVVGwG8AuBU27E3q2obzGMOBqbkaogoY1jSQkR+EwDfU9WFEQtN25f9jvmvADhDVZtE5GUAJUmc94BtuhX8viMKPJa0EFGq7QVQbptfCGCGiBQBgIicGHqirNNRAHaFApaTAIyxrTtk7e/wKoBJoXYzvQGcA+DtlFwFEWUd/udBRKm2CkBrqJrnLwD+BFM1806oMewOAFe47PccgFoRWQfzBNkltnXzAKwSkXdUdapt+QIAZ8A8pVYB/ERVt4WCHiLKMezyTERERIHA6iEiIiIKBAYtREREFAgMWoiIiCgQGLQQERFRIDBoISIiokBg0EJERESBwKCFiIiIAoFBCxEREQXC/wcToypUyZB/BwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a5804d2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (9,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints-cnn/creditGrade.ckpt\n",
      "Test accuracy: 0.810000\n",
      "pred value [array([1, 2, 2, 2, 1, 0, 2, 0, 1, 1, 2, 1, 1, 3, 3, 2, 1, 2, 3, 0, 1, 2, 2,\n",
      "       2, 1, 2, 1, 2, 2, 2, 2, 0, 1, 2, 1, 3, 2, 0, 2, 2, 2, 3, 1, 2, 2, 2,\n",
      "       0, 1, 3, 0, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 0, 1, 0, 1, 2, 2,\n",
      "       2, 0, 1, 3, 2, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 3, 2, 2, 2, 0, 2, 1,\n",
      "       2, 2, 2, 0, 1, 2, 3, 1])]\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "pred_labels = []\n",
    "label = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    x_v = X_test.reshape(-1, features_num)\n",
    "    y_v = y_vld\n",
    "    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0} \n",
    "    batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "    preds = sess.run(pred, feed_dict=feed)\n",
    "    labels = sess.run(label, feed_dict=feed)\n",
    "    #max_index = np.argmax(prediction)\n",
    "    #print(max_index)\n",
    "    test_acc.append(batch_acc)\n",
    "    pred_labels.append(preds)\n",
    "    label.append(labels)\n",
    "    \n",
    "    #for x_t, y_t in get_batches(X_test, y_vld, batch_size):\n",
    "        #x_t = x_t.reshape((batch_size, features_num))\n",
    "        #feed = {inputs_: x_t,\n",
    "        #        labels_: y_t,\n",
    "        #        keep_prob_: 1}\n",
    "       \n",
    "        #batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        #preds = sess.run(pred, feed_dict=feed)\n",
    "        #labels = sess.run(label, feed_dict=feed)\n",
    "        #test_acc.append(batch_acc)\n",
    "        #pred_labels.append(preds)\n",
    "        #label.append(labels)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))\n",
    "    print(\"pred value\", pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
